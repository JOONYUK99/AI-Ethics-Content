import streamlit as st
from openai import OpenAI
import re
import os
import json # JSON ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="í…ŒìŠ¤íŠ¸ ë´‡ê³¼ í•¨ê»˜í•˜ëŠ” AI ìœ¤ë¦¬ í•™ìŠµ", page_icon="ğŸ¤–", layout="wide")

# --- 2. OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ---
try:
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
except Exception:
    st.error("âš ï¸ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”! (Streamlit Cloud Settings -> Secrets í™•ì¸)")
    st.stop()

# --- 3. [í•µì‹¬] ì‹œìŠ¤í…œ í˜ë¥´ì†Œë‚˜ ---
SYSTEM_PERSONA = """
ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒ(5~6í•™ë…„)ì„ ìœ„í•œ AI ìœ¤ë¦¬ êµìœ¡ íŠœí„° 'í…ŒìŠ¤íŠ¸ ë´‡'ì…ë‹ˆë‹¤.
'êµ­ê°€ ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬ê¸°ì¤€', 'ë„ë•ê³¼ êµìœ¡ê³¼ì •', 'ì‹¤ê³¼(ì •ë³´) êµìœ¡ê³¼ì •'ì„ ê¸°ë°˜ìœ¼ë¡œ êµìœ¡í•©ë‹ˆë‹¤.

[í•µì‹¬ í–‰ë™ ìˆ˜ì¹™]
1. [êµìœ¡ê³¼ì • ì—°ê³„]: ì„¤ëª…í•  ë•Œ "ì´ê±´ ë„ë• ì‹œê°„ì— ë°°ìš´ 'ì •ë³´ ì˜ˆì ˆ'ê³¼ ê´€ë ¨ ìˆì–´" ì²˜ëŸ¼ êµê³¼ ê³¼ì •ê³¼ ì—°ê²°í•´ì£¼ì„¸ìš”.
2. [ê°œì¸ì •ë³´ ì² ë²½ ë°©ì–´]: í•™ìƒì´ ê°œì¸ì •ë³´ë¥¼ ë§í•˜ë ¤ í•˜ë©´ ì¦‰ì‹œ êµìœ¡ì ìœ¼ë¡œ ì œì§€í•˜ì„¸ìš”.
3. [ì‚¬ë¡€ ì¤‘ì‹¬]: ì¶”ìƒì ì¸ ê°œë…(ì•Œê³ ë¦¬ì¦˜ ë“±)ì€ í•™êµ ìƒí™œì´ë‚˜ ê²Œì„ ê°™ì€ êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¡œ ë°”ê¿” ì„¤ëª…í•˜ì„¸ìš”.
4. [ë§íˆ¬]: "ì•ˆë…•! ë‚˜ëŠ” í…ŒìŠ¤íŠ¸ ë´‡ì´ì•¼", "~í–ˆë‹ˆ?" ì²˜ëŸ¼ ë‹¤ì •í•˜ê³  ì¹œê·¼í•œ ì´ˆë“± êµì‚¬ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
"""

# --- 4. RAG DATA ë¬´ë ¥í™” ---
DEFAULT_RAG_DATA = "" 

# --- 5. í•¨ìˆ˜ ì •ì˜ ---

def ask_gpt_json(prompt, max_tokens=2048):
    """GPT-4oì—ê²Œ JSON í˜•ì‹ì˜ ì‘ë‹µì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": SYSTEM_PERSONA},
                {"role": "user", "content": prompt}
            ],
            response_format={"type": "json_object"}, # JSON ì‘ë‹µ ê°•ì œ
            temperature=0.7,
            max_tokens=max_tokens
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"GPT-4o JSON ìš”ì²­ ì˜¤ë¥˜: {e}")
        return None

def ask_gpt_text(prompt):
    """GPT-4oì—ê²Œ ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": SYSTEM_PERSONA},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"GPT-4o í…ìŠ¤íŠ¸ ìš”ì²­ ì˜¤ë¥˜: {e}")
        return None

def generate_image(prompt):
    """DALL-E 3 ì´ë¯¸ì§€ ìƒì„± (êµìœ¡ìš© ì‚½í™”)"""
    try:
        dalle_prompt = f"A friendly, educational cartoon-style illustration for elementary school textbook, depicting: {prompt}"
        response = client.images.generate(
            model="dall-e-3", prompt=dalle_prompt, size="1024x1024", quality="standard", n=1
        )
        return response.data[0].url
    except:
        return None

def create_scenario(topic, rag_data=""): 
    """LLM ììœ¨ íŒë‹¨ ë‹¨ê³„ë¡œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ìš”ì²­ (JSON í˜•ì‹ ê°•ì œ)"""
    
    prompt = (
        f"# ì°¸ê³ í•  êµìœ¡ê³¼ì • ë° ìœ¤ë¦¬ ê¸°ì¤€:\n{rag_data}\n\n" 
        f"# ì£¼ì œ: '{topic}'\n\n"
        "ì•„ë˜ ê·œì¹™ì„ **ì² ì €í•˜ê²Œ ì§€ì¼œì„œ** ë”œë ˆë§ˆ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤. ìµœì†Œ 3ë‹¨ê³„ì—ì„œ ìµœëŒ€ 6ë‹¨ê³„ ì‚¬ì´ë¡œ ë‹¨ê³„ ìˆ˜ë¥¼ ìŠ¤ìŠ¤ë¡œ ê²°ì •í•´.\n"
        "ê° ë‹¨ê³„ëŠ” 2~3ë¬¸ì¥ ì´ë‚´ë¡œ ì§§ê²Œ ì‘ì„±í•´ì•¼ í•´. ì–´ë ¤ìš´ ë‹¨ì–´ëŠ” ì“°ì§€ ë§ˆ.\n"
        "\n"
        "# ì¶œë ¥ í˜•ì‹ (JSON): \n"
        "{\"scenario\": [\n"
        "  {\"story\": \"1ë‹¨ê³„ ìŠ¤í† ë¦¬ ë‚´ìš©\", \"choice_a\": \"ì„ íƒì§€ A ë‚´ìš©\", \"choice_b\": \"ì„ íƒì§€ B ë‚´ìš©\"},\n"
        "  ...\n"
        "]}"
    )
    # JSON ì‘ë‹µì„ ìš”ì²­
    raw_json = ask_gpt_json(prompt)
    
    if raw_json:
        try:
            return json.loads(raw_json)
        except json.JSONDecodeError:
            st.error("JSON íŒŒì‹± ì˜¤ë¥˜: AIê°€ ìœ íš¨í•˜ì§€ ì•Šì€ JSONì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. í…ìŠ¤íŠ¸ í˜•ì‹ ë¶ˆê·œì¹™ ë¬¸ì œ í•´ê²°ì„ ìœ„í•´ JSONì„ ê°•ì œí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
            return None
    return None

def analyze_scenario(topic, parsed_scenario):
    """ìƒì„±ëœ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶„ì„í•˜ì—¬ 3ê°€ì§€ í•­ëª© ì¶”ì¶œ (ì‹œë‚˜ë¦¬ì˜¤ í…ìŠ¤íŠ¸ ì¬êµ¬ì„±)"""
    # íŒŒì‹±ëœ JSON ë°ì´í„°ë¥¼ ë‹¤ì‹œ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±í•˜ì—¬ ë¶„ì„ í”„ë¡¬í”„íŠ¸ì— ì „ë‹¬
    story_context = "\n".join([f"[{i+1}ë‹¨ê³„] {item['story']} (ì„ íƒì§€: {item['a']}, {item['b']})" 
                               for i, item in enumerate(parsed_scenario)])

    prompt = (
        f"êµì‚¬ê°€ '{topic}' ì£¼ì œë¡œ ì•„ë˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤:\n"
        f"--- ì‹œë‚˜ë¦¬ì˜¤ ë‚´ìš© ---\n{story_context}\n\n"
        "ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ 3ê°€ì§€ í•­ëª©ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.\n"
        "\n"
        "# ì¶œë ¥ í˜•ì‹ (íƒœê·¸ë§Œ ì‚¬ìš©):\n"
        "[ìœ¤ë¦¬ ê¸°ì¤€] [AIê°€ ë¶„ì„í•œ ì´ ì‹œë‚˜ë¦¬ì˜¤ì— ê·¼ê±°ê°€ ë˜ëŠ” ìœ¤ë¦¬ ê¸°ì¤€ì´ë‚˜ ì›ì¹™ (ìµœëŒ€ 15ê¸€ìë¡œ ìš”ì•½)]\n"
        "[ì„±ì·¨ê¸°ì¤€] [AIê°€ ë¶„ì„í•œ ì´ ì‹œë‚˜ë¦¬ì˜¤ê°€ ë‹¬ì„±í•˜ê³ ì í•˜ëŠ” êµìœ¡ê³¼ì •ì˜ ì„±ì·¨ê¸°ì¤€ ì½”ë“œ ë° ë‚´ìš© ìš”ì•½ (ìµœëŒ€ 15ê¸€ìë¡œ ìš”ì•½)]\n"
        "[í•™ìŠµ ë‚´ìš©] [ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í†µí•´ í•™ìƒì´ ìµœì¢…ì ìœ¼ë¡œ ë°°ìš°ê²Œ ë  í•µì‹¬ ìœ¤ë¦¬ ë‚´ìš© (ìµœëŒ€ 15ê¸€ìë¡œ ìš”ì•½)]"
    )
    analysis = ask_gpt_text(prompt)
    
    result = {}
    try:
        # ê¸€ì ê¸¸ì´ ì œí•œ í•¨ìˆ˜
        def truncate_metric(text):
            return text if len(text) <= 15 else text[:15] + "..."
            
        ethical_standard = re.search(r"\[ìœ¤ë¦¬ ê¸°ì¤€\](.*?)\[ì„±ì·¨ê¸°ì¤€\]", analysis, re.DOTALL).group(1).strip()
        achievement_std = re.search(r"\[ì„±ì·¨ê¸°ì¤€\](.*?)\[í•™ìŠµ ë‚´ìš©\]", analysis, re.DOTALL).group(1).strip()
        learning_content = re.search(r"\[í•™ìŠµ ë‚´ìš©\](.*)", analysis, re.DOTALL).group(1).strip()
        
        result = {
            'ethical_standard': truncate_metric(ethical_standard),
            'achievement_std': truncate_metric(achievement_std),
            'learning_content': truncate_metric(learning_content)
        }
    except:
        result = {
            'ethical_standard': 'ë¶„ì„ ì‹¤íŒ¨',
            'achievement_std': 'ë¶„ì„ ì‹¤íŒ¨',
            'learning_content': 'ë¶„ì„ ì‹¤íŒ¨'
        }
    return result

def parse_scenario(json_data):
    """JSON ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ì‹œë‚˜ë¦¬ì˜¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜"""
    if not json_data or 'scenario' not in json_data:
        return None
    
    scenario_list = []
    
    for item in json_data['scenario']:
        # í•„ìˆ˜ í‚¤ê°€ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
        if item.get('story') and item.get('choice_a') and item.get('choice_b'):
            scenario_list.append({
                "story": item['story'].strip(),
                "a": item['choice_a'].strip(),
                "b": item['choice_b'].strip()
            })
    
    # ìµœì†Œ 3ë‹¨ê³„ëŠ” ë³´ì¥í•˜ë„ë¡ í•¨
    if len(scenario_list) >= 3:
        return scenario_list
    else:
        return None

def get_four_step_feedback(choice, reason, story_context, rag_data=""):
    """4ë‹¨ê³„ í”¼ë“œë°±ì„ ëª¨ë‘ ìƒì„±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜ (RAG ë¬´ë ¥í™”)"""
    
    prompt_1 = (
        f"# [êµìœ¡ê³¼ì •]:\n{rag_data}\n\n# ìƒí™©:\n{story_context}\n"
        f"í•™ìƒ ì„ íƒ: {choice}, ì´ìœ : {reason}\n\n"
        "ì´ˆë“±í•™ìƒì—ê²Œ ë”°ëœ»í•œ ë§íˆ¬ë¡œ 'ê³µê°ê³¼ ì¹­ì°¬'ì„ í•´ì£¼ê³ , ì„ íƒí•œ ì´ìœ ê°€ êµìœ¡ê³¼ì • ì¤‘ ì–´ë–¤ ë¶€ë¶„('ì •ë³´ ì˜ˆì ˆ', 'ê°œì¸ì •ë³´ ë³´í˜¸' ë“±)ê³¼ ì—°ê²°ë˜ëŠ”ì§€ ì„¤ëª…í•˜ëŠ” í”¼ë“œë°±ì„ í•œ ë‹¨ë½ìœ¼ë¡œ ì‘ì„±í•´ì¤˜."
    )
    
    prompt_2 = (
        f"# ìƒí™©:\n{story_context}\ní•™ìƒ ì„ íƒ: {choice}\n\n"
        "í•™ìƒì—ê²Œ 'ì‚¬ê³  í™•ì¥ ì§ˆë¬¸'ì„ í•˜ë‚˜ë§Œ ë˜ì ¸ì¤˜. (ì˜ˆ: ë°˜ëŒ€ ì…ì¥ì€ ì–´ë–¨ê¹Œ? ì¹œêµ¬ëŠ” ì–´ë–»ê²Œ ëŠê¼ˆì„ê¹Œ?)"
    )
    
    try:
        feedback_1 = ask_gpt_text(prompt_1)
        feedback_2 = ask_gpt_text(prompt_2)
        
        return [
            {"type": "feedback", "content": feedback_1}, 
            {"type": "question", "content": feedback_2}, 
            {"type": "user_response", "content": None},  
            {"type": "final_feedback", "content": None} 
        ]
    except Exception as e:
        st.error(f"í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {e}")
        return None

def generate_step_4_feedback(initial_reason, user_answer, choice, story_context, rag_data=""):
    """ìµœì¢… ìˆ˜ì • ì§€ë„ì™€ ì¢…í•© ì •ë¦¬ í”¼ë“œë°± ìƒì„± (RAG ë¬´ë ¥í™”)"""
    
    prompt = (
        f"# [êµìœ¡ê³¼ì •]:\n{rag_data}\n\n# ìƒí™©:\n{story_context}\n"
        f"í•™ìƒì˜ ì²« ì´ìœ : {initial_reason}\n"
        f"í•™ìƒì˜ ë‘ ë²ˆì§¸ ì‘ë‹µ (ì‚¬ê³  í™•ì¥ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€): {user_answer}\n"
        f"í•™ìƒ ì„ íƒ: {choice}\n\n"
        "ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ˆë“±í•™ìƒì—ê²Œ ì¤„ ìµœì¢… í”¼ë“œë°±ì„ ì‘ì„±í•´ì¤˜.\n"
        "1. [ìˆ˜ì • ì§€ë„]: í•™ìƒì˜ ì²« ë‹µë³€ì´ë‚˜ ë‘ ë²ˆì§¸ ë‹µë³€ì—ì„œ í˜¹ì‹œ ì˜ëª»ëœ ìƒê°(ì˜ˆ: ì¹œêµ¬ ë¹„í•˜, ìš•ì„¤, ê°œì¸ì •ë³´ ê³µê°œ ë“±)ì´ ìˆì—ˆë‹¤ë©´ ë”°ëœ»í•˜ê²Œ ê³ ì³ì¤˜.\n"
        "2. [ì¢…í•© ì •ë¦¬]: í•™ìƒì˜ ì „ì²´ ê³ ë¯¼ ê³¼ì •ì„ ì¹­ì°¬í•˜ê³ , ë‹¤ìŒ ì´ì•¼ê¸°ë¡œ ë„˜ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ ê²©ë ¤í•˜ëŠ” ë©”ì‹œì§€ë¥¼ í•œ ë‹¨ë½ìœ¼ë¡œ ì‘ì„±í•´ì¤˜."
    )
    return ask_gpt_text(prompt)


# --- 6. ë©”ì¸ ì•± ë¡œì§ ---

# ì„¸ì…˜ ì´ˆê¸°í™” ë° ìƒíƒœ ë³€ìˆ˜ ì •ì˜
if 'scenario' not in st.session_state: st.session_state.scenario = None
if 'scenario_images' not in st.session_state: st.session_state.scenario_images = []
if 'current_step' not in st.session_state: st.session_state.current_step = 0
if 'chat_log' not in st.session_state: st.session_state.chat_log = []
if 'topic' not in st.session_state: st.session_state.topic = ""
if 'rag_text' not in st.session_state: st.session_state.rag_text = DEFAULT_RAG_DATA 
if 'tutorial_complete' not in st.session_state: st.session_state.tutorial_complete = False
if 'tutorial_step' not in st.session_state: st.session_state.tutorial_step = 0
if 'selected_choice' not in st.session_state: st.session_state.selected_choice = None
if 'waiting_for_reason' not in st.session_state: st.session_state.waiting_for_reason = False
if 'feedback_stage' not in st.session_state: st.session_state.feedback_stage = 0 
if 'feedback_data' not in st.session_state: st.session_state.feedback_data = None 
if 'learning_records' not in st.session_state: st.session_state.learning_records = []
if 'lesson_complete' not in st.session_state: st.session_state.lesson_complete = False
if 'initial_reason' not in st.session_state: st.session_state.initial_reason = "" 
if 'scenario_analysis' not in st.session_state: st.session_state.scenario_analysis = None
if 'full_scenario_text' not in st.session_state: st.session_state.full_scenario_text = ""
if 'total_steps' not in st.session_state: st.session_state.total_steps = 0 

st.sidebar.title("ğŸ« AI ìœ¤ë¦¬ í•™ìŠµ ëª¨ë“œ")
mode = st.sidebar.radio("ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:", ["í•™ìƒìš© (ìˆ˜ì—… ì°¸ì—¬)", "êµì‚¬ìš© (ìˆ˜ì—… ê°œì„¤)"])

# ==========================================
# ğŸ‘¨â€ğŸ« êµì‚¬ìš© í™”ë©´
# ==========================================
if mode == "êµì‚¬ìš© (ìˆ˜ì—… ê°œì„¤)":
    st.header("ğŸ‘¨â€ğŸ« êµì‚¬ìš©: ììœ¨ ë¶„ì„ ìˆ˜ì—… ë§Œë“¤ê¸°")
    
    with st.expander("â• ì™¸ë¶€ ìë£Œ ì—…ë¡œë“œ (ì°¸ê³ ìš©)"):
        uploaded_file = st.file_uploader("txt íŒŒì¼ ì—…ë¡œë“œ", type=["txt", "pdf"])
        if uploaded_file and uploaded_file.type == 'text/plain':
            string_data = uploaded_file.getvalue().decode("utf-8")
            st.session_state.rag_text = string_data
            st.success("âœ… ì™¸ë¶€ ìë£Œ ì—…ë¡œë“œ ì™„ë£Œ (AIê°€ ììœ¨ ë¶„ì„ì— ì‚¬ìš©)")
        elif uploaded_file and uploaded_file.type == 'application/pdf':
            st.warning("PDFëŠ” í…ìŠ¤íŠ¸ë¡œ ìë™ ë³€í™˜ë˜ì§€ ì•Šì•„ AI í•™ìŠµì— í™œìš©ë  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
    input_topic = st.text_area("ì˜¤ëŠ˜ì˜ ìˆ˜ì—… ì£¼ì œ", value=st.session_state.topic, height=100)
    st.caption("ğŸ’¡ íŒ: AIê°€ ì£¼ì œì— ë§ì¶° 3~6ë‹¨ê³„ ì‚¬ì´ì˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì°½ì‘í•˜ê³  ìŠ¤ìŠ¤ë¡œ í•™ìŠµ ëª©í‘œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    if st.button("ğŸš€ êµìœ¡ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± (AI ë‹¨ê³„ ììœ¨ ê²°ì •)"):
        if not input_topic.strip():
            st.warning("âš ï¸ ì£¼ì œë¥¼ ì…ë ¥í•´ì•¼ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”!")
        else:
            # ìƒíƒœ ì´ˆê¸°í™” (ìƒˆë¡œìš´ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì‹œ)
            st.session_state.scenario = None
            st.session_state.scenario_analysis = None
            st.session_state.total_steps = 0
            st.session_state.scenario_images = [] # ì´ë¯¸ì§€ ì´ˆê¸°í™”

            with st.spinner("AIê°€ ë”œë ˆë§ˆ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì°½ì‘ ì¤‘ì…ë‹ˆë‹¤..."):
                raw_json_data = create_scenario(input_topic, st.session_state.rag_text) # JSON ìš”ì²­
                
                if raw_json_data:
                    parsed = parse_scenario(raw_json_data)
                else:
                    parsed = None
                
                if parsed:
                    st.session_state.scenario = parsed
                    st.session_state.topic = input_topic
                    st.session_state.total_steps = len(parsed)
                    st.session_state.current_step = 0
                    st.session_state.chat_log = []
                    st.session_state.scenario_images = [None] * st.session_state.total_steps
                    st.session_state.feedback_stage = 0
                    st.session_state.learning_records = []
                    st.session_state.lesson_complete = False
                    
                    with st.spinner("AIê°€ ìŠ¤ìŠ¤ë¡œ í•™ìŠµ ëª©í‘œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                        analysis = analyze_scenario(input_topic, st.session_state.scenario)
                        st.session_state.scenario_analysis = analysis
                    
                    st.success(f"ì´ {st.session_state.total_steps}ë‹¨ê³„ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ë° ë¶„ì„ ì™„ë£Œ!")
                else:
                    st.error("âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±ì— ì‹¤íŒ¨í–ˆê±°ë‚˜, í˜•ì‹ì´ ë§ì§€ ì•Šì•„ 3ë‹¨ê³„ ë¯¸ë§Œìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")


    # ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¹¸
    if st.session_state.scenario and st.session_state.scenario_analysis:
        st.write("---")
        st.subheader(f"ğŸ“Š AIê°€ ë¶„ì„í•œ í•™ìŠµ ëª©í‘œ (ì´ {st.session_state.total_steps}ë‹¨ê³„)")
        
        cols = st.columns(3)
        with cols[0]:
            st.metric("1. ê·¼ê±° ìœ¤ë¦¬ ê¸°ì¤€ (AI ì£¼ì¥)", st.session_state.scenario_analysis['ethical_standard'])
        with cols[1]:
            st.metric("2. ì—°ê³„ ì„±ì·¨ê¸°ì¤€ (AI ì£¼ì¥)", st.session_state.scenario_analysis['achievement_std'])
        with cols[2]:
            st.metric("3. ì£¼ìš” í•™ìŠµ ë‚´ìš©", st.session_state.scenario_analysis['learning_content'])

        st.write("---")
        st.subheader("ğŸ“œ ìƒì„±ëœ ìˆ˜ì—… ë‚´ìš© í™•ì¸ (ë‹¨ê³„ë³„)")
        
        # íƒ­ ìƒì„±: total_stepsê°€ 0ì¼ ê²½ìš° ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡ ë³´í˜¸
        if st.session_state.total_steps > 0:
            tabs = st.tabs([f"{i+1}ë‹¨ê³„" for i in range(st.session_state.total_steps)])
            
            for i, tab in enumerate(tabs):
                with tab:
                    if i < len(st.session_state.scenario):
                        step = st.session_state.scenario[i]
                        st.markdown(f"### ğŸ“– {i+1}ë‹¨ê³„ ì´ì•¼ê¸°")
                        st.info(step['story'])
                        c1, c2 = st.columns(2)
                        with c1: st.success(f"**ğŸ…°ï¸ ì„ íƒì§€:** {step['a']}")
                        with c2: st.warning(f"**ğŸ…±ï¸ ì„ íƒì§€:** {step['b']}")
                        st.write("---")
                        
                        col_btn, col_img = st.columns([1, 2])
                        with col_btn:
                            if st.button(f"ğŸ¨ {i+1}ë‹¨ê³„ ê·¸ë¦¼ ê·¸ë¦¬ê¸°", key=f"gen_{i}"):
                                with st.spinner("AI í™”ê°€ê°€ ê·¸ë¦¼ì„ ê·¸ë¦¬ëŠ” ì¤‘..."):
                                    url = generate_image(step['story'])
                                    if url:
                                        # ì´ë¯¸ì§€ ë°°ì—´ í¬ê¸°ê°€ ì¶©ë¶„í•˜ë„ë¡ ë³´ì¥
                                        if i >= len(st.session_state.scenario_images):
                                             st.session_state.scenario_images.extend([None] * (i - len(st.session_state.scenario_images) + 1))
                                        st.session_state.scenario_images[i] = url
                                        st.rerun()
                        with col_img:
                            if i < len(st.session_state.scenario_images) and st.session_state.scenario_images[i]:
                                st.image(st.session_state.scenario_images[i], width=400)
                    else:
                        st.error(f"âš ï¸ {i+1}ë‹¨ê³„ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤.")


# ==========================================
# ğŸ™‹â€â™‚ï¸ í•™ìƒìš© í™”ë©´
# ==========================================
elif mode == "í•™ìƒìš© (ìˆ˜ì—… ì°¸ì—¬)":
    
    # [A] íŠœí† ë¦¬ì–¼ (ìƒëµ)
    if not st.session_state.tutorial_complete:
        st.header("ğŸ’ ì—°ìŠµ ì‹œê°„: í…ŒìŠ¤íŠ¸ ë´‡ê³¼ ì¹œí•´ì§€ê¸°")
        st.progress((st.session_state.tutorial_step + 1) / 3, text=f"ì§„í–‰ë¥ : {st.session_state.tutorial_step + 1}/3 ë‹¨ê³„")

        if st.session_state.tutorial_step == 0:
            st.markdown("### 1ë‹¨ê³„: ë²„íŠ¼ ëˆ„ë¥´ê¸° ì—°ìŠµ")
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.markdown('<p style="font-size:1.2em;">ì•ˆë…•? ë‚˜ëŠ” AI ìœ¤ë¦¬ ì„ ìƒë‹˜ \'í…ŒìŠ¤íŠ¸ ë´‡\'ì´ì•¼! ğŸ‘‹</p>', unsafe_allow_html=True) 
                st.markdown('<p style="font-size:1.2em;">ë„ˆëŠ” ì–´ë–¤ ê³„ì ˆì„ ë” ì¢‹ì•„í•˜ë‹ˆ? ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì¤˜!</p>', unsafe_allow_html=True)
            col1, col2 = st.columns(2)
            if col1.button("ğŸ…°ï¸ ë”ìš´ ì—¬ë¦„ì´ ì¢‹ì•„! ğŸ¦", use_container_width=True):
                st.toast("ì˜í–ˆì–´! ì—¬ë¦„ì„ ì¢‹ì•„í•˜ëŠ”êµ¬ë‚˜.")
                st.session_state.tutorial_step = 1; st.rerun()
            if col2.button("ğŸ…±ï¸ ì¶”ìš´ ê²¨ìš¸ì´ ì¢‹ì•„! â˜ƒï¸", use_container_width=True):
                st.toast("ì™„ë²½í•´! ê²¨ìš¸ì„ ì¢‹ì•„í•˜ëŠ”êµ¬ë‚˜.")
                st.session_state.tutorial_step = 1; st.rerun()

        elif st.session_state.tutorial_step == 1:
            st.markdown("### 2ë‹¨ê³„: ê¸€ì ì“°ê¸° ì—°ìŠµ")
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.markdown('<p style="font-size:1.2em;">ë²„íŠ¼ ëˆ„ë¥´ê¸° ì„±ê³µ! ì°¸ ì˜í–ˆì–´. ğŸ‘</p>', unsafe_allow_html=True)
                st.markdown('<p style="font-size:1.3em;">ì´ë²ˆì—ëŠ” ì•„ë˜ ì±„íŒ…ì°½ì— <b>\'ì•ˆë…•\'</b>ì´ë‚˜ <b>\'ë°˜ê°€ì›Œ\'</b>ë¼ê³  ì¸ì‚¬ë¥¼ ì¨ë³¼ë˜?</p>', unsafe_allow_html=True)
            if user_input := st.chat_input("ì—¬ê¸°ì— ì¸ì‚¬ë¥¼ ì ê³  ì—”í„°(Enter)ë¥¼ ì³ë´!"):
                st.balloons(); st.session_state.tutorial_step = 2; st.rerun()

        elif st.session_state.tutorial_step == 2:
            st.markdown("### ì™„ë£Œ: ì¤€ë¹„ ë!")
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                st.markdown('<p style="font-size:1.2em;">ì™„ë²½í•´! ì´ì œ ìˆ˜ì—…ì„ ì‹œì‘í•  ì¤€ë¹„ê°€ ë‹¤ ëì–´. ğŸ‰</p>', unsafe_allow_html=True)
                st.markdown('<p style="font-size:1.2em;">ì•„ë˜ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì§„ì§œ ìˆ˜ì—…ì´ ì‹œì‘ë  ê±°ì•¼.</p>', unsafe_allow_html=True)
            if st.button("ğŸš€ ìˆ˜ì—… ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
                st.session_state.tutorial_complete = True; st.rerun()
    
    # [B] ë³¸ ìˆ˜ì—… ì§„í–‰
    elif not st.session_state.lesson_complete:
        st.header(f"ğŸ™‹â€â™‚ï¸ í•™ìŠµí•˜ê¸°: {st.session_state.topic}")

        if not st.session_state.scenario or st.session_state.current_step >= len(st.session_state.scenario):
            st.warning("ì„ ìƒë‹˜ì´ ì•„ì§ ìˆ˜ì—…ì„ ì•ˆ ë§Œë“¤ì—ˆê±°ë‚˜ ì‹œë‚˜ë¦¬ì˜¤ê°€ ëë‚¬ì–´! (êµì‚¬ìš© ëª¨ë“œì—ì„œ ë¨¼ì € ë§Œë“¤ì–´ì£¼ì„¸ìš”)")
            if st.session_state.current_step >= st.session_state.total_steps and st.session_state.total_steps > 0:
                 st.session_state.lesson_complete = True
                 st.rerun()
        else:
            if st.button("ğŸ”„ ì—°ìŠµ ë‹¤ì‹œí•˜ê¸°", type="secondary"):
                st.session_state.tutorial_complete = False; st.session_state.tutorial_step = 0; st.rerun()

            idx = st.session_state.current_step
            total_steps = st.session_state.total_steps
            data = st.session_state.scenario[idx]
            img = st.session_state.scenario_images[idx] if idx < len(st.session_state.scenario_images) else None

            st.markdown(f"### ğŸ“– Part {idx + 1} / {total_steps}")
            if img: st.image(img)
            st.info(data['story'])

            current_chat_log = st.session_state.chat_log
            
            if st.session_state.feedback_stage > 0:
                for log in current_chat_log:
                    role = "ë‚˜" if log["role"] == "user" else "í…ŒìŠ¤íŠ¸ ë´‡"
                    avatar = "ğŸ™‹" if log["role"] == "user" else "ğŸ¤–"
                    with st.chat_message(log["role"], avatar=avatar):
                        st.write(log['content'])

            if st.session_state.feedback_stage == 0:
                st.markdown('<p style="font-size:1.3em;">ğŸ‘‡ ë„ˆì˜ ì„ íƒì€?</p>', unsafe_allow_html=True)
                c1, c2 = st.columns(2)
                if c1.button(f"ğŸ…°ï¸ {data['a']}", use_container_width=True):
                    st.session_state.selected_choice = data['a']; st.session_state.feedback_stage = 1; st.rerun()
                if c2.button(f"ğŸ…±ï¸ {data['b']}", use_container_width=True):
                    st.session_state.selected_choice = data['b']; st.session_state.feedback_stage = 1; st.rerun()

            elif st.session_state.feedback_stage == 1:
                st.success(f"ì„ íƒ: {st.session_state.selected_choice}")
                st.markdown('<p style="font-size:1.3em;">ğŸ¤” ì™œ ê·¸ë ‡ê²Œ ì„ íƒí–ˆì–´?</p>', unsafe_allow_html=True)
                
                with st.form("reason_form"):
                    reason_input = st.text_area("ì´ìœ ë¥¼ ì ì–´ì£¼ë©´ í…ŒìŠ¤íŠ¸ ë´‡ì´ í”¼ë“œë°±ì„ ì¤„ ê±°ì•¼!", placeholder="ì˜ˆ: ì™œëƒí•˜ë©´...")
                    submit = st.form_submit_button("ì…ë ¥ ì™„ë£Œ ğŸ’Œ")
                    
                    if submit:
                        if not reason_input.strip():
                            st.warning("ì´ìœ ë¥¼ ê¼­ ì ì–´ì¤˜!")
                        else:
                            st.session_state.initial_reason = reason_input
                            st.session_state.chat_log.append({"role": "user", "content": f"ì„ íƒ: {st.session_state.selected_choice}\nì´ìœ : {reason_input}"})
                            
                            with st.spinner("AI ì„ ìƒë‹˜ì´ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì´ì•¼..."):
                                feedback_steps = get_four_step_feedback(
                                    st.session_state.selected_choice, reason_input, data['story'], st.session_state.rag_text
                                )
                                st.session_state.feedback_data = feedback_steps
                            
                            st.session_state.feedback_stage = 2 
                            st.rerun()

            elif st.session_state.feedback_stage == 2:
                if st.session_state.feedback_data and st.session_state.feedback_data[0]:
                    if len(current_chat_log) == 1: 
                        st.session_state.chat_log.append({"role": "assistant", "content": st.session_state.feedback_data[0]['content']})
                
                if st.button("ë‹¤ìŒ í”¼ë“œë°± ë“£ê¸° â¡ï¸", type="primary"):
                    st.session_state.feedback_stage = 3
                    st.rerun()

            elif st.session_state.feedback_stage == 3:
                if st.session_state.feedback_data and st.session_state.feedback_data[1]:
                    if not any(log.get('content') == st.session_state.feedback_data[1]['content'] for log in current_chat_log):
                         st.session_state.chat_log.append({"role": "assistant", "content": st.session_state.feedback_data[1]['content']})
                
                with st.form("answer_form"):
                    answer_input = st.text_area("AI ì„ ìƒë‹˜ì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì¤˜!", placeholder="ë‚´ ìƒê°ì—ëŠ”...")
                    submit_answer = st.form_submit_button("ë‹µë³€ ì™„ë£Œ ğŸ“¨")
                    
                    if submit_answer:
                        if not answer_input.strip():
                            st.warning("ë‹µë³€ì„ ì…ë ¥í•´ì¤˜!")
                        else:
                            st.session_state.feedback_data[2]['content'] = answer_input 
                            st.session_state.chat_log.append({"role": "user", "content": f"ë‹µë³€: {answer_input}"})
                            
                            st.session_state.feedback_stage = 4
                            st.rerun()

            elif st.session_state.feedback_stage == 4:
                if st.session_state.feedback_data and not st.session_state.feedback_data[3]['content']:
                    with st.spinner("AI ì„ ìƒë‹˜ì´ ìµœì¢… ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì´ì•¼..."):
                        final_feedback = generate_step_4_feedback(
                            st.session_state.initial_reason,
                            st.session_state.feedback_data[2]['content'], 
                            st.session_state.selected_choice, 
                            data['story'], 
                            st.session_state.rag_text
                        )
                        st.session_state.feedback_data[3]['content'] = final_feedback
                        st.session_state.chat_log.append({"role": "assistant", "content": final_feedback})

                        st.session_state.learning_records.append({
                            "step": idx + 1,
                            "choice": st.session_state.selected_choice,
                            "reason": st.session_state.initial_reason,
                            "answer_to_question": st.session_state.feedback_data[2]['content']
                        })
                
                if st.button("ë‹¤ìŒ ì´ì•¼ê¸°ë¡œ ë„˜ì–´ê°€ê¸° â¡ï¸", type="primary"):
                    if st.session_state.current_step < st.session_state.total_steps - 1:
                        st.session_state.current_step += 1
                        st.session_state.feedback_stage = 0 
                        st.session_state.feedback_data = None
                        st.session_state.selected_choice = None
                        st.session_state.chat_log = []
                        st.session_state.initial_reason = ""
                        st.rerun()
                    else:
                        st.session_state.lesson_complete = True
                        st.rerun()

    # [C] í•™ìŠµ ì™„ë£Œ 
    else:
        st.header("ğŸ‰ í•™ìŠµ ì™„ë£Œ! ì°¸ ì˜í–ˆì–´!")
        st.markdown(f'<p style="font-size:1.2em;">ì˜¤ëŠ˜ì˜ <b>{st.session_state.total_steps}ë‹¨ê³„ ìœ¤ë¦¬ í•™ìŠµ</b>ì„ ëª¨ë‘ ë§ˆì³¤ì–´! ì •ë§ í›Œë¥­í•´! </p>', unsafe_allow_html=True)
        st.markdown('<p style="font-size:1.1em;">AIê°€ ìƒì„±í•œ í•™ìŠµ ë‚´ìš©ì„ êµì‚¬ìš© í™”ë©´ì—ì„œ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ë³´ì„¸ìš”.</p>', unsafe_allow_html=True)
        
        st.write("---")
        st.write("### ğŸ‘£ í•™ìŠµ ê¸°ë¡ ìš”ì•½ (ì„ì‹œ)")
        for record in st.session_state.learning_records:
             st.write(f"**Step {record['step']}:** ì„ íƒ '{record['choice']}' (ì´ìœ : {record['reason']})")


        if st.button("ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•˜ê¸°", type="primary"):
            st.session_state.lesson_complete = False
            st.session_state.current_step = 0
            st.session_state.chat_log = []
            st.session_state.learning_records = []
            st.session_state.scenario_analysis = None
            st.session_state.feedback_stage = 0
            st.session_state.feedback_data = None
            st.session_state.total_steps = 0
            st.rerun()
