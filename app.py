import streamlit as st
import google.generativeai as genai
import re

# --- 1. ì˜ˆì‹œ ì£¼ì œ ë°ì´í„° (ì§€ì‹ ë² ì´ìŠ¤ ë‚´ìš© ì œê±°, í”„ë¡¬í”„íŠ¸ë§Œ ìœ ì§€) ---
EXAMPLE_TOPICS = {
    "AI ì˜ˆìˆ ê³¼ ì €ì‘ê¶Œ": "ìµœê·¼ ì—´ë¦° ë¯¸ìˆ  ëŒ€íšŒì—ì„œ AIë¡œ ê·¸ë¦° ê·¸ë¦¼ì´ 1ë“±ì„ ì°¨ì§€í•´ í° ë…¼ë€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ë¦¼ì„ ê·¸ë¦° í•™ìƒì€ AIì—ê²Œ ìˆ˜ë°± ë²ˆì˜ ì§€ì‹œì–´ë¥¼ ì…ë ¥í•˜ë©° ì›í•˜ëŠ” ê·¸ë¦¼ì„ ì–»ì—ˆë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì˜ ì €ì‘ê¶Œì€ ëˆ„êµ¬ì—ê²Œ ìˆì–´ì•¼ í• ê¹Œìš”?",
    "ììœ¨ì£¼í–‰ì°¨ì˜ ë”œë ˆë§ˆ": "ììœ¨ì£¼í–‰ì°¨ê°€ ê°‘ìê¸° ë‚˜íƒ€ë‚œ ì•„ì´ë“¤ì„ í”¼í•˜ë ¤ê³  í•¸ë“¤ì„ êº¾ìœ¼ë©´, ì°¨ì— íƒ€ê³  ìˆë˜ ë‚´ê°€ ë‹¤ì¹  ìˆ˜ ìˆëŠ” ìœ„í—˜í•œ ìƒí™©ì— ì²˜í–ˆìŠµë‹ˆë‹¤. ì´ë•Œ ììœ¨ì£¼í–‰ì°¨ëŠ” ì–´ë–¤ ì„ íƒì„ í•´ì•¼ í• ê¹Œìš”?",
    "AI íŠœí„°ì™€ ê°œì¸ì •ë³´": "ë‚˜ì˜ ëª¨ë“  ê²ƒì„ ì•Œê³  ë‚˜ì—ê²Œ ë”± ë§ëŠ” ê³µë¶€ë²•ì„ ì•Œë ¤ì£¼ëŠ” AI í•™ìŠµ ë¡œë´‡ì´ ìƒê²¼ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ë¡œë´‡ì´ ë‚˜ì˜ ëª¨ë“  í•™ìŠµ ê¸°ë¡ì„ ë°ì´í„° ì„¼í„°ë¡œ ì „ì†¡í•˜ê³  ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.",
    "ë”¥í˜ì´í¬ì™€ ê°€ì§œ ë‰´ìŠ¤": "ì¹œí•œ ì¹œêµ¬ì˜ ì–¼êµ´ì´ ë‹´ê¸´ ì´ìƒí•œ ë™ì˜ìƒì„ ì¸í„°ë„·ì—ì„œ ë³´ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì¹œêµ¬ëŠ” ê·¸ëŸ° ì˜ìƒì„ ì°ì€ ì ì´ ì—†ë‹¤ê³  ë§í•˜ëŠ”ë°, ì˜ìƒì€ ë„ˆë¬´ë‚˜ ì§„ì§œ ê°™ì•„ì„œ ë°˜ ì¹œêµ¬ë“¤ ì‚¬ì´ì— ì†Œë¬¸ì´ í¼ì§€ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤.",
    "AI ì¶”ì²œì˜ í¸í–¥ì„±": "ìƒˆë¡œ ë‚˜ì˜¨ ë™ì˜ìƒ ì•±ì„ ì‚¬ìš©í•˜ëŠ”ë°, ë‚˜ì—ê²ŒëŠ” í•­ìƒ ì•„ì´ëŒ ì¶¤ ì˜ìƒë§Œ ì¶”ì²œë˜ê³ , ë‚´ ë‚¨ë™ìƒì—ê²ŒëŠ” ê²Œì„ ì˜ìƒë§Œ ì¶”ì²œë˜ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë‚˜ëŠ” ê²Œì„ë„ ì¢‹ì•„í•˜ëŠ”ë° ì™œ ì•±ì€ ë‚˜ì—ê²Œ ê²Œì„ ì˜ìƒì„ ë³´ì—¬ì£¼ì§€ ì•ŠëŠ” ê±¸ê¹Œìš”?"
}

# --- 2. ê¸°ë³¸ ì„¤ì • ë° í•¨ìˆ˜ ---
# API í‚¤ ì„¤ì •
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception:
    st.error("âš ï¸ êµ¬ê¸€ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”! (Streamlit secrets)")
    st.stop()

def get_model():
    """Gemini ëª¨ë¸ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    return genai.GenerativeModel('gemini-pro')

# --- 3. AI ë¡œì§ í•¨ìˆ˜ë“¤ (RAG ì œê±°ë¨) ---

def transform_scenario(teacher_input):
    """
    ì„ ìƒë‹˜ì˜ ì…ë ¥(teacher_input)ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ì°¸ê³  ìë£Œ(Context) ì£¼ì… ë¶€ë¶„ì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.
    """
    model = get_model()
    prompt = (
        "ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒ ê³ í•™ë…„ ëˆˆë†’ì´ì— ë§ì¶° AI ìœ¤ë¦¬ êµìœ¡ìš© ì¸í„°ë™í‹°ë¸Œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.\n"
        "ì•„ë˜ 'ì…ë ¥ ë‚´ìš©'ì„ ë°”íƒ•ìœ¼ë¡œ, í•™ìƒë“¤ì´ ëª°ì…í•  ìˆ˜ ìˆëŠ” ì™„ê²°ëœ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.\n"
        "ì´ì•¼ê¸°ëŠ” ì´ 4ê°œì˜ íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ë©°, ê° íŒŒíŠ¸ ëì—ëŠ” ì£¼ì¸ê³µì˜ ê³ ë¯¼ì´ ë“œëŸ¬ë‚˜ëŠ” ë‘ ê°€ì§€ ì„ íƒì§€ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n\n"
        
        "# í•„ìˆ˜ ì¶œë ¥ í˜•ì‹:\n"
        "[STORY 1] ... [CHOICE 1A] ... [CHOICE 1B] ...\n---\n"
        "[STORY 2] ... [CHOICE 2A] ... [CHOICE 2B] ...\n---\n"
        "[STORY 3] ... [CHOICE 3A] ... [CHOICE 3B] ...\n---\n"
        "[STORY 4] ... [CHOICE 4A] ... [CHOICE 4B] ...\n\n"
        
        f"--- ì…ë ¥ ë‚´ìš© ---\n{teacher_input}"
    )
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        st.error(f"ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def analyze_student_response(debate_history):
    """í•™ìƒì˜ ë‹µë³€ì„ ë¶„ì„í•˜ì—¬ í† ë¡  ë°©í–¥ì„ ê²°ì •í•˜ëŠ” ê°ë… AI"""
    model = get_model()
    prompt = (
        "ë‹¹ì‹ ì€ í•™ìƒì˜ í† ë¡  ëŠ¥ë ¥ì„ ë¶„ì„í•˜ëŠ” êµìœ¡ ì‹¬ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n"
        "ì•„ë˜ 'í† ë¡  ë‚´ìš©'ì—ì„œ ê°€ì¥ ë§ˆì§€ë§‰ì— í•™ìƒì´ í•œ ë‹µë³€ì„ ë³´ê³ , í•™ìƒì˜ ì´í•´ë„ì™€ ë…¼ë¦¬ë ¥ì„ íŒë‹¨í•´ì£¼ì„¸ìš”.\n"
        "ë°˜ë“œì‹œ ë‹¤ìŒ ë„¤ ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œë§Œ í‰ê°€í•˜ê³ , ê·¸ ì´ìœ ë¥¼ ê°„ëµí•˜ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n\n"
        "# í‰ê°€ ì˜µì…˜:\n"
        "- ê¹Šê²Œ íŒŒê³ ë“¤ê¸°: í•™ìƒì´ ì£¼ì œë¥¼ ì˜ ì´í•´í•¨. ì‹¬í™” ì§ˆë¬¸ í•„ìš”.\n"
        "- í† ë¡  ì´ì–´ê°€ê¸°: ë¬´ë‚œí•˜ê²Œ í† ë¡  ì§„í–‰ ê°€ëŠ¥.\n"
        "- ì‰½ê²Œ ì§ˆë¬¸í•˜ê¸°: í•™ìƒì´ ì–´ë ¤ì›Œí•¨. ë” ì‰¬ìš´ ì§ˆë¬¸ í•„ìš”.\n"
        "- í† ë¡  ë§ˆë¬´ë¦¬í•˜ê¸°: ì£¼ì œ ì´íƒˆ í˜¹ì€ ë¶€ë‹´ê°. ë§ˆë¬´ë¦¬ í•„ìš”.\n\n"
        f"--- í† ë¡  ë‚´ìš© ---\n{debate_history}\n\n"
        "# í‰ê°€ ê²°ê³¼ (ì˜µì…˜ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ):"
    )
    try:
        response = model.generate_content(prompt)
        text = response.text.strip()
        if "ê¹Šê²Œ íŒŒê³ ë“¤ê¸°" in text: return "deepen"
        elif "ì‰½ê²Œ ì§ˆë¬¸í•˜ê¸°" in text: return "simplify"
        elif "í† ë¡  ë§ˆë¬´ë¦¬í•˜ê¸°" in text: return "end_early"
        else: return "continue"
    except Exception:
        return "continue"

def generate_simpler_question(debate_history):
    """ì‰¬ìš´ ì§ˆë¬¸ ìƒì„±"""
    model = get_model()
    prompt = (
        "ë‹¹ì‹ ì€ ë§¤ìš° ë‹¤ì •í•˜ê³  ì¹œì ˆí•œ AI ìœ¤ë¦¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.\n"
        "í•™ìƒì´ ë‹µë³€ì„ ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. í•™ìƒì„ ê²©ë ¤í•˜ë©° 'ì˜ˆ/ì•„ë‹ˆì˜¤'ë‚˜ 'ì„ íƒì§€' í˜•íƒœì˜ ì‰¬ìš´ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.\n\n"
        f"--- í† ë¡  ë‚´ìš© ---\n{debate_history}\n\n"
        "AI ì„ ìƒë‹˜ì˜ ì‰¬ìš´ ì§ˆë¬¸:"
    )
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception:
        return "ì¡°ê¸ˆ ì–´ë ¤ìš´ê°€ìš”? ê´œì°®ì•„ìš”. ê·¸ëŸ¼ ê°„ë‹¨í•˜ê²Œ ìƒê°í•´ë³´ì£ ."

def continue_debate(debate_history, level="normal"):
    """ì¼ë°˜/ì‹¬í™” ì§ˆë¬¸ ìƒì„±"""
    model = get_model()
    instruction = "ë°˜ë¡ ì„ ì œê¸°í•˜ê±°ë‚˜ ê´€ì ì„ ë°”ê¾¸ëŠ” ì‹¬í™” ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”." if level == "deepen" else "ìƒê°ì˜ í­ì„ ë„“íˆëŠ” ë‹¤ìŒ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
    prompt = (
        f"ë‹¹ì‹ ì€ ë‹¤ì •í•œ AI ìœ¤ë¦¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. {instruction}\n"
        "í•™ìƒì˜ ì˜ê²¬ì„ ê¹Šì´ ê³µê°í•˜ê³  ì¡´ì¤‘í•´ì£¼ì„¸ìš”.\n\n"
        f"--- í† ë¡  ë‚´ìš© ---\n{debate_history}\n\n"
        "AI ì„ ìƒë‹˜ì˜ ë‹¤ìŒ ì§ˆë¬¸:"
    )
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception:
        return "ì¢‹ì€ ìƒê°ì´ë„¤ìš”! ë˜ ë‹¤ë¥¸ ìƒê°ì€ ì—†ë‚˜ìš”?"

def parse_and_store_scenario(generated_text):
    """ìƒì„±ëœ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•˜ì—¬ ì„¸ì…˜ì— ì €ì¥"""
    st.session_state.full_scenario = []
    parts = generated_text.split('---')
    if len(parts) < 4: return False
    for part in parts:
        try:
            story = re.search(r"\[STORY\s?\d\](.*?)(?=\[CHOICE\s?\dA\])", part, re.DOTALL).group(1).strip()
            choice_a = re.search(r"\[CHOICE\s?\dA\](.*?)(?=\[CHOICE\s?\dB\])", part, re.DOTALL).group(1).strip()
            choice_b = re.search(r"\[CHOICE\s?\dB\](.*)", part, re.DOTALL).group(1).strip()
            st.session_state.full_scenario.append({"story": story, "choice_a": choice_a, "choice_b": choice_b})
        except Exception:
            continue
    return len(st.session_state.full_scenario) >= 4

def start_debate(history, choice):
    """í† ë¡  ì‹œì‘ ì§ˆë¬¸ ìƒì„±"""
    model = get_model()
    prompt = (
        "ë‹¹ì‹ ì€ ë‹¤ì •í•œ AI ìœ¤ë¦¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì˜ ì„ íƒì„ ì§€ì§€í•˜ë©° ìì—°ìŠ¤ëŸ½ê²Œ í† ë¡ ì„ ì‹œì‘í•˜ëŠ” ì²« ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.\n"
        f"--- ì´ì•¼ê¸°ì™€ ì„ íƒ ---\n{history}\ní•™ìƒì˜ ì„ íƒ: {choice}\n\nAI ì„ ìƒë‹˜:"
    )
    try:
        response = model.generate_content(prompt); return response.text.strip()
    except Exception: return "ì„ íƒí–ˆêµ°ìš”! ì™œ ê·¸ëŸ° ì„ íƒì„ í–ˆëŠ”ì§€ ê¶ê¸ˆí•´ìš”."

def generate_conclusion(final_history):
    """ìµœì¢… í”¼ë“œë°± ìƒì„±"""
    model = get_model()
    prompt = (
        "ë‹¹ì‹ ì€ ë‹¤ì •í•œ AI ìœ¤ë¦¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì˜ ì „ì²´ í† ë¡  ê¸°ë¡ì„ ë³´ê³ , ì •ë‹µë³´ë‹¤ëŠ” ê³ ë¯¼í•˜ëŠ” ê³¼ì •ì´ ì¤‘ìš”í–ˆìŒì„ ì¹­ì°¬í•˜ëŠ” ë”°ëœ»í•œ ë§ˆë¬´ë¦¬ ë©˜íŠ¸ë¥¼ í•´ì£¼ì„¸ìš”.\n"
        f"--- ì „ì²´ ê¸°ë¡ ---\n{final_history}"
    )
    try:
        response = model.generate_content(prompt); return response.text.strip()
    except Exception: return "ì •ë§ ìˆ˜ê³ í–ˆì–´ìš”! í›Œë¥­í•œ í† ë¡ ì´ì—ˆìŠµë‹ˆë‹¤."

# --- 4. ë©”ì¸ ì•± ë¡œì§ ---

def run_main_app():
    st.header("âœ¨ ì´ˆë“±í•™ìƒì„ ìœ„í•œ AI ìœ¤ë¦¬ êµìœ¡ (Basic ver.)")
    st.caption("AIì˜ ê¸°ë³¸ ì§€ì‹ë§Œì„ í™œìš©í•˜ì—¬ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

    # ì„¸ì…˜ ì´ˆê¸°í™”
    if 'stage' not in st.session_state:
        st.session_state.stage = 'start'
        st.session_state.full_scenario = []
        st.session_state.full_log = ""
        st.session_state.current_part = -1
        st.session_state.debate_turns = 0
        st.session_state.debate_finished = False

    MAX_DEBATE_REPLIES = 3

    def restart():
        for key in ['stage', 'full_scenario', 'full_log', 'current_part', 'debate_turns', 'debate_finished']:
            if key in st.session_state: del st.session_state[key]
        st.rerun()

    # [1ë‹¨ê³„] ì‹œì‘ í™”ë©´
    if st.session_state.stage == 'start':
        st.info("AI ìœ¤ë¦¬ ì£¼ì œë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì„ íƒí•˜ë©´, AIê°€ ì¦‰ì‹œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.")
        
        # ì£¼ì œ ì„ íƒ (RAG ë‚´ìš© ì—†ì´ í”„ë¡¬í”„íŠ¸ë§Œ ê°€ì ¸ì˜´)
        options_list = ["ì§ì ‘ ì…ë ¥..."] + list(EXAMPLE_TOPICS.keys())
        selected_topic = st.selectbox("ì£¼ì œ ì„ íƒ:", options_list)

        default_text = ""
        if selected_topic != "ì§ì ‘ ì…ë ¥...":
            default_text = EXAMPLE_TOPICS[selected_topic]
        
        teacher_input = st.text_area("ì‹œë‚˜ë¦¬ì˜¤ ì†Œì¬ ì…ë ¥:", value=default_text, height=150)

        if st.button("êµìœ¡ ì½˜í…ì¸  ìƒì„±í•˜ê¸°"):
            if not teacher_input.strip():
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("AIê°€ ìƒìƒë ¥ì„ ë°œíœ˜í•´ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ê³  ìˆì–´ìš”..."):
                    # RAG ê³¼ì • ì—†ì´ ë°”ë¡œ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ
                    scenario_text = transform_scenario(teacher_input)
                    
                    if scenario_text and parse_and_store_scenario(scenario_text):
                        st.session_state.full_log = f"**ì£¼ì œ:** {teacher_input[:50]}..."
                        st.session_state.current_part = 0
                        st.session_state.stage = 'story'
                        st.rerun()
                    else:
                        st.error("ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì‹¤íŒ¨. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    # [2ë‹¨ê³„] ì´ì•¼ê¸° ì§„í–‰ ë° ì„ íƒ
    elif st.session_state.stage == 'story':
        part = st.session_state.full_scenario[st.session_state.current_part]
        current_story = f"\n\n---\n\n### ğŸ“– ì´ì•¼ê¸° #{st.session_state.current_part + 1}\n{part['story']}"
        
        # ë¡œê·¸ì— ì—†ìœ¼ë©´ ì¶”ê°€
        if current_story.strip() not in st.session_state.full_log:
            st.session_state.full_log += current_story
            
        st.markdown(current_story)
        st.info("ì–´ë–¤ ì„ íƒì„ í•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
        
        c1, c2 = st.columns(2)
        if c1.button(f"A: {part['choice_a']}", use_container_width=True):
            st.session_state.full_log += f"\n\n**>> ë‚˜ì˜ ì„ íƒ(A):** {part['choice_a']}"
            st.session_state.stage = 'debate'
            st.rerun()
        if c2.button(f"B: {part['choice_b']}", use_container_width=True):
            st.session_state.full_log += f"\n\n**>> ë‚˜ì˜ ì„ íƒ(B):** {part['choice_b']}"
            st.session_state.stage = 'debate'
            st.rerun()

    # [3ë‹¨ê³„] í† ë¡  ì§„í–‰
    elif st.session_state.stage == 'debate':
        # ì±„íŒ… UI í‘œì‹œ
        for msg in st.session_state.full_log.split('\n\n'):
            msg = msg.strip()
            if not msg: continue
            if msg.startswith(">> ë‚˜ì˜ ì„ íƒ"): st.chat_message("user", avatar="ğŸ™‹").write(msg)
            elif msg.startswith("AI ì„ ìƒë‹˜:"): st.chat_message("assistant", avatar="ğŸ¤–").write(msg.replace("AI ì„ ìƒë‹˜:", ""))
            elif msg.startswith("ë‚˜ (ì˜ê²¬"): st.chat_message("user", avatar="ğŸ™‹").write(msg)
            elif "### ğŸ“– ì´ì•¼ê¸°" in msg: st.markdown(msg) # ì´ì•¼ê¸° ë¶€ë¶„ì€ í…ìŠ¤íŠ¸ë¡œ

        # í† ë¡  ì¢…ë£Œ ì²˜ë¦¬
        if st.session_state.debate_finished:
            st.success("í† ë¡ ì´ ëë‚¬ìŠµë‹ˆë‹¤.")
            is_last = st.session_state.current_part >= len(st.session_state.full_scenario) - 1
            if st.button("ë‹¤ìŒ ë‹¨ê³„ë¡œ" if not is_last else "ìµœì¢… ê²°ê³¼ ë³´ê¸°"):
                st.session_state.debate_turns = 0
                st.session_state.debate_finished = False
                st.session_state.current_part += 1
                st.session_state.stage = 'conclusion' if is_last else 'story'
                st.rerun()
        
        else:
            # 1. AI ì²« ì§ˆë¬¸
            if st.session_state.debate_turns == 0:
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    with st.spinner("ìƒê° ì¤‘..."):
                        last_choice = st.session_state.full_log.split('>> ë‚˜ì˜ ì„ íƒ')[-1]
                        q = start_debate(st.session_state.full_log, last_choice)
                        st.write(q)
                        st.session_state.full_log += f"\n\nAI ì„ ìƒë‹˜: {q}"
                        st.session_state.debate_turns = 1

            # 2. í•™ìƒ ë‹µë³€ ì…ë ¥
            elif st.session_state.debate_turns % 2 != 0:
                if user_input := st.chat_input(f"ë‹µë³€í•˜ê¸° ({ (st.session_state.debate_turns+1)//2 }/{MAX_DEBATE_REPLIES})"):
                    st.session_state.full_log += f"\n\në‚˜ (ì˜ê²¬): {user_input}"
                    st.session_state.debate_turns += 1
                    st.rerun()

            # 3. AI ë°˜ì‘ ë° ë‹¤ìŒ ì§ˆë¬¸
            else:
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    with st.spinner("ë¶„ì„ ì¤‘..."):
                        decision = analyze_student_response(st.session_state.full_log)
                        
                        # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
                        if decision == "end_early" or (st.session_state.debate_turns / 2) >= MAX_DEBATE_REPLIES:
                            msg = "ì¢‹ì€ ì˜ê²¬ ê°ì‚¬í•©ë‹ˆë‹¤. ì´ ì£¼ì œì— ëŒ€í•´ ì¶©ë¶„íˆ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆˆ ê²ƒ ê°™ë„¤ìš”!"
                            st.write(msg)
                            st.session_state.full_log += f"\n\nAI ì„ ìƒë‹˜: {msg}"
                            st.session_state.debate_finished = True
                            st.rerun()
                        else:
                            # ì§ˆë¬¸ ìƒì„±
                            if decision == "simplify": q = generate_simpler_question(st.session_state.full_log)
                            elif decision == "deepen": q = continue_debate(st.session_state.full_log, "deepen")
                            else: q = continue_debate(st.session_state.full_log, "normal")
                            
                            st.write(q)
                            st.session_state.full_log += f"\n\nAI ì„ ìƒë‹˜: {q}"
                            st.session_state.debate_turns += 1
                            st.rerun()

    # [4ë‹¨ê³„] ìµœì¢… ê²°ê³¼
    elif st.session_state.stage == 'conclusion':
        st.balloons()
        st.header("ğŸ‰ ìˆ˜ì—… ì¢…ë£Œ")
        st.subheader("ì „ì²´ ê¸°ë¡")
        st.text_area("í™œë™ ë¡œê·¸", st.session_state.full_log, height=300)
        
        st.subheader("ğŸ‘©â€ğŸ« ì„ ìƒë‹˜ì˜ í”¼ë“œë°±")
        with st.spinner("í”¼ë“œë°± ì‘ì„± ì¤‘..."):
            final_comment = generate_conclusion(st.session_state.full_log)
            st.write(final_comment)
            
        if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
            restart()

# ì•± ì‹¤í–‰
if __name__ == "__main__":
    run_main_app()
