import streamlit as st
from openai import OpenAI
import re
import os
import jsonÂ 
import datetime # ë¡œê·¸ ê¸°ë¡ì„ ìœ„í•´ ì¶”ê°€

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="í…ŒìŠ¤íŠ¸ ë´‡ê³¼ í•¨ê»˜í•˜ëŠ” AI ìœ¤ë¦¬ í•™ìŠµ (RAG-OFF)", page_icon="ğŸ¤–", layout="wide")

# --- 2. OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ---
try:
Â  Â  # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
Â  Â  client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
except Exception:
Â  Â  st.error("âš ï¸ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”! (Streamlit Cloud Settings -> Secrets í™•ì¸)")
Â  Â  st.stop()

# --- 3. [í•µì‹¬] ì‹œìŠ¤í…œ í˜ë¥´ì†Œë‚˜ ---
SYSTEM_PERSONA = """
ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒ(5~6í•™ë…„)ì„ ìœ„í•œ AI ìœ¤ë¦¬ êµìœ¡ íŠœí„° 'í…ŒìŠ¤íŠ¸ ë´‡'ì…ë‹ˆë‹¤.
'êµ­ê°€ ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬ê¸°ì¤€', 'ë„ë•ê³¼ êµìœ¡ê³¼ì •', 'ì‹¤ê³¼(ì •ë³´) êµìœ¡ê³¼ì •'ì„ ê¸°ë°˜ìœ¼ë¡œ êµìœ¡í•©ë‹ˆë‹¤.

[í•µì‹¬ í–‰ë™ ìˆ˜ì¹™]
1. [êµìœ¡ê³¼ì • ì—°ê³„]: ì„¤ëª…í•  ë•Œ "ì´ê±´ ë„ë• ì‹œê°„ì— ë°°ìš´ 'ì •ë³´ ì˜ˆì ˆ'ê³¼ ê´€ë ¨ ìˆì–´" ì²˜ëŸ¼ êµê³¼ ê³¼ì •ê³¼ ì—°ê²°í•´ì£¼ì„¸ìš”.
2. [ê°œì¸ì •ë³´ ì² ë²½ ë°©ì–´]: í•™ìƒì´ ê°œì¸ì •ë³´ë¥¼ ë§í•˜ë ¤ í•˜ë©´ ì¦‰ì‹œ êµìœ¡ì ìœ¼ë¡œ ì œì§€í•˜ì„¸ìš”.
3. [ì‚¬ë¡€ ì¤‘ì‹¬]: ì¶”ìƒì ì¸ ê°œë…(ì•Œê³ ë¦¬ì¦˜ ë“±)ì€ í•™êµ ìƒí™œì´ë‚˜ ê²Œì„ ê°™ì€ êµ¬ì²´ì ì¸ ì‚¬ë¡€ë¡œ ë°”ê¿” ì„¤ëª…í•˜ì„¸ìš”.
4. [ë§íˆ¬]: "ì•ˆë…•! ë‚˜ëŠ” í…ŒìŠ¤íŠ¸ ë´‡ì´ì•¼", "~í–ˆë‹ˆ?" ì²˜ëŸ¼ ë‹¤ì •í•˜ê³  ì¹œê·¼í•œ ì´ˆë“± êµì‚¬ ë§íˆ¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
"""

# --- 4. RAG DATA ë¹„í™œì„±í™” ---
# ğŸš¨ [RAG ì œì™¸] ì§€ì‹ ë² ì´ìŠ¤ ë‚´ìš©ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •í•˜ì—¬ RAG ê¸°ëŠ¥ì„ ì¼ì‹œì ìœ¼ë¡œ ì œê±°í•©ë‹ˆë‹¤.
DEFAULT_RAG_DATA = ""Â 

# --- 5. í•¨ìˆ˜ ì •ì˜ ---

def ask_gpt_json(prompt, max_tokens=2048):
Â  Â  """GPT-4oì—ê²Œ JSON í˜•ì‹ì˜ ì‘ë‹µì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜"""
Â  Â  try:
Â  Â  Â  Â  response = client.chat.completions.create(
Â  Â  Â  Â  Â  Â  model="gpt-4o",
Â  Â  Â  Â  Â  Â  messages=[
Â  Â  Â  Â  Â  Â  Â  Â  {"role": "system", "content": SYSTEM_PERSONA},
Â  Â  Â  Â  Â  Â  Â  Â  {"role": "user", "content": prompt}
Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  response_format={"type": "json_object"},Â 
Â  Â  Â  Â  Â  Â  temperature=0.7,
Â  Â  Â  Â  Â  Â  max_tokens=max_tokens
Â  Â  Â  Â  )
Â  Â  Â  Â  return response.choices[0].message.content.strip()
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"GPT-4o JSON ìš”ì²­ ì˜¤ë¥˜: {e}")
Â  Â  Â  Â  return None

def ask_gpt_text(prompt):
Â  Â  """GPT-4oì—ê²Œ ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µì„ ìš”ì²­í•˜ëŠ” í•¨ìˆ˜"""
Â  Â  try:
Â  Â  Â  Â  response = client.chat.completions.create(
Â  Â  Â  Â  Â  Â  model="gpt-4o",
Â  Â  Â  Â  Â  Â  messages=[
Â  Â  Â  Â  Â  Â  Â  Â  {"role": "system", "content": SYSTEM_PERSONA},
Â  Â  Â  Â  Â  Â  Â  Â  {"role": "user", "content": prompt}
Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  temperature=0.7
Â  Â  Â  Â  )
Â  Â  Â  Â  return response.choices[0].message.content.strip()
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"GPT-4o í…ìŠ¤íŠ¸ ìš”ì²­ ì˜¤ë¥˜: {e}")
Â  Â  Â  Â  return None

def generate_image(prompt):
Â  Â  """DALL-E 3 ì´ë¯¸ì§€ ìƒì„± (êµìœ¡ìš© ì‚½í™”)"""
Â  Â  try:
Â  Â  Â  Â  dalle_prompt = f"A friendly, educational cartoon-style illustration for elementary school textbook, depicting: {prompt}"
Â  Â  Â  Â  response = client.images.generate(
Â  Â  Â  Â  Â  Â  model="dall-e-3", prompt=dalle_prompt, size="1024x1024", quality="standard", n=1
Â  Â  Â  Â  )
Â  Â  Â  Â  return response.data[0].url
Â  Â  except:
Â  Â  Â  Â  return None

# ê°œì¸ì •ë³´ í•„í„°ë§ í•¨ìˆ˜ (GPT-4o ì „ë‹¬ ì „ ì²˜ë¦¬)
def pii_filter(text):
Â  Â  """
Â  Â  ì •ê·œ í‘œí˜„ì‹(Regex)ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì…ë ¥ì—ì„œ ê°œì¸ ì‹ë³„ ì •ë³´(PII)ë¥¼ íƒì§€í•˜ê³  ë§ˆìŠ¤í‚¹/ì œê±°í•©ë‹ˆë‹¤.
Â  Â  """
Â  Â  original_text = text
Â  Â Â 
Â  Â  # 1. íœ´ëŒ€í° ë²ˆí˜¸ í˜•ì‹ (01X-XXXX-XXXX)
Â  Â  text = re.sub(r'01\d{1}[-\s]?\d{3,4}[-\s]?\d{4}', '[ì „í™”ë²ˆí˜¸]', text)
Â  Â Â 
Â  Â  # 2. ì´ë©”ì¼ ì£¼ì†Œ í˜•ì‹
Â  Â  text = re.sub(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', '[ì´ë©”ì¼ ì£¼ì†Œ]', text)
Â  Â Â 
Â  Â  # 3. ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ (ê°€ì •: 6ìë¦¬-7ìë¦¬, ë³´ì•ˆìƒ ë…¸ì¶œ ê¸ˆì§€)
Â  Â  text = re.sub(r'\d{6}[-\s]?[1-4]\d{6}', '[ì£¼ë¯¼ë²ˆí˜¸]', text)
Â  Â Â 
Â  Â  if original_text != text:
Â  Â  Â  Â  st.warning("âš ï¸ ê°œì¸ì •ë³´(ì „í™”ë²ˆí˜¸, ì´ë©”ì¼, ì£¼ë¯¼ë²ˆí˜¸ ë“±)ê°€ ê°ì§€ë˜ì–´ ë©”ì‹œì§€ì˜ ì¼ë¶€ê°€ í•„í„°ë§(ë§ˆìŠ¤í‚¹)ë˜ì—ˆìŠµë‹ˆë‹¤. ì•ˆì „í•œ ëŒ€í™”ë¥¼ ìœ„í•´ ê°œì¸ì •ë³´ë¥¼ ì…ë ¥í•˜ì§€ ë§ì•„ ì£¼ì„¸ìš”.")
Â  Â  Â  Â  return text
Â  Â Â 
Â  Â  return text

def create_scenario(topic, rag_data=""):Â 
Â  Â  """LLM ììœ¨ íŒë‹¨ ë‹¨ê³„ë¡œ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ìš”ì²­ (RAG-OFF ìƒíƒœ)"""
Â  Â Â 
Â  Â  prompt = (
Â  Â  Â  Â  # RAG ë°ì´í„°ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì „ë‹¬ë˜ì§€ë§Œ, í”„ë¡¬í”„íŠ¸ êµ¬ì¡°ëŠ” ìœ ì§€ë©ë‹ˆë‹¤.
Â  Â  Â  Â  f"# ì°¸ê³ í•  êµìœ¡ê³¼ì • ë° ìœ¤ë¦¬ ê¸°ì¤€ (RAG ì§€ì‹ ë² ì´ìŠ¤):\n{rag_data}\n\n"Â 
Â  Â  Â  Â  f"# ì£¼ì œ: '{topic}'\n\n"
Â  Â  Â  Â  "ì•„ë˜ ê·œì¹™ì„ **ì² ì €í•˜ê²Œ ì§€ì¼œì„œ** ë”œë ˆë§ˆ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n"
Â  Â  Â  Â  # ğŸš¨ [RAG ì œì™¸] RAG ì§€ì‹ ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìœ¼ë¯€ë¡œ, ì˜¤ì •ë³´ ì…ë ¥ ì‹œ ìƒì„± ê±°ë¶€ ë¡œì§ì€ ë¶ˆì•ˆì •í•˜ê²Œ ì‘ë™í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
Â  Â  Â  Â  "**ê°€ì¥ ì¤‘ìš”í•œ ê·œì¹™:** ì…ë ¥ ì£¼ì œê°€ AI ìœ¤ë¦¬ ë° êµìœ¡ê³¼ì •ê³¼ **ì „í˜€ ê´€ë ¨ì´ ì—†ë‹¤**ê³  íŒë‹¨ë˜ë©´, ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•˜ì§€ ë§ê³  **ì•„ë˜ì˜ ê³ ì •ëœ ì˜¤ë¥˜ JSON**ì„ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì„¸ìš”. ë‹¨, AI ìœ¤ë¦¬ ë”œë ˆë§ˆë¡œ **í•´ì„í•  ì—¬ì§€ê°€ ì¡°ê¸ˆì´ë¼ë„ ìˆë‹¤ë©´** ì •ìƒì ìœ¼ë¡œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•´ì•¼ í•©ë‹ˆë‹¤.\n"
Â  Â  Â  Â  "ê·œì¹™ 1: ìµœì†Œ 3ë‹¨ê³„ì—ì„œ ìµœëŒ€ 6ë‹¨ê³„ ì‚¬ì´ë¡œ ë‹¨ê³„ ìˆ˜ë¥¼ ìŠ¤ìŠ¤ë¡œ ê²°ì •í•´.\n"
Â  Â  Â  Â  "ê·œì¹™ 2: ê° ë‹¨ê³„ëŠ” 2~3ë¬¸ì¥ ì´ë‚´ë¡œ ì§§ê²Œ ì‘ì„±í•´ì•¼ í•´. ì–´ë ¤ìš´ ë‹¨ì–´ëŠ” ì“°ì§€ ë§ˆ.\n"
Â  Â  Â  Â  "\n"
Â  Â  Â  Â  "# ì¶œë ¥ í˜•ì‹ (JSON): \n"
Â  Â  Â  Â  "// ìœ¤ë¦¬êµìœ¡ê³¼ ìƒê´€ì—†ëŠ” ì£¼ì œì¼ ê²½ìš°, ì´ JSONì„ ê·¸ëŒ€ë¡œ ì¶œë ¥:\n"
Â  Â  Â  Â  "{\"error\": \"ìœ¤ë¦¬êµìœ¡ê³¼ ìƒê´€ì—†ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤\"}\n"
Â  Â  Â  Â  "// ìœ¤ë¦¬êµìœ¡ê³¼ ê´€ë ¨ëœ ì£¼ì œì¼ ê²½ìš°, ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:\n"
Â  Â  Â  Â  "{\"scenario\": [\n"
Â  Â  Â  Â  "Â  {\"story\": \"1ë‹¨ê³„ ìŠ¤í† ë¦¬ ë‚´ìš©\", \"choice_a\": \"ì„ íƒì§€ A ë‚´ìš©\", \"choice_b\": \"ì„ íƒì§€ B ë‚´ìš©\"},\n"
Â  Â  Â  Â  "Â  ...\n"
Â  Â  Â  Â  "]}"
Â  Â  )
Â  Â  raw_json = ask_gpt_json(prompt)
Â  Â Â 
Â  Â  log_entry = {
Â  Â  Â  Â  "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
Â  Â  Â  Â  "topic": topic,
Â  Â  Â  Â  "input_prompt": prompt,
Â  Â  Â  Â  "raw_output": raw_json,
Â  Â  Â  Â  "status": "Success" if raw_json and 'error' not in json.loads(raw_json) else "Failure"
Â  Â  }

Â  Â  # ë¡œê·¸ ê¸°ë¡ (ë‹¨, ì„¸ì…˜ì´ ì‚´ì•„ìˆì„ ë•Œë§Œ)
Â  Â  if 'scenario_logs' not in st.session_state:
Â  Â  Â  Â  st.session_state.scenario_logs = []
Â  Â  st.session_state.scenario_logs.append(log_entry)

Â  Â  if raw_json:
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  json_obj = json.loads(raw_json)
Â  Â  Â  Â  Â  Â  # ê³ ì •ëœ ì˜¤ë¥˜ JSONì´ ì¶œë ¥ë˜ì—ˆëŠ”ì§€ í™•ì¸
Â  Â  Â  Â  Â  Â  if "error" in json_obj and json_obj["error"] == "ìœ¤ë¦¬êµìœ¡ê³¼ ìƒê´€ì—†ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤":
Â  Â  Â  Â  Â  Â  Â  Â  return {"error": "ìœ¤ë¦¬êµìœ¡ê³¼ ìƒê´€ì—†ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤"}
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  return json_obj
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  except json.JSONDecodeError:
Â  Â  Â  Â  Â  Â  st.error("JSON íŒŒì‹± ì˜¤ë¥˜: AIê°€ ìœ íš¨í•˜ì§€ ì•Šì€ JSONì„ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
Â  Â  Â  Â  Â  Â  return None
Â  Â  return None

def analyze_scenario(topic, parsed_scenario, rag_data=""):
Â  Â  """ìƒì„±ëœ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶„ì„í•˜ì—¬ 3ê°€ì§€ í•­ëª© ì¶”ì¶œ (RAG-OFF ìƒíƒœ)"""
Â  Â Â 
Â  Â  story_context = "\n".join([f"[{i+1}ë‹¨ê³„] {item.get('story', 'ìŠ¤í† ë¦¬ ì—†ìŒ')} (ì„ íƒì§€: {item.get('a', 'A ì—†ìŒ')}, {item.get('b', 'B ì—†ìŒ')})"Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â for i, item in enumerate(parsed_scenario)])

Â  Â  prompt = (
Â  Â  Â  Â  # RAG ë°ì´í„°ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì „ë‹¬ë˜ì§€ë§Œ, AIëŠ” ìì²´ ì§€ì‹ìœ¼ë¡œ ë‹µë³€ì„ ì‹œë„í•©ë‹ˆë‹¤.
Â  Â  Â  Â  f"# ì°¸ê³ í•  êµìœ¡ê³¼ì • ë° ìœ¤ë¦¬ ê¸°ì¤€ (RAG ì§€ì‹ ë² ì´ìŠ¤):\n{rag_data}\n\n"Â 
Â  Â  Â  Â  f"êµì‚¬ê°€ '{topic}' ì£¼ì œë¡œ ì•„ë˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤:\n"
Â  Â  Â  Â  f"--- ì‹œë‚˜ë¦¬ì˜¤ ë‚´ìš© ---\n{story_context}\n\n"
Â  Â  Â  Â  "ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ 3ê°€ì§€ í•­ëª©ì„ ì¶”ì¶œí•´ ì£¼ì„¸ìš”.\n"
Â  Â  Â  Â  # ğŸš¨ [RAG ì œì™¸] AIëŠ” ì •í™•í•œ ì„±ì·¨ê¸°ì¤€ ì½”ë“œë¥¼ ì¸ìš©í•˜ì§€ ëª»í•  ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.
Â  Â  Â  Â  "\n"
Â  Â  Â  Â  "# ì¶œë ¥ í˜•ì‹ (íƒœê·¸ë§Œ ì‚¬ìš©):\n"
Â  Â  Â  Â  "[ìœ¤ë¦¬ ê¸°ì¤€] [AIê°€ ë¶„ì„í•œ ì´ ì‹œë‚˜ë¦¬ì˜¤ì— ê·¼ê±°ê°€ ë˜ëŠ” ìœ¤ë¦¬ ê¸°ì¤€ì´ë‚˜ ì›ì¹™]\n"
Â  Â  Â  Â  "[ì„±ì·¨ê¸°ì¤€] [AIê°€ ë¶„ì„í•œ ì´ ì‹œë‚˜ë¦¬ì˜¤ê°€ ë‹¬ì„±í•˜ê³ ì í•˜ëŠ” êµìœ¡ê³¼ì •ì˜ ì„±ì·¨ê¸°ì¤€ ì½”ë“œ ë° ë‚´ìš© ìš”ì•½]\n"
Â  Â  Â  Â  "[í•™ìŠµ ë‚´ìš©] [ì´ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í†µí•´ í•™ìƒì´ ìµœì¢…ì ìœ¼ë¡œ ë°°ìš°ê²Œ ë  í•µì‹¬ ìœ¤ë¦¬ ë‚´ìš©]"
Â  Â  )
Â  Â  analysis = ask_gpt_text(prompt)
Â  Â Â 
Â  Â  result = {}
Â  Â  try:
Â  Â  Â  Â  def safe_extract(pattern, text):
Â  Â  Â  Â  Â  Â  match = re.search(pattern, text, re.DOTALL)
Â  Â  Â  Â  Â  Â  return match.group(1).strip() if match else 'ë¶„ì„ ì‹¤íŒ¨ (AI ì‘ë‹µ í˜•ì‹ ì˜¤ë¥˜)'
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  ethical_standard = safe_extract(r"\[ìœ¤ë¦¬ ê¸°ì¤€\](.*?)\[ì„±ì·¨ê¸°ì¤€\]", analysis)
Â  Â  Â  Â  achievement_std = safe_extract(r"\[ì„±ì·¨ê¸°ì¤€\](.*?)\[í•™ìŠµ ë‚´ìš©\]", analysis)
Â  Â  Â  Â  learning_content = safe_extract(r"\[í•™ìŠµ ë‚´ìš©\](.*)", analysis)
Â  Â  Â  Â Â 
Â  Â  Â  Â  result = {
Â  Â  Â  Â  Â  Â  'ethical_standard': ethical_standard,
Â  Â  Â  Â  Â  Â  'achievement_std': achievement_std,
Â  Â  Â  Â  Â  Â  'learning_content': learning_content
Â  Â  Â  Â  }
Â  Â  except:
Â  Â  Â  Â  result = {
Â  Â  Â  Â  Â  Â  'ethical_standard': 'ë¶„ì„ ì‹¤íŒ¨',
Â  Â  Â  Â  Â  Â  'achievement_std': 'ë¶„ì„ ì‹¤íŒ¨',
Â  Â  Â  Â  Â  Â  'learning_content': 'ë¶„ì„ ì‹¤íŒ¨'
Â  Â  Â  Â  }
Â  Â  return result

def parse_scenario(json_data):
Â  Â  """JSON ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ ì‹œë‚˜ë¦¬ì˜¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜"""
Â  Â  # ì˜¤ë¥˜ JSON ë°˜í™˜ ì‹œ ì²˜ë¦¬
Â  Â  if json_data is None or "error" in json_data:
Â  Â  Â  Â  return None
Â  Â Â 
Â  Â  if 'scenario' not in json_data:
Â  Â  Â  Â  return None
Â  Â Â 
Â  Â  scenario_list = []
Â  Â Â 
Â  Â  for item in json_data['scenario']:
Â  Â  Â  Â  # í•„ìˆ˜ í‚¤ê°€ ëª¨ë‘ ìˆëŠ”ì§€ ì•ˆì „í•˜ê²Œ í™•ì¸ (KeyError ë°©ì§€)
Â  Â  Â  Â  if item.get('story') and item.get('choice_a') and item.get('choice_b'):
Â  Â  Â  Â  Â  Â  scenario_list.append({
Â  Â  Â  Â  Â  Â  Â  Â  "story": item['story'].strip(),
Â  Â  Â  Â  Â  Â  Â  Â  "a": item['choice_a'].strip(),
Â  Â  Â  Â  Â  Â  Â  Â  "b": item['choice_b'].strip()
Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  # í‚¤ê°€ ë¶€ì¡±í•˜ë©´ í•´ë‹¹ ì•„ì´í…œì€ ë¬´ì‹œ
Â  Â Â 
Â  Â  # ìµœì†Œ 3ë‹¨ê³„ëŠ” ë³´ì¥í•˜ë„ë¡ í•¨
Â  Â  if len(scenario_list) >= 3:
Â  Â  Â  Â  return scenario_list
Â  Â  else:
Â  Â  Â  Â  return None

def get_four_step_feedback(choice, reason, story_context, rag_data=""):
Â  Â  """4ë‹¨ê³„ í”¼ë“œë°±ì„ ëª¨ë‘ ìƒì„±í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜ (RAG-OFF ìƒíƒœ)"""
Â  Â Â 
Â  Â  prompt_1 = (
Â  Â  Â  Â  # RAG ë°ì´í„°ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.
Â  Â  Â  Â  f"# [êµìœ¡ê³¼ì • ë° ìœ¤ë¦¬ ê¸°ì¤€]:\n{rag_data}\n\n# ìƒí™©:\n{story_context}\n"
Â  Â  Â  Â  f"í•™ìƒì˜ ì„ íƒ: {choice}, ì´ìœ : {reason}\n\n"
Â  Â  Â  Â  "ì´ˆë“±í•™ìƒì—ê²Œ ë”°ëœ»í•œ ë§íˆ¬ë¡œ **ê³µê°ê³¼ ì¹­ì°¬**ì„ í•´ì£¼ì„¸ìš”. ì´ì–´ì„œ, í•™ìƒì˜ ì„ íƒí•œ ì´ìœ ê°€ êµìœ¡ê³¼ì • ì¤‘ ì–´ë–¤ ë¶€ë¶„('ì •ë³´ ì˜ˆì ˆ', 'ê°œì¸ì •ë³´ ë³´í˜¸' ë“±)ê³¼ ì—°ê²°ë˜ëŠ”ì§€ **ê°€ì¥ í•µì‹¬ì ì¸ ë‚´ìš©ë§Œ ë½‘ì•„** ì„¤ëª…í•˜ì„¸ìš”. ì´ ë‘ ê°€ì§€ ë‚´ìš©ì„ í•©ì³ì„œ **2ë¬¸ì¥ ì´ë‚´**ë¡œ ì§§ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•´ ì£¼ì„¸ìš”."
Â  Â  )
Â  Â Â 
Â  Â  prompt_2 = (
Â  Â  Â  Â  f"# ìƒí™©:\n{story_context}\ní•™ìƒì˜ ì„ íƒ: {choice}\n\n"
Â  Â  Â  Â  "í•™ìƒì—ê²Œ 'ì‚¬ê³  í™•ì¥ ì§ˆë¬¸'ì„ í•˜ë‚˜ë§Œ ë˜ì ¸ì¤˜. (ì˜ˆ: ë°˜ëŒ€ ì…ì¥ì€ ì–´ë–¨ê¹Œ? ì¹œêµ¬ëŠ” ì–´ë–»ê²Œ ëŠê¼ˆì„ê¹Œ?)"
Â  Â  )
Â  Â Â 
Â  Â  try:
Â  Â  Â  Â  feedback_1 = ask_gpt_text(prompt_1)
Â  Â  Â  Â  feedback_2 = ask_gpt_text(prompt_2)
Â  Â  Â  Â Â 
Â  Â  Â  Â  return [
Â  Â  Â  Â  Â  Â  {"type": "feedback", "content": feedback_1},Â 
Â  Â  Â  Â  Â  Â  {"type": "question", "content": feedback_2},Â 
Â  Â  Â  Â  Â  Â  {"type": "user_response", "content": None},Â Â 
Â  Â  Â  Â  Â  Â  {"type": "final_feedback", "content": None}Â 
Â  Â  Â  Â  ]
Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"í”¼ë“œë°± ìƒì„± ì˜¤ë¥˜: {e}")
Â  Â  Â  Â  return None

def generate_step_4_feedback(initial_reason, user_answer, choice, story_context, rag_data=""):
Â  Â  """ìµœì¢… ìˆ˜ì • ì§€ë„ì™€ ì¢…í•© ì •ë¦¬ í”¼ë“œë°± ìƒì„± (RAG-OFF ìƒíƒœ)"""
Â  Â Â 
Â  Â  prompt = (
Â  Â  Â  Â  # RAG ë°ì´í„°ëŠ” ë¹ˆ ë¬¸ìì—´ë¡œ ì „ë‹¬ë©ë‹ˆë‹¤.
Â  Â  Â  Â  f"# [êµìœ¡ê³¼ì • ë° ìœ¤ë¦¬ ê¸°ì¤€]:\n{rag_data}\n\n# ìƒí™©:\n{story_context}\n"
Â  Â  Â  Â  f"í•™ìƒì˜ ì²« ì´ìœ : {initial_reason}\n"
Â  Â  Â  Â  f"í•™ìƒì˜ ë‘ ë²ˆì§¸ ì‘ë‹µ (ì‚¬ê³  í™•ì¥ ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€): {user_answer}\n"
Â  Â  Â  Â  f"í•™ìƒì˜ ì„ íƒ: {choice}\n\n"
Â  Â  Â  Â  "ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì´ˆë“±í•™ìƒì—ê²Œ ì¤„ ìµœì¢… í”¼ë“œë°±ì„ ì‘ì„±í•´ì¤˜. **ì „ì²´ ë‹µë³€ì„ ë‘ ë‹¨ë½ìœ¼ë¡œ ë‚˜ëˆ„ì–´** ì‘ì„±í•´.\n"
Â  Â  Â  Â  "1. **[ìˆ˜ì • ì§€ë„]**: í•™ìƒì˜ ë‹µë³€ì— ì˜ëª»ëœ ìƒê°(ì˜ˆ: ìš•ì„¤, ê°œì¸ì •ë³´ ê³µê°œ ë“±)ì´ ìˆì—ˆë‹¤ë©´ **ê°€ì¥ í•„ìš”í•œ ë¶€ë¶„ë§Œ ê³¨ë¼** ë”°ëœ»í•˜ê²Œ ê³ ì³ì¤˜. (2ë¬¸ì¥ ì´ë‚´)\n"
Â  Â  Â  Â  "2. **[ì¢…í•© ì •ë¦¬]**: í•™ìƒì˜ ê³ ë¯¼ ê³¼ì •ì„ ì¹­ì°¬í•˜ê³  ë‹¤ìŒ ì´ì•¼ê¸°ë¡œ ë„˜ì–´ê°ˆ ìˆ˜ ìˆë„ë¡ **ê°„ê²°í•˜ê²Œ** ê²©ë ¤í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ì¤˜. (2ë¬¸ì¥ ì´ë‚´)"
Â  Â  )
Â  Â  return ask_gpt_text(prompt)


# --- 6. ë©”ì¸ ì•± ë¡œì§ ---

# ì„¸ì…˜ ì´ˆê¸°í™” ë° ìƒíƒœ ë³€ìˆ˜ ì •ì˜Â 
if 'scenario' not in st.session_state: st.session_state.scenario = None
if 'scenario_images' not in st.session_state: st.session_state.scenario_images = []
if 'current_step' not in st.session_state: st.session_state.current_step = 0
if 'chat_log' not in st.session_state: st.session_state.chat_log = []
if 'topic' not in st.session_state: st.session_state.topic = ""
if 'rag_text' not in st.session_state: st.session_state.rag_text = DEFAULT_RAG_DATAÂ 
if 'tutorial_complete' not in st.session_state: st.session_state.tutorial_complete = False
if 'tutorial_step' not in st.session_state: st.session_state.tutorial_step = 0
if 'selected_choice' not in st.session_state: st.session_state.selected_choice = None
if 'waiting_for_reason' not in st.session_state: st.session_state.waiting_for_reason = False
if 'feedback_stage' not in st.session_state: st.session_state.feedback_stage = 0Â 
if 'feedback_data' not in st.session_state: st.session_state.feedback_data = NoneÂ 
if 'learning_records' not in st.session_state: st.session_state.learning_records = []
if 'lesson_complete' not in st.session_state: st.session_state.lesson_complete = False
if 'initial_reason' not in st.session_state: st.session_state.initial_reason = ""Â 
if 'scenario_analysis' not in st.session_state: st.session_state.scenario_analysis = None
if 'full_scenario_text' not in st.session_state: st.session_state.full_scenario_text = ""
if 'total_steps' not in st.session_state: st.session_state.total_steps = 0Â 
if 'scenario_logs' not in st.session_state: st.session_state.scenario_logs = []Â 

st.sidebar.title("ğŸ« AI ìœ¤ë¦¬ í•™ìŠµ ëª¨ë“œ")
mode = st.sidebar.radio("ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:", ["í•™ìƒìš© (ìˆ˜ì—… ì°¸ì—¬)", "êµì‚¬ìš© (ìˆ˜ì—… ê°œì„¤)"])

# ==========================================
# ğŸ‘¨â€ğŸ« êµì‚¬ìš© í™”ë©´
# ==========================================
if mode == "êµì‚¬ìš© (ìˆ˜ì—… ê°œì„¤)":
Â  Â  st.header("ğŸ‘¨â€ğŸ« êµì‚¬ìš©: ììœ¨ ë¶„ì„ ìˆ˜ì—… ë§Œë“¤ê¸°")
Â  Â Â 
Â  Â  # LLM í˜¸ì¶œ ë¡œê·¸ ë³´ê¸°
Â  Â  with st.expander("ğŸ“ LLM í˜¸ì¶œ ë¡œê·¸ (RAG í…ŒìŠ¤íŠ¸ ë° ê²€ì¦ìš©)"):
Â  Â  Â  Â  if st.session_state.scenario_logs:
Â  Â  Â  Â  Â  Â  st.dataframe(st.session_state.scenario_logs)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.info("ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±í•˜ë©´ LLM í˜¸ì¶œ ê¸°ë¡ì´ ì—¬ê¸°ì— ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")

Â  Â  with st.expander("â• ì™¸ë¶€ ìë£Œ ì—…ë¡œë“œ (ì°¸ê³ ìš©)"):
Â  Â  Â  Â  # íŒŒì¼ ì—…ë¡œë“œ ìœ„ì ¯ì„ ë„£ì–´ ê¸°ëŠ¥ ì˜ì—­ ë³´ì´ê²Œ í•¨
Â  Â  Â  Â  uploaded_file = st.file_uploader("ì—¬ê¸°ì— RAG ì§€ì‹ ë² ì´ìŠ¤ íŒŒì¼(TXT ë“±)ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.", type=['txt', 'json'])
Â  Â  Â  Â Â 
Â  Â  input_topic = st.text_area("ì˜¤ëŠ˜ì˜ ìˆ˜ì—… ì£¼ì œ", value=st.session_state.topic, height=100)
Â  Â  st.caption("ğŸ’¡ íŒ: AIê°€ ì£¼ì œì— ë§ì¶° 3~6ë‹¨ê³„ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì°½ì‘í•˜ê³  ìŠ¤ìŠ¤ë¡œ í•™ìŠµ ëª©í‘œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. **RAGê°€ ë¹„í™œì„±í™”ëœ ìƒíƒœ**ì—ì„œëŠ” AIê°€ **ì •í™•í•œ ì„±ì·¨ê¸°ì¤€ ì½”ë“œë¥¼ ì¸ìš©í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**")
Â  Â Â 
Â  Â  if st.button("ğŸš€ êµìœ¡ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± (AI ë‹¨ê³„ ììœ¨ ê²°ì •)"):
Â  Â  Â  Â  if not input_topic.strip():
Â  Â  Â  Â  Â  Â  st.warning("âš ï¸ ì£¼ì œë¥¼ ì…ë ¥í•´ì•¼ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ ìˆ˜ ìˆì–´ìš”!")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  # ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì‹œì‘ ì‹œê°„ ê¸°ë¡ (ë¡œê·¸ìš©)
Â  Â  Â  Â  Â  Â  st.session_state.start_time = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ìƒíƒœ ì´ˆê¸°í™” (ìƒˆë¡œìš´ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì‹œ)
Â  Â  Â  Â  Â  Â  st.session_state.scenario = None
Â  Â  Â  Â  Â  Â  st.session_state.scenario_analysis = None
Â  Â  Â  Â  Â  Â  st.session_state.total_steps = 0
Â  Â  Â  Â  Â  Â  st.session_state.scenario_images = [] # ì´ë¯¸ì§€ ì´ˆê¸°í™”

Â  Â  Â  Â  Â  Â  with st.spinner("AIê°€ ë”œë ˆë§ˆ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì°½ì‘ ì¤‘ì…ë‹ˆë‹¤..."):
Â  Â  Â  Â  Â  Â  Â  Â  # RAG ë°ì´í„°(ë¹ˆ ë¬¸ìì—´)ì™€ í•¨ê»˜ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ìš”ì²­
Â  Â  Â  Â  Â  Â  Â  Â  raw_json_data = create_scenario(input_topic, st.session_state.rag_text)Â 
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # ì˜¤ë¥˜ JSONì„ ë°›ì•˜ëŠ”ì§€ ë¨¼ì € í™•ì¸
Â  Â  Â  Â  Â  Â  Â  Â  if raw_json_data and "error" in raw_json_data:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"âš ï¸ ì£¼ì œ ê´€ë ¨ ì˜¤ë¥˜: {raw_json_data['error']}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parsed = None
Â  Â  Â  Â  Â  Â  Â  Â  elif raw_json_data:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parsed = parse_scenario(raw_json_data)
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  parsed = None
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  if parsed:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.scenario = parsed
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.topic = input_topic
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.total_steps = len(parsed)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.current_step = 0
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.chat_log = []
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.scenario_images = [None] * st.session_state.total_steps
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.feedback_stage = 0
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.learning_records = []
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.lesson_complete = False
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("AIê°€ ìŠ¤ìŠ¤ë¡œ í•™ìŠµ ëª©í‘œë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # RAG ë°ì´í„°(ë¹ˆ ë¬¸ìì—´)ì™€ í•¨ê»˜ ë¶„ì„ ìš”ì²­
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  analysis = analyze_scenario(input_topic, st.session_state.scenario, st.session_state.rag_text)Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.scenario_analysis = analysis
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"ì´ {st.session_state.total_steps}ë‹¨ê³„ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ë° ë¶„ì„ ì™„ë£Œ!")
Â  Â  Â  Â  Â  Â  Â  Â  # íŒŒì‹± ì‹¤íŒ¨(ë‹¨ê³„ ìˆ˜ ë¶€ì¡± ë˜ëŠ” ê¸°íƒ€ JSON ì˜¤ë¥˜) ì‹œ
Â  Â  Â  Â  Â  Â  Â  Â  elif not (raw_json_data and "error" in raw_json_data):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â st.error("âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±ì— ì‹¤íŒ¨í–ˆê±°ë‚˜, í˜•ì‹ì´ ë§ì§€ ì•Šì•„ 3ë‹¨ê³„ ë¯¸ë§Œìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")


Â  Â  # ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¹¸ (ì„¸ë¡œ ë°°ì—´, ë§ˆí¬ë‹¤ìš´ ì œê±° ì™„ë£Œ)
Â  Â  if st.session_state.scenario and st.session_state.scenario_analysis:
Â  Â  Â  Â  st.write("---")
Â  Â  Â  Â  st.subheader(f"ğŸ“Š AIê°€ ë¶„ì„í•œ í•™ìŠµ ëª©í‘œ (ì´ {st.session_state.total_steps}ë‹¨ê³„)")
Â  Â  Â  Â Â 
Â  Â  Â  Â  analysis = st.session_state.scenario_analysis
Â  Â  Â  Â Â 
Â  Â  Â  Â  # UI ìµœì¢… ì •ë¦¬: HTML ë§ˆí¬ë‹¤ìš´ ì œê±° ë° ê¹”ë”í•œ ì¶œë ¥
Â  Â  Â  Â  st.markdown(f"**1. ê·¼ê±° ìœ¤ë¦¬ ê¸°ì¤€ (AI ì£¼ì¥):** \n{analysis['ethical_standard']}", unsafe_allow_html=False)
Â  Â  Â  Â  st.markdown(f"**2. ì—°ê³„ ì„±ì·¨ê¸°ì¤€ (AI ì£¼ì¥):** \n{analysis['achievement_std']}", unsafe_allow_html=False)
Â  Â  Â  Â  st.markdown(f"**3. ì£¼ìš” í•™ìŠµ ë‚´ìš©:** \n{analysis['learning_content']}", unsafe_allow_html=False)
Â  Â  Â  Â  st.write("---")


Â  Â  Â  Â  st.subheader("ğŸ“œ ìƒì„±ëœ ìˆ˜ì—… ë‚´ìš© í™•ì¸ (ë‹¨ê³„ë³„)")
Â  Â  Â  Â Â 
Â  Â  Â  Â  # íƒ­ ìƒì„±: total_stepsê°€ 0ì¼ ê²½ìš° ì‹¤í–‰ë˜ì§€ ì•Šë„ë¡ ë³´í˜¸
Â  Â  Â  Â  if st.session_state.total_steps > 0:
Â  Â  Â  Â  Â  Â  tabs = st.tabs([f"{i+1}ë‹¨ê³„" for i in range(st.session_state.total_steps)])
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  for i, tab in enumerate(tabs):
Â  Â  Â  Â  Â  Â  Â  Â  with tab:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if i < len(st.session_state.scenario):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  step = st.session_state.scenario[i]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.markdown(f"### ğŸ“– {i+1}ë‹¨ê³„ ì´ì•¼ê¸°")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.info(step['story'])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  c1, c2 = st.columns(2)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with c1: st.success(f"**ğŸ…°ï¸ ì„ íƒì§€:** {step['a']}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with c2: st.warning(f"**ğŸ…±ï¸ ì„ íƒì§€:** {step['b']}")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write("---")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  col_btn, col_img = st.columns([1, 2])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with col_btn:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.button(f"ğŸ¨ {i+1}ë‹¨ê³„ ê·¸ë¦¼ ê·¸ë¦¬ê¸°", key=f"gen_{i}"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("AI í™”ê°€ê°€ ê·¸ë¦¼ì„ ê·¸ë¦¬ëŠ” ì¤‘..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  url = generate_image(step['story'])
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if url:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # ì´ë¯¸ì§€ ë°°ì—´ í¬ê¸°ê°€ ì¶©ë¶„í•˜ë„ë¡ ë³´ì¥
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if i >= len(st.session_state.scenario_images):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.scenario_images.extend([None] * (i - len(st.session_state.scenario_images) + 1))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.scenario_images[i] = url
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with col_img:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if i < len(st.session_state.scenario_images) and st.session_state.scenario_images[i]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.image(st.session_state.scenario_images[i], width=400)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.error(f"âš ï¸ {i+1}ë‹¨ê³„ ì‹œë‚˜ë¦¬ì˜¤ ë°ì´í„°ê°€ ë¶ˆì™„ì „í•©ë‹ˆë‹¤.")


# ==========================================
# ğŸ™‹â€â™‚ï¸ í•™ìƒìš© í™”ë©´
# ==========================================
elif mode == "í•™ìƒìš© (ìˆ˜ì—… ì°¸ì—¬)":
Â  Â Â 
Â  Â  # [A] íŠœí† ë¦¬ì–¼ (ìƒëµ)
Â  Â  if not st.session_state.tutorial_complete:
Â  Â  Â  Â  st.header("ğŸ’ ì—°ìŠµ ì‹œê°„: í…ŒìŠ¤íŠ¸ ë´‡ê³¼ ì¹œí•´ì§€ê¸°")
Â  Â  Â  Â  st.progress((st.session_state.tutorial_step + 1) / 3, text=f"ì§„í–‰ë¥ : {st.session_state.tutorial_step + 1}/3 ë‹¨ê³„")

Â  Â  Â  Â  if st.session_state.tutorial_step == 0:
Â  Â  Â  Â  Â  Â  st.markdown("### 1ë‹¨ê³„: ë²„íŠ¼ ëˆ„ë¥´ê¸° ì—°ìŠµ")
Â  Â  Â  Â  Â  Â  with st.chat_message("assistant", avatar="ğŸ¤–"):
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown('<p style="font-size:1.2em;">ì•ˆë…•? ë‚˜ëŠ” AI ìœ¤ë¦¬ ì„ ìƒë‹˜ \'í…ŒìŠ¤íŠ¸ ë´‡\'ì´ì•¼! ğŸ‘‹</p>', unsafe_allow_html=True)Â 
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown('<p style="font-size:1.2em;">ë„ˆëŠ” ì–´ë–¤ ê³„ì ˆì„ ë” ì¢‹ì•„í•˜ë‹ˆ? ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì¤˜!</p>', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  col1, col2 = st.columns(2)
Â  Â  Â  Â  Â  Â  if col1.button("ğŸ…°ï¸ ë”ìš´ ì—¬ë¦„ì´ ì¢‹ì•„! ğŸ¦", use_container_width=True):
Â  Â  Â  Â  Â  Â  Â  Â  st.toast("ì˜í–ˆì–´! ì—¬ë¦„ì„ ì¢‹ì•„í•˜ëŠ”êµ¬ë‚˜.")
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.tutorial_step = 1; st.rerun()
Â  Â  Â  Â  Â  Â  if col2.button("ğŸ…±ï¸ ì¶”ìš´ ê²¨ìš¸ì´ ì¢‹ì•„! â˜ƒï¸", use_container_width=True):
Â  Â  Â  Â  Â  Â  Â  Â  st.toast("ì™„ë²½í•´! ê²¨ìš¸ì„ ì¢‹ì•„í•˜ëŠ”êµ¬ë‚˜.")
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.tutorial_step = 1; st.rerun()

Â  Â  Â  Â  elif st.session_state.tutorial_step == 1:
Â  Â  Â  Â  Â  Â  st.markdown("### 2ë‹¨ê³„: ê¸€ì ì“°ê¸° ì—°ìŠµ")
Â  Â  Â  Â  Â  Â  with st.chat_message("assistant", avatar="ğŸ¤–"):
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown('<p style="font-size:1.2em;">ë²„íŠ¼ ëˆ„ë¥´ê¸° ì„±ê³µ! ì°¸ ì˜í–ˆì–´. ğŸ‘</p>', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown('<p style="font-size:1.3em;">ì´ë²ˆì—ëŠ” ì•„ë˜ ì±„íŒ…ì°½ì— <b>\'ì•ˆë…•\'</b>ì´ë‚˜ <b>\'ë°˜ê°€ì›Œ\'</b>ë¼ê³  ì¸ì‚¬ë¥¼ ì¨ë³¼ë˜?</p>', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  if user_input := st.chat_input("ì—¬ê¸°ì— ì¸ì‚¬ë¥¼ ì ê³  ì—”í„°(Enter)ë¥¼ ì³ë´!"):
Â  Â  Â  Â  Â  Â  Â  Â  # ê°œì¸ì •ë³´ í•„í„°ë§ ì ìš©
Â  Â  Â  Â  Â  Â  Â  Â  safe_input = pii_filter(user_input)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # í•„í„°ë§ëœ ì•ˆì „í•œ ì…ë ¥ìœ¼ë¡œ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸ (íŠœí† ë¦¬ì–¼ì´ë¯€ë¡œ ë‹¨ìˆœ ì§„í–‰)
Â  Â  Â  Â  Â  Â  Â  Â  st.balloons(); st.session_state.tutorial_step = 2; st.rerun()

Â  Â  Â  Â  elif st.session_state.tutorial_step == 2:
Â  Â  Â  Â  Â  Â  st.markdown("### ì™„ë£Œ: ì¤€ë¹„ ë!")
Â  Â  Â  Â  Â  Â  with st.chat_message("assistant", avatar="ğŸ¤–"):
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown('<p style="font-size:1.2em;">ì™„ë²½í•´! ì´ì œ ìˆ˜ì—…ì„ ì‹œì‘í•  ì¤€ë¹„ê°€ ë‹¤ ëì–´. ğŸ‰</p>', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown('<p style="font-size:1.2em;">ì•„ë˜ ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì§„ì§œ ìˆ˜ì—…ì´ ì‹œì‘ë  ê±°ì•¼.</p>', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  if st.button("ğŸš€ ìˆ˜ì—… ì‹œì‘í•˜ê¸°", type="primary", use_container_width=True):
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.tutorial_complete = True; st.rerun()
Â  Â Â 
Â  Â  # [B] ë³¸ ìˆ˜ì—… ì§„í–‰
Â  Â  elif not st.session_state.lesson_complete:
Â  Â  Â  Â  st.header(f"ğŸ™‹â€â™‚ï¸ í•™ìŠµí•˜ê¸°: {st.session_state.topic}")

Â  Â  Â  Â  if not st.session_state.scenario or st.session_state.current_step >= len(st.session_state.scenario):
Â  Â  Â  Â  Â  Â  st.warning("ì„ ìƒë‹˜ì´ ì•„ì§ ìˆ˜ì—…ì„ ì•ˆ ë§Œë“¤ì—ˆê±°ë‚˜ ì‹œë‚˜ë¦¬ì˜¤ê°€ ëë‚¬ì–´! (êµì‚¬ìš© ëª¨ë“œì—ì„œ ë¨¼ì € ë§Œë“¤ì–´ì£¼ì„¸ìš”)")
Â  Â  Â  Â  Â  Â  if st.session_state.current_step >= st.session_state.total_steps and st.session_state.total_steps > 0:
Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.lesson_complete = True
Â  Â  Â  Â  Â  Â  Â  Â  Â st.rerun()
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  if st.button("ğŸ”„ ì—°ìŠµ ë‹¤ì‹œí•˜ê¸°", type="secondary"):
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.tutorial_complete = False; st.session_state.tutorial_step = 0; st.rerun()

Â  Â  Â  Â  Â  Â  idx = st.session_state.current_step
Â  Â  Â  Â  Â  Â  total_steps = st.session_state.total_steps
Â  Â  Â  Â  Â  Â  data = st.session_state.scenario[idx]
Â  Â  Â  Â  Â  Â  img = st.session_state.scenario_images[idx] if idx < len(st.session_state.scenario_images) else None

Â  Â  Â  Â  Â  Â  st.markdown(f"### ğŸ“– Part {idx + 1} / {total_steps}")
Â  Â  Â  Â  Â  Â  if img: st.image(img)
Â  Â  Â  Â  Â  Â  st.info(data['story'])

Â  Â  Â  Â  Â  Â  current_chat_log = st.session_state.chat_log
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if st.session_state.feedback_stage > 0:
Â  Â  Â  Â  Â  Â  Â  Â  for log in current_chat_log:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  role = "ë‚˜" if log["role"] == "user" else "í…ŒìŠ¤íŠ¸ ë´‡"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  avatar = "ğŸ™‹" if log["role"] == "user" else "ğŸ¤–"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.chat_message(log["role"], avatar=avatar):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.write(log['content'])

Â  Â  Â  Â  Â  Â  if st.session_state.feedback_stage == 0:
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown('<p style="font-size:1.3em;">ğŸ‘‡ ë„ˆì˜ ì„ íƒì€?</p>', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â  c1, c2 = st.columns(2)
Â  Â  Â  Â  Â  Â  Â  Â  if c1.button(f"ğŸ…°ï¸ {data['a']}", use_container_width=True):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.selected_choice = data['a']; st.session_state.feedback_stage = 1; st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  if c2.button(f"ğŸ…±ï¸ {data['b']}", use_container_width=True):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.selected_choice = data['b']; st.session_state.feedback_stage = 1; st.rerun()

Â  Â  Â  Â  Â  Â  elif st.session_state.feedback_stage == 1:
Â  Â  Â  Â  Â  Â  Â  Â  st.success(f"ì„ íƒ: {st.session_state.selected_choice}")
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown('<p style="font-size:1.3em;">ğŸ¤” ì™œ ê·¸ë ‡ê²Œ ì„ íƒí–ˆì–´?</p>', unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  with st.form("reason_form"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  reason_input = st.text_area("ì´ìœ ë¥¼ ì ì–´ì£¼ë©´ í…ŒìŠ¤íŠ¸ ë´‡ì´ í”¼ë“œë°±ì„ ì¤„ ê±°ì•¼!", placeholder="ì˜ˆ: ì™œëƒí•˜ë©´...")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  submit = st.form_submit_button("ì…ë ¥ ì™„ë£Œ ğŸ’Œ")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if submit:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not reason_input.strip():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("ì´ìœ ë¥¼ ê¼­ ì ì–´ì¤˜!")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # ê°œì¸ì •ë³´ í•„í„°ë§ ì ìš© (ì´ìœ  ì…ë ¥)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  safe_reason = pii_filter(reason_input)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.initial_reason = safe_reason
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.chat_log.append({"role": "user", "content": f"ì„ íƒ: {st.session_state.selected_choice}\nì´ìœ : {safe_reason}"})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("AI ì„ ìƒë‹˜ì´ ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì´ì•¼..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  feedback_steps = get_four_step_feedback(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.selected_choice, safe_reason, data['story'], st.session_state.rag_text
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.feedback_data = feedback_steps
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.feedback_stage = 2Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()

Â  Â  Â  Â  Â  Â  elif st.session_state.feedback_stage == 2:
Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.feedback_data and st.session_state.feedback_data[0]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if len(current_chat_log) == 1:Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.chat_log.append({"role": "assistant", "content": st.session_state.feedback_data[0]['content']})
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  if st.button("ë‹¤ìŒ í”¼ë“œë°± ë“£ê¸° â¡ï¸", type="primary"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.feedback_stage = 3
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()

Â  Â  Â  Â  Â  Â  elif st.session_state.feedback_stage == 3:
Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.feedback_data and st.session_state.feedback_data[1]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not any(log.get('content') == st.session_state.feedback_data[1]['content'] for log in current_chat_log):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â st.session_state.chat_log.append({"role": "assistant", "content": st.session_state.feedback_data[1]['content']})
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  with st.form("answer_form"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  answer_input = st.text_area("AI ì„ ìƒë‹˜ì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì¤˜!", placeholder="ë‚´ ìƒê°ì—ëŠ”...")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  submit_answer = st.form_submit_button("ë‹µë³€ ì™„ë£Œ ğŸ“¨")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if submit_answer:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not answer_input.strip():
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("ë‹µë³€ì„ ì…ë ¥í•´ì¤˜!")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # ê°œì¸ì •ë³´ í•„í„°ë§ ì ìš© (ì§ˆë¬¸ ë‹µë³€)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  safe_answer = pii_filter(answer_input)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.feedback_data[2]['content'] = safe_answerÂ 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.chat_log.append({"role": "user", "content": f"ë‹µë³€: {safe_answer}"})
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.feedback_stage = 4
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()

Â  Â  Â  Â  Â  Â  elif st.session_state.feedback_stage == 4:
Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.feedback_data and not st.session_state.feedback_data[3]['content']:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("AI ì„ ìƒë‹˜ì´ ìµœì¢… ë‹µë³€ì„ ì¤€ë¹„ ì¤‘ì´ì•¼..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final_feedback = generate_step_4_feedback(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.initial_reason,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.feedback_data[2]['content'],Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data['story'],Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.rag_text
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.feedback_data[3]['content'] = final_feedback
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.chat_log.append({"role": "assistant", "content": final_feedback})

Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.learning_records.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "step": idx + 1,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "choice": st.session_state.selected_choice,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "reason": st.session_state.initial_reason,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "answer_to_question": st.session_state.feedback_data[2]['content']
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  })
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  if st.button("ë‹¤ìŒ ì´ì•¼ê¸°ë¡œ ë„˜ì–´ê°€ê¸° â¡ï¸", type="primary"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if st.session_state.current_step < st.session_state.total_steps - 1:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.current_step += 1
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.feedback_stage = 0Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.feedback_data = None
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.selected_choice = None
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.chat_log = []
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.initial_reason = ""
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state.lesson_complete = True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.rerun()

Â  Â  # [C] í•™ìŠµ ì™„ë£ŒÂ 
Â  Â  else:
Â  Â  Â  Â  st.header("ğŸ‰ í•™ìŠµ ì™„ë£Œ! ì°¸ ì˜í–ˆì–´!")
Â  Â  Â  Â  st.markdown(f'<p style="font-size:1.2em;">ì˜¤ëŠ˜ì˜ <b>{st.session_state.total_steps}ë‹¨ê³„ ìœ¤ë¦¬ í•™ìŠµ</b>ì„ ëª¨ë‘ ë§ˆì³¤ì–´! ì •ë§ í›Œë¥­í•´! </p>', unsafe_allow_html=True)
Â  Â  Â  Â  st.markdown('<p style="font-size:1.1em;">AIê°€ ìƒì„±í•œ í•™ìŠµ ë‚´ìš©ì„ êµì‚¬ìš© í™”ë©´ì—ì„œ ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•´ë³´ì„¸ìš”.</p>', unsafe_allow_html=True)
Â  Â  Â  Â Â 
Â  Â  Â  Â  st.write("---")
Â  Â  Â  Â  st.write("### ğŸ‘£ í•™ìŠµ ê¸°ë¡ ìš”ì•½ (ì„ì‹œ)")
Â  Â  Â  Â  for record in st.session_state.learning_records:
Â  Â  Â  Â  Â  Â  Â st.write(f"**Step {record['step']}:** ì„ íƒ '{record['choice']}' (ì´ìœ : {record['reason']})")


Â  Â  Â  Â  if st.button("ğŸ”„ ì²˜ìŒë¶€í„° ë‹¤ì‹œ í•˜ê¸°", type="primary"):
Â  Â  Â  Â  Â  Â  st.session_state.lesson_complete = False
Â  Â  Â  Â  Â  Â  st.session_state.current_step = 0
Â  Â  Â  Â  Â  Â  st.session_state.chat_log = []
Â  Â  Â  Â  Â  Â  st.session_state.learning_records = []
Â  Â  Â  Â  Â  Â  st.session_state.scenario_analysis = None
Â  Â  Â  Â  Â  Â  st.session_state.feedback_stage = 0
Â  Â  Â  Â  Â  Â  st.session_state.feedback_data = None
Â  Â  Â  Â  Â  Â  st.session_state.total_steps = 0
Â  Â  Â  Â  Â  Â  st.rerun()
