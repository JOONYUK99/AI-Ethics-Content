# ===================================================================
# 1. í•„ìš”í•œ ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
# ===================================================================
!pip install -q streamlit google-generativeai pyngrok

# ===================================================================
# 2. Streamlit ì•± ì „ì²´ ì½”ë“œë¥¼ app.py íŒŒì¼ë¡œ ì €ì¥
# ===================================================================
app_code = r"""
import streamlit as st
import google.generativeai as genai
import re
import urllib.parse

# --- 1. AI í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ì •ì˜ ---
def get_model(model_name='gemini-pro'):
    return genai.GenerativeModel(model_name)

def generate_story_part(topic, history_summary=""):
    model = get_model()
    # <--- ìˆ˜ì •: ì´ì•¼ê¸°ë¥¼ 'ë°˜ë“œì‹œ 2ë¬¸ì¥'ìœ¼ë¡œ ë§¤ìš° ì§§ê²Œ ë§Œë“¤ë„ë¡ í”„ë¡¬í”„íŠ¸ ê°•í™”
    if not history_summary:
        prompt = f"'{topic}'ë¼ëŠ” ì£¼ì œë¡œ, 5~7ì„¸ ì•„ë™ì„ ìœ„í•œ AI ìœ¤ë¦¬ ë™í™”ë¥¼ ë§Œë“¤ì–´ì¤˜. ì´ì•¼ê¸°ì˜ 'ì²« ë¶€ë¶„'ì€ ë°˜ë“œì‹œ ê°„ê²°í•œ 2ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±í•˜ê³ , ì£¼ì¸ê³µì´ ì¤‘ìš”í•œ ê²°ì •ì„ ë‚´ë ¤ì•¼ í•˜ëŠ” ìˆœê°„ì—ì„œ ëë‚˜ì•¼ í•´."
    else:
        prompt = f"ë‹¤ìŒì€ ì§€ê¸ˆê¹Œì§€ ì§„í–‰ëœ ì´ì•¼ê¸°ì˜ ìš”ì•½ì´ì•¼: '{history_summary}'. ì´ ì´ì•¼ê¸°ì— ì´ì–´ì„œ, í•™ìƒì˜ ì„ íƒìœ¼ë¡œ ì¸í•´ ë²Œì–´ì§€ëŠ” 'ë‹¤ìŒ ì‚¬ê±´'ì„ ë°˜ë“œì‹œ ê°„ê²°í•œ 2ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜. ê·¸ë¦¬ê³  ì´ì•¼ê¸°ê°€ ë˜ ë‹¤ë¥¸ ì¤‘ìš”í•œ ê²°ì •ì„ ë‚´ë ¤ì•¼ í•˜ëŠ” ìˆœê°„ì—ì„œ ëë‚˜ë„ë¡ í•´ì¤˜."
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e: return f"ì´ì•¼ê¸° ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

def generate_image_keywords(story_part):
    model = get_model()
    # <--- ìˆ˜ì •: ì´ë¯¸ì§€ ê²€ìƒ‰ìš© í‚¤ì›Œë“œë¥¼ ë” ëª…í™•í•˜ê²Œ ì¶”ì¶œí•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
    prompt = f"ë‹¤ìŒ ë¬¸ì¥ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ì‚¬ë¬¼ì´ë‚˜ ê°ì •ì„ ë‚˜íƒ€ë‚´ëŠ” ì˜ì–´ ë‹¨ì–´ 2ê°œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ìš”ì•½í•´ì¤˜. ì˜ˆ: 'ìŠ¬í”ˆ ì•„ì´ê°€ ë¡œë´‡ê³¼ í•¨ê»˜ ìˆë‹¤' -> 'sad child, robot'\n\në¬¸ì¥: {story_part}"
    try:
        response = model.generate_content(prompt)
        keywords = [keyword.strip() for keyword in response.text.strip().replace('*','').split(',')]
        return ",".join(keywords)
    except Exception:
        return "AI,robot"

def generate_choices_for_story(story_part):
    model = get_model()
    prompt = f"ì•„ë˜ ì´ì•¼ê¸°ì˜ ë§ˆì§€ë§‰ ìƒí™©ì—ì„œ ì£¼ì¸ê³µì´ í•  ìˆ˜ ìˆëŠ”, ìœ¤ë¦¬ì ìœ¼ë¡œ ìƒë°˜ëœ ë‘ ê°€ì§€ ì„ íƒì§€ë¥¼ ì´ˆë“±í•™ìƒ ëˆˆë†’ì´ì— ë§ì¶°ì„œ ê°„ê²°í•˜ê²Œ ë§Œë“¤ì–´ì¤˜.\n[ì¶œë ¥ í˜•ì‹]\nA: [A ì„ íƒì§€ ë‚´ìš©]\nB: [B ì„ íƒì§€ ë‚´ìš©]\n\n--- ì´ì•¼ê¸° ---\n{story_part}"
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e: return f"ì„ íƒì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

def start_debate(current_story_log, choice):
    model = get_model()
    prompt = f"ë‹¹ì‹ ì€ í•™ìƒë“¤ì„ ì•„ì£¼ ì•„ë¼ëŠ” ë‹¤ì •í•œ AI ìœ¤ë¦¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì´ ë°©ê¸ˆ ë‚´ë¦° ì„ íƒ('{choice}')ì„ ì¹­ì°¬í•˜ê³ , ì™œ ê·¸ë ‡ê²Œ ìƒê°í–ˆëŠ”ì§€ ë¶€ë“œëŸ½ê²Œ ì²« ì§ˆë¬¸ì„ ë˜ì ¸ì£¼ì„¸ìš”."
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e: return f"í† ë¡  ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}"

def continue_debate(current_debate_history):
    model = get_model()
    prompt = f"ë‹¹ì‹ ì€ ë‹¤ì •í•œ AI ìœ¤ë¦¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì˜ ì´ì „ ë‹µë³€ì— ê³µê°í•˜ë©° í† ë¡ ì„ ì´ì–´ê°€ì£¼ì„¸ìš”. 'í˜¹ì‹œ ì´ëŸ° ì ì€ ì–´ë–¨ê¹Œìš”?' ì™€ ê°™ì´ ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¡œ ë°˜ëŒ€ ê´€ì ì´ë‚˜ ìƒˆë¡œìš´ ìƒê°í•´ë³¼ ê±°ë¦¬ë¥¼ ì§ˆë¬¸ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”.\n\n--- ì§€ê¸ˆê¹Œì§€ì˜ í† ë¡  ë‚´ìš© ---\n{current_debate_history}\n\nAI ì„ ìƒë‹˜ì˜ ë‹¤ìŒ ì§ˆë¬¸:"
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e: return f"í† ë¡  ì¤‘ ì˜¤ë¥˜: {e}"

def generate_conclusion(final_history):
    model = get_model()
    prompt = (
        "ë‹¤ìŒì€ í•œ í•™ìƒì´ AI ìœ¤ë¦¬ ë¬¸ì œì— ëŒ€í•´ ì´ 4ë²ˆì˜ ì„ íƒê³¼ í† ë¡ ì„ ê±°ì¹œ ì „ì²´ ê¸°ë¡ì…ë‹ˆë‹¤.\n\n"
        "# ë‹¹ì‹ ì˜ ì—­í• :\n"
        "1. í•™ìƒì˜ ê³ ë¯¼ ê³¼ì •ì„ ìš”ì•½í•˜ê³ , ë¹„íŒì  ì‚¬ê³  ëŠ¥ë ¥ì„ ë”°ëœ»í•˜ê²Œ ì¹­ì°¬í•´ì£¼ì„¸ìš”.\n"
        "2. ì´ ìœ¤ë¦¬ì  ë”œë ˆë§ˆë¥¼ ë§ˆì£¼í–ˆì„ ë•Œ, ì´ˆë“±í•™ìƒì´ í˜„ì‹¤ì—ì„œ ìƒê°í•´ ë³´ê±°ë‚˜ ì‹¤ì²œí•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ 'ëŒ€ì²˜ ë°©ë²•'ì´ë‚˜ 'ë§ˆìŒê°€ì§'ì„ í•œë‘ ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”.\n"
        "3. ì •ë‹µì€ ì—†ë‹¤ëŠ” ì ì„ ê°•ì¡°í•˜ë©°, í•™ìƒì˜ ì„±ì¥ì„ ê²©ë ¤í•˜ëŠ” ë©”ì‹œì§€ë¡œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.\n\n"
        f"--- ì „ì²´ ê¸°ë¡ ---\n{final_history}"
    )
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e: return f"ê²°ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

# --- 2. Streamlit ì•± UI ë° ë¡œì§ ---
st.set_page_config(page_title="AI ìœ¤ë¦¬ êµìœ¡", page_icon="âœ¨", layout="centered")
st.title("âœ¨ ì´ˆë“±í•™ìƒì„ ìœ„í•œ AI ìœ¤ë¦¬ êµìœ¡")

try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception:
    st.error("API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
    st.stop()

if 'stage' not in st.session_state:
    st.session_state.stage = 'start'
    st.session_state.full_log = ""
    st.session_state.current_story_part_log = ""
    st.session_state.choice_count = 0
    st.session_state.debate_turns = 0
    st.session_state.MAX_CHOICES = 4

def restart_lesson():
    st.session_state.stage = 'start'
    st.session_state.full_log = ""
    st.session_state.current_story_part_log = ""
    st.session_state.choice_count = 0
    st.session_state.debate_turns = 0

if st.session_state.stage == 'start':
    st.info("ì•ˆë…•í•˜ì„¸ìš”, ì¹œêµ¬ë“¤! AI ìœ¤ë¦¬ ë¬¸ì œì— ëŒ€í•´ í•¨ê»˜ ê³ ë¯¼í•´ë³´ëŠ” ìˆ˜ì—…ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•´ìš”.")
    topics = ["ììœ¨ì£¼í–‰ ìë™ì°¨ì˜ ìœ¤ë¦¬ì  ë”œë ˆë§ˆ", "ì¸ê³µì§€ëŠ¥ íŒì‚¬ì˜ ê³µì •ì„± ë¬¸ì œ", "AI ì°½ì‘ë¬¼ì˜ ì €ì‘ê¶Œ", "ê°œì¸ì •ë³´ë¥¼ í•™ìŠµí•œ AI ì±—ë´‡"]
    selected_topic = st.selectbox("ì˜¤ëŠ˜ íƒêµ¬í•´ë³¼ ì£¼ì œë¥¼ ì„ íƒí•´ë³¼ê¹Œìš”?", topics)
    if st.button("ìˆ˜ì—… ì‹œì‘í•˜ê¸°"):
        st.session_state.topic = selected_topic
        st.session_state.full_log = f"**ì£¼ì œ:** {st.session_state.topic}"
        st.session_state.stage = 'story'
        st.rerun()

elif st.session_state.stage == 'story':
    history_summary = st.session_state.full_log[-300:] if st.session_state.choice_count > 0 else ""
    st.markdown(f"### âœ¨ ì´ì•¼ê¸° #{st.session_state.choice_count + 1} âœ¨")
    
    with st.spinner(f"AIê°€ ì´ì•¼ê¸° #{st.session_state.choice_count + 1}ì„(ë¥¼) ë§Œë“¤ê³  ìˆì–´ìš”..."):
        story_part = generate_story_part(st.session_state.topic, history_summary)
        keywords = generate_image_keywords(story_part)
        choices_text = generate_choices_for_story(story_part)
    
    # <--- ìˆ˜ì •: ì•ˆì •ì ì¸ placeholder ì´ë¯¸ì§€ ì„œë¹„ìŠ¤ë¡œ êµì²´í•˜ê³ , ì˜¤ë¥˜ ì²˜ë¦¬ ì¶”ê°€
    try:
        encoded_keywords = urllib.parse.quote(keywords)
        st.image(f"https://placehold.co/600x300/E8E8E8/313131?text={encoded_keywords}", caption=f"AIê°€ ìƒê°í•œ ì´ë¯¸ì§€: {keywords}")
    except Exception:
        st.info("ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”.")
        
    st.write(story_part)
    st.session_state.current_story_part_log = f"### ì´ì•¼ê¸° #{st.session_state.choice_count + 1}\n{story_part}"
    
    try:
        match_a = re.search(r"A:\s*(.*)", choices_text, re.DOTALL)
        match_b = re.search(r"B:\s*(.*)", choices_text, re.DOTALL)
        if not (match_a and match_b): raise ValueError("ì„ íƒì§€ í˜•ì‹ ì˜¤ë¥˜")
        choice_a_text = match_a.group(1).strip()
        choice_b_text = match_b.group(1).strip()
        st.info("ì, ì´ì œ ì–´ë–¤ ì„ íƒì„ í•´ë³¼ê¹Œìš”?")
        col1, col2 = st.columns(2)
        if col1.button(f"A: {choice_a_text}", use_container_width=True, key=f"A_{st.session_state.choice_count}"):
            st.session_state.current_story_part_log += f"\n\n**>> ë‚˜ì˜ ì„ íƒ:** {choice_a_text}"; st.session_state.stage = 'debate'; st.rerun()
        if col2.button(f"B: {choice_b_text}", use_container_width=True, key=f"B_{st.session_state.choice_count}"):
            st.session_state.current_story_part_log += f"\n\n**>> ë‚˜ì˜ ì„ íƒ:** {choice_b_text}"; st.session_state.stage = 'debate'; st.rerun()
    except Exception as e:
        st.error("ì„ íƒì§€ë¥¼ ë§Œë“œëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”. AIì˜ ë‹µë³€ í˜•ì‹ì´ ë‹¬ëì„ ìˆ˜ ìˆì–´ìš”.")
        if st.button("ì´ì•¼ê¸° ë‹¤ì‹œ ë§Œë“¤ê¸°"): st.rerun()

elif st.session_state.stage == 'debate':
    st.markdown(f"### ì´ì•¼ê¸° #{st.session_state.choice_count + 1} í† ë¡ ")
    log_parts = st.session_state.current_story_part_log.split('\n\n')
    for p in log_parts:
        if p.startswith("**>> ë‚˜ì˜ ì„ íƒ"): st.chat_message("user").write(p.replace("**>> ë‚˜ì˜ ì„ íƒ:**",""))
        elif p.startswith("**AI ì„ ìƒë‹˜:**"): st.chat_message("assistant").write(p.replace("**AI ì„ ìƒë‹˜:**",""))
        elif p.startswith("**ë‚˜ (ì˜ê²¬"): st.chat_message("user").write(p)
        else: st.write(p)
    
    if st.session_state.debate_turns == 0:
        with st.chat_message("assistant"):
            with st.spinner("AI ì„ ìƒë‹˜ì´ ì§ˆë¬¸ì„ ì¤€ë¹„í•˜ê³  ìˆì–´ìš”..."):
                question = start_debate(st.session_state.current_story_part_log, st.session_state.current_story_part_log.split('>> ë‚˜ì˜ ì„ íƒ:')[-1].strip())
                st.session_state.current_story_part_log += f"\n\n**AI ì„ ìƒë‹˜:** {question}"
                st.session_state.debate_turns = 1; st.rerun()
    elif st.session_state.debate_turns == 1:
        if reply := st.chat_input("ì²« ë²ˆì§¸ ì˜ê²¬ì„ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”:"):
            st.session_state.current_story_part_log += f"\n\n**ë‚˜ (ì˜ê²¬ 1):** {reply}"; st.session_state.debate_turns = 2; st.rerun()
    elif st.session_state.debate_turns == 2:
        with st.chat_message("assistant"):
            with st.spinner("AI ì„ ìƒë‹˜ì´ ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒê° ì¤‘ì´ì—ìš”..."):
                question = continue_debate(st.session_state.current_story_part_log)
                st.session_state.current_story_part_log += f"\n\n**AI ì„ ìƒë‹˜:** {question}"; st.session_state.debate_turns = 3; st.rerun()
    elif st.session_state.debate_turns == 3:
        if reply := st.chat_input("ë‘ ë²ˆì§¸ ì˜ê²¬ì„ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”:"):
            st.session_state.current_story_part_log += f"\n\n**ë‚˜ (ì˜ê²¬ 2):** {reply}"; st.session_state.debate_turns = 4; st.rerun()
    elif st.session_state.debate_turns == 4:
        st.info("í† ë¡ ì´ ì™„ë£Œë˜ì—ˆì–´ìš”. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°€ìš”!")
        st.session_state.full_log += f"\n\n---\n\n{st.session_state.current_story_part_log}"
        st.session_state.choice_count += 1
        if st.button("ë‹¤ìŒ ì´ì•¼ê¸°ë¡œ" if st.session_state.choice_count < st.session_state.MAX_CHOICES else "ìµœì¢… ì •ë¦¬ ë³´ê¸°"):
            st.session_state.debate_turns = 0; st.session_state.current_story_part_log = ""
            if st.session_state.choice_count >= st.session_state.MAX_CHOICES:
                st.session_state.stage = 'conclusion'
            else:
                st.session_state.stage = 'story'
            st.rerun()

elif st.session_state.stage == 'conclusion':
    st.markdown("### ğŸ“š ìš°ë¦¬ì˜ ì „ì²´ ì´ì•¼ê¸°ì™€ ê³ ë¯¼ ğŸ“š")
    st.markdown(st.session_state.full_log, unsafe_allow_html=True)
    st.markdown("---")
    with st.spinner("AI ì„ ìƒë‹˜ì´ ìš°ë¦¬ì˜ ë©‹ì§„ ì—¬ì •ì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”..."):
        conclusion = generate_conclusion(st.session_state.full_log)
        st.balloons(); st.success("ëª¨ë“  ì´ì•¼ê¸°ê°€ ëë‚¬ì–´ìš”! ì •ë§ ìˆ˜ê³  ë§ì•˜ì–´ìš”!")
        st.markdown("---")
        st.markdown("### âœ¨ AI ì„ ìƒë‹˜ì˜ ìµœì¢… ì •ë¦¬ ë° ëŒ€ì²˜ë²• âœ¨")
        st.write(conclusion)
    if st.button("ìƒˆë¡œìš´ ì£¼ì œë¡œ ë‹¤ì‹œ ì‹œì‘í•˜ê¸°"):
        restart_lesson(); st.rerun()
"""
with open("app.py", "w", encoding="utf-8") as f:
    f.write(app_code)

# ===================================================================
# 3. Colabì— API í‚¤ë¥¼ ì„¤ì •í•˜ê³  Streamlit ì•± ì‹¤í–‰
# ===================================================================
from google.colab import userdata
from pyngrok import ngrok
import os

try:
    ngrok_token = userdata.get('NGROK_AUTH_TOKEN')
    api_key = userdata.get('GOOGLE_API_KEY')
    !ngrok authtoken {ngrok_token}
    secrets_dir = os.path.expanduser('~/.streamlit')
    os.makedirs(secrets_dir, exist_ok=True)
    with open(os.path.join(secrets_dir, "secrets.toml"), "w") as f:
        f.write(f'GOOGLE_API_KEY = "{api_key}"\n')
except (userdata.SecretNotFoundError, NameError):
    print("â—ï¸ Colab Secretsì— 'NGROK_AUTH_TOKEN'ê³¼ 'GOOGLE_API_KEY'ë¥¼ ëª¨ë‘ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
    raise SystemExit()

ngrok.kill()
try:
    public_url = ngrok.connect(8501)
    print("ğŸ‰ ì±—ë´‡ ì•±ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤! ì•„ë˜ ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ì ‘ì†í•˜ì„¸ìš”:")
    print(public_url)
except Exception as e:
    print(f"â—ï¸ ngrok ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    raise SystemExit()

!streamlit run app.py --logger.level=error
