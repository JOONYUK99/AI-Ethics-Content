import streamlit as st
from openai import OpenAI
import json
import base64
import requests
from datetime import datetime
import hashlib
import numpy as np
from pathlib import Path

# =========================================================
# 1) Page config
# =========================================================
st.set_page_config(page_title="AI ìœ¤ë¦¬ êµìœ¡ (RAG)", page_icon="ğŸ¤–", layout="wide")

# =========================================================
# 2) Model configuration
# =========================================================
TEXT_MODEL = "gpt-4o"
IMAGE_MODEL = "dall-e-3"
EMBED_MODEL = "text-embedding-3-small"

# âœ… ì•± ë‚´ë¶€(reference.txt)ë§Œ ì°¸ê³ í•˜ëŠ” RAG (í•­ìƒ ON)
REFERENCE_PATH = "reference.txt"   # repo ë£¨íŠ¸ì— reference.txt ë‘ê¸°
RAG_TOP_K = 4                      # ê³ ì • (UIë¡œ ë…¸ì¶œ ì•ˆ í•¨)

# âœ… ì´ë¯¸ì§€ì— ê¸€ì(ì˜ì–´/í•œê¸€ í¬í•¨) ë‚˜ì˜¤ì§€ ì•Šê²Œ ê°•ì œ
NO_TEXT_IMAGE_PREFIX = (
    "Minimalist, flat design illustration, educational context. "
    "ABSOLUTELY NO TEXT: no words, no letters, no numbers, no captions, no subtitles, "
    "no watermarks, no logos, no signs, no posters with writing. "
    "No text-like shapes. Only ê·¸ë¦¼/ë„í˜•/ì‚¬ë¬¼. "
)

# =========================================================
# 3) OpenAI client
# =========================================================
try:
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
except Exception:
    st.error("âš ï¸ API í‚¤ ì˜¤ë¥˜: secrets.tomlì„ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# =========================================================
# 4) System persona (dry / bullet style)
# =========================================================
SYSTEM_PERSONA = """
ë‹¹ì‹ ì€ AI ìœ¤ë¦¬ íŠœí„°ì…ë‹ˆë‹¤.
ê°ì •ì„ ë°°ì œí•˜ê³ , ì§ˆë¬¸ì— ëŒ€í•´ í•µì‹¬ë§Œ 'ë‹¨ë‹µí˜•' í˜¹ì€ 'ê°œì¡°ì‹'ìœ¼ë¡œ ëŒ€ë‹µí•˜ì„¸ìš”.
ì¸ì‚¬ë§(ì•ˆë…•, ë°˜ê°€ì›Œ)ê³¼ ì„œìˆ ì–´(~ì…ë‹ˆë‹¤, ~í•´ìš”)ë¥¼ ìƒëµí•˜ì„¸ìš”.
ì˜ˆì‹œ: "ì„ íƒ Aì˜ ìœ¤ë¦¬ì  ë¬¸ì œëŠ” ë¬´ì—‡ì¸ê°€?" -> "ë‹¤ìˆ˜ì˜ ì´ìµì„ ìœ„í•´ ì†Œìˆ˜ë¥¼ í¬ìƒí•˜ëŠ” ê³µë¦¬ì£¼ì˜ì  ë”œë ˆë§ˆ ë°œìƒ."
"""

# =========================================================
# 5) Helpers
# =========================================================
def now_str():
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

def _clip(s: str, max_len: int = 1600) -> str:
    s = (s or "").strip()
    return s[:max_len] + ("â€¦" if len(s) > max_len else "")

def safe_json_load(s: str):
    if not s:
        return None
    s = s.strip()
    try:
        return json.loads(s)
    except Exception:
        try:
            a = s.find("{")
            b = s.rfind("}")
            if a != -1 and b != -1 and b > a:
                return json.loads(s[a:b + 1])
        except Exception:
            return None
    return None

def ask_gpt_json_object(prompt: str) -> dict:
    try:
        resp = client.chat.completions.create(
            model=TEXT_MODEL,
            messages=[
                {"role": "system", "content": SYSTEM_PERSONA},
                {"role": "user", "content": prompt},
            ],
            response_format={"type": "json_object"},
            temperature=0.5,
        )
        raw = (resp.choices[0].message.content or "").strip()
        data = safe_json_load(raw)
        return data if isinstance(data, dict) else {}
    except Exception:
        return {}

def normalize_steps(raw_steps):
    """
    Supports:
    - legacy dilemma steps: {"story","choice_a","choice_b"}
    - mixed steps:
      - image_task: {"type":"image_task","story","prompt_goal","question"}
      - dilemma: {"type":"dilemma","story","choice_a","choice_b"}
      - discussion: {"type":"discussion","story","question"}
    """
    if not isinstance(raw_steps, list):
        return []

    steps = []
    for s in raw_steps:
        if not isinstance(s, dict):
            continue

        # legacy dilemma -> convert
        if "type" not in s and all(k in s for k in ("story", "choice_a", "choice_b")):
            steps.append({
                "type": "dilemma",
                "story": str(s.get("story", "")).strip(),
                "choice_a": str(s.get("choice_a", "")).strip(),
                "choice_b": str(s.get("choice_b", "")).strip(),
            })
            continue

        t = str(s.get("type", "")).strip().lower()
        story = str(s.get("story", "")).strip()

        if t == "image_task":
            steps.append({
                "type": "image_task",
                "story": story,
                "prompt_goal": str(s.get("prompt_goal", "")).strip(),
                "prompt_hint": str(s.get("prompt_hint", "")).strip(),
                "question": str(s.get("question", "")).strip(),
            })
        elif t == "discussion":
            steps.append({
                "type": "discussion",
                "story": story,
                "question": str(s.get("question", "")).strip(),
            })
        else:
            steps.append({
                "type": "dilemma",
                "story": story,
                "choice_a": str(s.get("choice_a", "")).strip(),
                "choice_b": str(s.get("choice_b", "")).strip(),
            })

    return steps

def normalize_analysis(analysis_any):
    if isinstance(analysis_any, dict):
        return {
            "ethics_standards": analysis_any.get("ethics_standards", []),
            "curriculum_alignment": analysis_any.get("curriculum_alignment", []),
            "lesson_content": analysis_any.get("lesson_content", []),
        }
    if isinstance(analysis_any, str) and analysis_any.strip():
        return {"ethics_standards": [], "curriculum_alignment": [], "lesson_content": [analysis_any.strip()]}
    return {"ethics_standards": [], "curriculum_alignment": [], "lesson_content": []}

def render_bullets(items):
    if not items:
        st.caption("ë‚´ìš© ì—†ìŒ.")
        return
    if isinstance(items, list):
        for x in items:
            st.write(f"- {str(x)}")
        return
    st.write(str(items))

def render_analysis_box(analysis_dict):
    a = normalize_analysis(analysis_dict)
    st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
    c1, c2, c3 = st.columns(3)
    with c1:
        st.markdown("### ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬ê¸°ì¤€")
        render_bullets(a.get("ethics_standards", []))
    with c2:
        st.markdown("### ì—°ê³„ êµìœ¡ê³¼ì •")
        render_bullets(a.get("curriculum_alignment", []))
    with c3:
        st.markdown("### ìˆ˜ì—… ë‚´ìš©")
        render_bullets(a.get("lesson_content", []))

# =========================================================
# 6) RAG (internal reference.txt)
# =========================================================
def sha256_text(s: str) -> str:
    return hashlib.sha256((s or "").encode("utf-8")).hexdigest()

def chunk_text(text: str, max_chars: int = 900, overlap: int = 160):
    text = (text or "").replace("\r\n", "\n").strip()
    if not text:
        return []

    # Split on blank lines first
    parts = []
    buf = []
    for line in text.split("\n"):
        if line.strip() == "":
            if buf:
                parts.append("\n".join(buf).strip())
                buf = []
        else:
            buf.append(line)
    if buf:
        parts.append("\n".join(buf).strip())

    # Re-pack into chunks
    chunks = []
    current = ""
    for p in parts:
        if len(current) + len(p) + 2 <= max_chars:
            current = (current + "\n\n" + p).strip() if current else p
        else:
            if current:
                chunks.append(current)
            if len(p) > max_chars:
                start = 0
                while start < len(p):
                    end = min(len(p), start + max_chars)
                    chunks.append(p[start:end])
                    start = max(0, end - overlap)
                current = ""
            else:
                current = p
    if current:
        chunks.append(current)

    # Add overlap
    final = []
    for i, c in enumerate(chunks):
        if i == 0:
            final.append(c)
        else:
            tail = chunks[i - 1][-overlap:] if overlap > 0 else ""
            merged = (tail + "\n" + c).strip() if tail else c
            final.append(merged)
    return [x.strip() for x in final if x.strip()]

@st.cache_data(show_spinner=False)
def load_reference_text_cached(path_str: str, mtime: float) -> str:
    p = Path(path_str)
    if not p.exists():
        return ""
    txt = p.read_text(encoding="utf-8", errors="ignore")
    if len(txt) > 1_200_000:
        txt = txt[:1_200_000]
    return txt

@st.cache_data(show_spinner=False)
def build_rag_index_cached(path_str: str, embed_model: str, mtime: float):
    txt = load_reference_text_cached(path_str, mtime)
    if not txt.strip():
        return {"chunks": [], "emb": None, "norms": None, "content_hash": ""}

    content_hash = sha256_text(txt)
    chunks = chunk_text(txt, max_chars=900, overlap=160)
    if not chunks:
        return {"chunks": [], "emb": None, "norms": None, "content_hash": content_hash}

    try:
        resp = client.embeddings.create(model=embed_model, input=chunks)
        vecs = [d.embedding for d in resp.data]
        emb = np.array(vecs, dtype=np.float32)
        norms = np.linalg.norm(emb, axis=1) + 1e-8
        return {"chunks": chunks, "emb": emb, "norms": norms, "content_hash": content_hash}
    except Exception:
        return {"chunks": chunks, "emb": None, "norms": None, "content_hash": content_hash}

def get_rag_index():
    p = Path(REFERENCE_PATH)
    if not p.exists():
        return None
    mtime = p.stat().st_mtime
    return build_rag_index_cached(REFERENCE_PATH, EMBED_MODEL, mtime)

def rag_retrieve(query: str, index: dict, top_k: int = RAG_TOP_K) -> str:
    query = (query or "").strip()
    if not query or not index or not index.get("chunks") or index.get("emb") is None:
        return ""
    try:
        q = client.embeddings.create(model=EMBED_MODEL, input=query).data[0].embedding
        qv = np.array(q, dtype=np.float32)
        qn = np.linalg.norm(qv) + 1e-8

        emb = index["emb"]
        norms = index["norms"]
        sims = (emb @ qv) / (norms * qn)
        k = max(1, min(int(top_k), len(index["chunks"])))
        top_idx = np.argsort(-sims)[:k].tolist()

        ctx = "\n\n---\n\n".join(index["chunks"][i].strip() for i in top_idx)
        return _clip(ctx, 2200)
    except Exception:
        return ""

# =========================================================
# 7) Lesson generation (RAG-applied)
# =========================================================
def generate_scenario_3steps(topic: str, rag_ctx: str = "") -> dict:
    prompt = f"""
ì£¼ì œ '{topic}'ì˜ 3ë‹¨ê³„ ë”œë ˆë§ˆ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ìƒì„±.
ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥.
ìµœìƒìœ„ í‚¤: scenario (ë¦¬ìŠ¤íŠ¸, ê¸¸ì´=3)
ê° ì›ì†Œ í‚¤: story, choice_a, choice_b

[ì™¸ë¶€ ì°¸ê³ ìë£Œ(reference.txt ë°œì·Œ)]
{rag_ctx if rag_ctx else "- ì—†ìŒ"}

ì¡°ê±´:
- ì´ˆë“± ê³ í•™ë…„ ìˆ˜ì¤€
- ê³¼ë„í•œ í­ë ¥/ê³µí¬ ë°°ì œ
- ì„ íƒ A/BëŠ” ì„œë¡œ ë‹¤ë¥¸ ê°€ì¹˜ê°€ ì¶©ëŒí•˜ë„ë¡
"""
    data = ask_gpt_json_object(prompt)
    return {"scenario": normalize_steps(data.get("scenario", []))}

def generate_mixed_lesson(topic: str, rag_ctx: str = "") -> tuple[str, dict, dict, str]:
    prompt = f"""
ì´ˆë“± ê³ í•™ë…„ ëŒ€ìƒ AI ìœ¤ë¦¬ ìˆ˜ì—…(í˜¼í•©í˜•) ìƒì„±.
ì£¼ì œ: '{topic}'

[ì™¸ë¶€ ì°¸ê³ ìë£Œ(reference.txt ë°œì·Œ)]
{rag_ctx if rag_ctx else "- ì—†ìŒ"}

ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥.
í‚¤:
- topic: ë¬¸ìì—´
- analysis: ê°ì²´
  - ethics_standards: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
  - curriculum_alignment: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
  - lesson_content: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
- teacher_guide: ê°œì¡°ì‹ ë¬¸ìì—´(ë„ì…-í™œë™-í† ë¡ -ì •ë¦¬, êµì‚¬ìš© ì§ˆë¬¸ 3ê°œ, ê°„ë‹¨ í‰ê°€ ê¸°ì¤€ í¬í•¨)
- scenario: ë¦¬ìŠ¤íŠ¸(ê¸¸ì´ 4~5)

scenarioì˜ ê° ë‹¨ê³„ type:
type="image_task" | "dilemma" | "discussion"

ê·œì¹™:
- ìµœì†Œ 1ê°œëŠ” image_task í¬í•¨.
- image_task í‚¤: type, story, prompt_goal, question (+prompt_hint ì„ íƒ)
- dilemma í‚¤: type, story, choice_a, choice_b
- discussion í‚¤: type, story, question
- í­ë ¥/ê³µí¬ ë°°ì œ
- ë²• ì¡°í•­ ë‹¨ì • ê¸ˆì§€(ì•½ê´€/í•™êµ ê·œì¹™ í™•ì¸ í•„ìš” ê´€ì )
"""
    data = ask_gpt_json_object(prompt)

    t = str(data.get("topic", topic)).strip() or topic
    analysis = normalize_analysis(data.get("analysis", {}))
    guide = str(data.get("teacher_guide", "")).strip()
    steps = normalize_steps(data.get("scenario", []))

    if not any(s.get("type") == "image_task" for s in steps):
        steps = ([{
            "type": "image_task",
            "story": "í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•´ ìˆ˜ì—… ì£¼ì œì™€ ê´€ë ¨ëœ ì´ë¯¸ì§€ë¥¼ 1ì¥ ìƒì„±í•œë‹¤.",
            "prompt_goal": "ìˆ˜ì—… ì£¼ì œë¥¼ ìƒì§•í•˜ëŠ” ê·¸ë¦¼ ë§Œë“¤ê¸°",
            "prompt_hint": "ì‚¬ëŒ/ì‚¬ë¬¼/ë°°ê²½ 3ìš”ì†Œ(ê¸€ì ì—†ìŒ)",
            "question": "ì´ í™œë™ì—ì„œ ì¤‘ìš”í•œ ì  1ê°œë¥¼ ë§í•˜ë¼.",
        }] + steps)

    return t, analysis, {"scenario": steps}, guide

def generate_copyright_lesson(rag_ctx: str = "") -> tuple[str, dict, dict, str]:
    prompt = f"""
ì´ˆë“± ê³ í•™ë…„ ëŒ€ìƒ 'ì €ì‘ê¶Œ + ìƒì„±í˜• AI ì´ë¯¸ì§€' ìˆ˜ì—… ìƒì„±.

[ì™¸ë¶€ ì°¸ê³ ìë£Œ(reference.txt ë°œì·Œ)]
{rag_ctx if rag_ctx else "- ì—†ìŒ"}

ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥.
í‚¤:
- topic
- analysis: ê°ì²´
  - ethics_standards: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
  - curriculum_alignment: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
  - lesson_content: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸
- teacher_guide
- scenario: ë¦¬ìŠ¤íŠ¸(ê¸¸ì´ 4)

í•„ìˆ˜ êµ¬ì„±(ìˆœì„œ ì¤‘ìš”):
1) image_task 1ê°œ (ì²« ë‹¨ê³„)
   - í•™ìƒì´ í”„ë¡¬í”„íŠ¸ë¥¼ ì§ì ‘ ì…ë ¥í•´ ì´ë¯¸ì§€ë¥¼ 1ì¥ ìƒì„±í•˜ëŠ” ìƒí™©
   - ì§ˆë¬¸: "ì´ ì´ë¯¸ì§€ì˜ ì €ì‘ê¶Œ/ì‚¬ìš©ê¶Œì€ ëˆ„êµ¬ì—ê²Œ ìˆëŠ”ê°€?"
2) dilemma 2ê°œ
   - ì‚¬ìš©/ìˆ˜ì • ìš”ì²­(í—ˆë½/ì¶œì²˜í‘œê¸°/ìš©ë„ ì œí•œ)
   - ê³µìœ  í™•ì¥ ë˜ëŠ” ìƒì—…ì  ì´ìš©(ì•½ê´€/ê·œì • í™•ì¸, ëŒ€ì²´ìë£Œ ê³ ë ¤)
3) discussion 1ê°œ (ë§ˆì§€ë§‰)
   - 'ìš°ë¦¬ ë°˜ ê·œì¹™' ë§Œë“¤ê¸° ì§ˆë¬¸

ê·œì¹™:
- í­ë ¥/ê³µí¬ ë°°ì œ
- ì„ íƒì§€ëŠ” ê°€ì¹˜ ì¶©ëŒ ëª…í™•
- ë²• ì¡°í•­ ë‹¨ì • ê¸ˆì§€(êµ­ê°€/í”Œë«í¼/ì•½ê´€/í•™êµ ê·œì¹™ í™•ì¸ í•„ìš” ê´€ì )
"""
    data = ask_gpt_json_object(prompt)

    topic = str(data.get("topic", "ì €ì‘ê¶Œê³¼ ìƒì„±í˜• AI ì´ë¯¸ì§€: ê¶Œë¦¬ëŠ” ëˆ„êµ¬ì—ê²Œ?")).strip()
    analysis = normalize_analysis(data.get("analysis", {}))
    guide = str(data.get("teacher_guide", "")).strip()
    steps = normalize_steps(data.get("scenario", []))

    if len(steps) < 4 or steps[0].get("type") != "image_task":
        steps = [
            {
                "type": "image_task",
                "story": "í•™êµ ê³¼ì œë¡œ ë°œí‘œìë£Œ í‘œì§€ ê·¸ë¦¼ì´ í•„ìš”í•˜ë‹¤. ë„ˆëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì§ì ‘ ì…ë ¥í•´ AIë¡œ ì´ë¯¸ì§€ë¥¼ 1ì¥ ìƒì„±í–ˆë‹¤. ì¹œêµ¬ê°€ ë¬»ëŠ”ë‹¤: 'ì´ ì´ë¯¸ì§€ì˜ ì €ì‘ê¶Œ(ì‚¬ìš© ê¶Œí•œ)ì€ ëˆ„êµ¬ì—ê²Œ ìˆì–´?'",
                "prompt_goal": "ë°œí‘œìë£Œ í‘œì§€ì— ì“¸ â€˜í•™ìŠµ/í•™êµâ€™ ëŠë‚Œ ê·¸ë¦¼",
                "prompt_hint": "ì‚¬ëŒ/ì‚¬ë¬¼/ë°°ê²½ 3ìš”ì†Œ(ê¸€ì ì—†ìŒ)",
                "question": "ì´ ì´ë¯¸ì§€ì˜ ê¶Œë¦¬Â·ì±…ì„ì€ ëˆ„êµ¬ì—ê²Œ ìˆë‹¤ê³  ìƒê°í•˜ëŠ”ê°€? ì´ìœ  1ê°œ",
            },
            {
                "type": "dilemma",
                "story": "ì¹œêµ¬ê°€ ê·¸ ì´ë¯¸ì§€ë¥¼ ìê¸° ë°œí‘œ ìë£Œì— ì“°ê³  ì‹¶ë‹¤ê³  í•œë‹¤. ì¼ë¶€ ìˆ˜ì •ë„ í•˜ê² ë‹¤ê³  í•œë‹¤. í—ˆë½/ì¶œì²˜í‘œê¸°/ìš©ë„ ì œí•œì„ ì–´ë–»ê²Œ í• ê¹Œ?",
                "choice_a": "ì¡°ê±´ë¶€ í—ˆë½: ì¶œì²˜(ë„êµ¬/í”„ë¡¬í”„íŠ¸) í‘œê¸° + ë°œí‘œìš©ìœ¼ë¡œë§Œ í—ˆë½",
                "choice_b": "í—ˆë½í•˜ì§€ ì•ŠìŒ: ë‹¤ë¥¸ ì‚¬ëŒì´ ì‚¬ìš©/ìˆ˜ì •í•˜ë©´ ì•ˆ ëœë‹¤ê³  ë§í•¨",
            },
            {
                "type": "dilemma",
                "story": "ì¶•ì œ ë•Œ ê·¸ ì´ë¯¸ì§€ë¥¼ ìŠ¤í‹°ì»¤ë¡œ ë§Œë“¤ì–´ íŒë§¤í•˜ìëŠ” ì˜ê²¬ì´ ë‚˜ì™”ë‹¤. ìƒì—…ì  ì´ìš© ê°€ëŠ¥ ì—¬ë¶€(ì•½ê´€/í•™êµ ê·œì¹™)ê°€ í™•ì‹¤ì¹˜ ì•Šë‹¤.",
                "choice_a": "ë°”ë¡œ íŒë§¤í•œë‹¤: ìš°ë¦¬ê°€ ë§Œë“¤ì—ˆìœ¼ë‹ˆ ë¬¸ì œ ì—†ë‹¤ê³  íŒë‹¨",
                "choice_b": "íŒë§¤ ë³´ë¥˜: ì•½ê´€/ê·œì¹™ í™•ì¸ í›„, í•„ìš”í•˜ë©´ ì§ì ‘ ì œì‘/ë¼ì´ì„ ìŠ¤ ëª…í™• ìë£Œë¡œ ëŒ€ì²´",
            },
            {
                "type": "discussion",
                "story": "ì •ë¦¬ í† ë¡ : ì•ìœ¼ë¡œ ìš°ë¦¬ ë°˜ì—ì„œ AIë¡œ ë§Œë“  ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•  ë•Œ ì§€ì¼œì•¼ í•  ê·œì¹™ì„ ì •í•œë‹¤.",
                "question": "â€˜í—ˆë½â€™, â€˜ì¶œì²˜í‘œê¸°â€™, â€˜ì‚¬ìš© ëª©ì (ê³¼ì œ/ê³µìœ /íŒë§¤)â€™ ê¸°ì¤€ìœ¼ë¡œ ìš°ë¦¬ ë°˜ ê·œì¹™ 3ê°€ì§€ë¥¼ ì ì–´ë¼.",
            },
        ]

    if not guide:
        guide = "\n".join([
            "ìˆ˜ì—… íë¦„(ì˜ˆì‹œ)",
            "1) ë„ì…: â€˜AIê°€ ë§Œë“  ê·¸ë¦¼ì˜ ê¶Œë¦¬ëŠ” ëˆ„êµ¬ì—ê²Œ?â€™",
            "2) í™œë™: í”„ë¡¬í”„íŠ¸ ì…ë ¥ â†’ ì´ë¯¸ì§€ 1ì¥ ìƒì„±(ê¸€ì ì—†ëŠ” ê·¸ë¦¼ë§Œ)",
            "3) í† ë¡ : ì„ íƒí˜• ë”œë ˆë§ˆ + ì •ë¦¬ í† ë¡ (ìš°ë¦¬ ë°˜ ê·œì¹™)",
            "4) ì •ë¦¬: ë‹¤ìŒ í–‰ë™ 1ê°œ(ì•½ê´€ í™•ì¸/ì¶œì²˜í‘œê¸°/í—ˆë½ ë°›ê¸°)",
        ])

    return topic, analysis, {"scenario": steps}, guide

# =========================================================
# 8) Feedback (RAG + teacher rubric)
# =========================================================
def get_teacher_feedback_context() -> str:
    ctx = (st.session_state.get("teacher_feedback_context") or "").strip()
    return _clip(ctx, 900) if ctx else ""

def feedback_with_tags(step_story: str, answer_text: str, extra_context: str = "", mode: str = "generic", rag_ctx: str = "") -> dict:
    teacher_ctx = get_teacher_feedback_context()

    if mode == "copyright":
        tag_candidates = "ì €ì‘ê¶Œ, ì¶œì²˜í‘œê¸°, í—ˆë½, ì±…ì„, íˆ¬ëª…ì„±, ê³µì •ì„±, ì•½ê´€í™•ì¸"
        caution = "ì£¼ì˜: ë²• ì¡°í•­ ë‹¨ì • ê¸ˆì§€. í”Œë«í¼ ì•½ê´€/í•™êµ ê·œì¹™/ì‚¬ìš© ëª©ì  í™•ì¸ í•„ìš”."
    else:
        tag_candidates = "í”„ë¼ì´ë²„ì‹œ, ê³µì •ì„±, ì±…ì„, ì•ˆì „, íˆ¬ëª…ì„±, ë°ì´í„°ë³´í˜¸, í¸í–¥, ì„¤ëª…ê°€ëŠ¥ì„±"
        caution = "ì£¼ì˜: ë‹¨ì •ì  ì‚¬ì‹¤ ì£¼ì¥ ê¸ˆì§€. ìƒí™© ê·¼ê±° ì¤‘ì‹¬."

    prompt = f"""
ìƒí™©/í™œë™: {step_story}

[ì™¸ë¶€ ì°¸ê³ ìë£Œ(reference.txt ë°œì·Œ)]
{rag_ctx if rag_ctx else "- ì—†ìŒ"}

[êµì‚¬ ê´€ì /í‰ê°€ê¸°ì¤€(ë°˜ì˜)]
{teacher_ctx if teacher_ctx else "- (êµì‚¬ ì…ë ¥ ì—†ìŒ)"}

[ì¶”ê°€ ë§¥ë½]
{_clip(extra_context, 700)}

[í•™ìƒ ë‹µ]
{answer_text}

{caution}

ë°˜ë“œì‹œ JSONë§Œ ì¶œë ¥.
í‚¤:
- tags: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸(ìµœëŒ€ 3ê°œ)
- summary: 1ì¤„ ìš”ì•½
- feedback: ë‹¨ë‹µí˜• í”¼ë“œë°±(í•µì‹¬ë§Œ, êµì‚¬ ê¸°ì¤€ + reference.txt ê´€ì ì„ ë°˜ì˜)

tags í›„ë³´:
{tag_candidates}
"""
    data = ask_gpt_json_object(prompt)

    tags = data.get("tags", [])
    if not isinstance(tags, list):
        tags = []
    tags = [str(t).strip() for t in tags if str(t).strip()][:3]

    summary = str(data.get("summary", "")).strip()
    fb = str(data.get("feedback", "")).strip() or "ì‘ë‹µ ë¶ˆê°€."
    return {"tags": tags, "summary": summary, "feedback": fb}

# =========================================================
# 9) Image generation
# =========================================================
@st.cache_data(show_spinner=False)
def generate_image_bytes_cached(user_prompt: str, image_model: str):
    full_prompt = f"{NO_TEXT_IMAGE_PREFIX}{user_prompt}"

    # 1) b64_json
    try:
        r = client.images.generate(
            model=image_model,
            prompt=full_prompt,
            size="1024x1024",
            n=1,
            response_format="b64_json",
        )
        b64 = getattr(r.data[0], "b64_json", None)
        if b64:
            return base64.b64decode(b64)
    except Exception:
        pass

    # 2) url fallback
    try:
        r = client.images.generate(
            model=image_model,
            prompt=full_prompt,
            size="1024x1024",
            n=1,
        )
        url = getattr(r.data[0], "url", None)
        if not url:
            return None
        resp = requests.get(url, timeout=25)
        resp.raise_for_status()
        return resp.content
    except Exception:
        return None

# =========================================================
# 10) Reports / Reset
# =========================================================
def compute_report(logs):
    tag_counts = {}
    step_type_counts = {}
    for row in logs:
        tags = row.get("tags", [])
        if isinstance(tags, list):
            for t in tags:
                tag_counts[t] = tag_counts.get(t, 0) + 1
        stype = row.get("step_type", "")
        if stype:
            step_type_counts[stype] = step_type_counts.get(stype, 0) + 1
    return tag_counts, step_type_counts

def clear_generated_images_from_session():
    to_del = [k for k in st.session_state.keys()
              if str(k).startswith("img_bytes_") or str(k).startswith("user_img_bytes_")]
    for k in to_del:
        del st.session_state[k]

def reset_student_progress(keep_logs: bool = True):
    st.session_state.current_step = 0
    st.session_state.tutorial_done = False
    st.session_state.tutorial_step = 1
    st.session_state.chat_history = []
    st.session_state.confirm_student_reset = False

    st.session_state.tutorial_choice = ""
    st.session_state.tutorial_reason = ""
    st.session_state.tutorial_img_prompt = ""
    st.session_state.tutorial_img_bytes = None

    st.session_state.last_student_image_prompt = ""
    st.session_state.last_student_image_done = False

    if not keep_logs:
        st.session_state.logs = []

# =========================================================
# 11) Session state init
# =========================================================
if "scenario" not in st.session_state or not isinstance(st.session_state.scenario, dict):
    st.session_state.scenario = {"scenario": []}

default_keys = {
    "analysis": {"ethics_standards": [], "curriculum_alignment": [], "lesson_content": []},
    "current_step": 0,
    "chat_history": [],
    "topic": "",
    "tutorial_done": False,
    "tutorial_step": 1,

    "logs": [],
    "student_name": "",
    "confirm_student_reset": False,

    "lesson_type": "general",      # general | copyright
    "teacher_guide": "",
    "teacher_feedback_context": "",

    # tutorial
    "tutorial_choice": "",
    "tutorial_reason": "",
    "tutorial_img_prompt": "",
    "tutorial_img_bytes": None,

    # last activity context
    "last_student_image_prompt": "",
    "last_student_image_done": False,
}
for k, v in default_keys.items():
    if k not in st.session_state:
        st.session_state[k] = v

st.session_state.analysis = normalize_analysis(st.session_state.analysis)

# =========================================================
# 12) Sidebar
# =========================================================
st.sidebar.title("ğŸ¤– AI ìœ¤ë¦¬ í•™ìŠµ (RAG)")

if st.sidebar.button("âš ï¸ ì•± ì „ì²´ ì´ˆê¸°í™”(ì™„ì „ ì´ˆê¸°í™”)"):
    st.session_state.clear()
    st.rerun()

mode = st.sidebar.radio("ëª¨ë“œ ì„ íƒ", ["ğŸ‘¨â€ğŸ« êµì‚¬ìš©", "ğŸ™‹â€â™‚ï¸ í•™ìƒìš©"], key="sb_mode")

# âœ… ìš”ì²­ì‚¬í•­: ì‚¬ì§„ì— ìˆë˜ RAG UI(ì²´í¬ë°•ìŠ¤/URL/Top-K/ìƒˆë¡œê³ ì¹¨/ìƒíƒœ ë²„íŠ¼) ì „ë¶€ ì œê±°
# âœ… ëŒ€ì‹  â€œreference.txtë¥¼ ë‚´ë¶€ì—ì„œ ìë™ ì°¸ê³ (RAG ì ìš©)â€ë§Œ í‘œì‹œ
rag_index = get_rag_index()
if rag_index and rag_index.get("chunks"):
    st.sidebar.caption(f"ğŸ“š RAG ì ìš©: internal reference.txt (Top-K={RAG_TOP_K})")
else:
    st.sidebar.caption("ğŸ“š RAG ì ìš©: internal reference.txt")
    if not Path(REFERENCE_PATH).exists():
        st.sidebar.warning("reference.txt ì—†ìŒ(ë ˆí¬ì— í¬í•¨ í•„ìš”)")

if mode == "ğŸ™‹â€â™‚ï¸ í•™ìƒìš©":
    st.sidebar.subheader("ğŸ™‹â€â™‚ï¸ í•™ìƒ ë„êµ¬")
    st.session_state.student_name = st.sidebar.text_input("ì´ë¦„(ì„ íƒ)", value=st.session_state.student_name)
    if st.sidebar.button("ì—°ìŠµ ë‹¤ì‹œí•˜ê¸°(íŠœí† ë¦¬ì–¼)"):
        reset_student_progress(keep_logs=True)
        st.rerun()

    if not st.session_state.confirm_student_reset:
        if st.sidebar.button("ì§„í–‰ ì´ˆê¸°í™”(í•™ìƒ)"):
            st.session_state.confirm_student_reset = True
            st.rerun()
    else:
        st.sidebar.warning("ì •ë§ ì´ˆê¸°í™”?")
        c1, c2 = st.sidebar.columns(2)
        with c1:
            if st.sidebar.button("ì´ˆê¸°í™” í™•ì •"):
                reset_student_progress(keep_logs=True)
                st.rerun()
        with c2:
            if st.sidebar.button("ì·¨ì†Œ"):
                st.session_state.confirm_student_reset = False
                st.rerun()

    if st.session_state.logs:
        st.sidebar.download_button(
            "í•™ìŠµ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ(JSON)",
            data=json.dumps(st.session_state.logs, ensure_ascii=False, indent=2),
            file_name="ethics_class_log.json",
            mime="application/json",
        )

# =========================================================
# 13) Teacher mode
# =========================================================
if mode == "ğŸ‘¨â€ğŸ« êµì‚¬ìš©":
    st.header("ğŸ› ï¸ ìˆ˜ì—… ìƒì„± (RAG: reference.txt ìë™ ì ìš©)")

    with st.expander("ğŸ“˜ êµì‚¬ìš© ê°€ì´ë“œë¼ì¸(ì‚¬ìš©ë²•)", expanded=True):
        st.markdown(
            """
**1) reference.txt ì¤€ë¹„**
- GitHub ë ˆí¬ì— `reference.txt`ë¥¼ ì•± ì½”ë“œì™€ í•¨ê»˜ í¬í•¨
- ì•±ì€ ë‚´ë¶€ íŒŒì¼ì„ ìë™ìœ¼ë¡œ ê²€ìƒ‰/ê·¼ê±°ë¡œ í™œìš©(RAG)

**2) ìˆ˜ì—… ìƒì„±**
- ì£¼ì œ ì…ë ¥ â†’ ì•„ë˜ ë²„íŠ¼ìœ¼ë¡œ ìƒì„±
- ìƒì„± ì‹œ reference.txtì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ê²€ìƒ‰(Top-K ê³ ì •)í•´ ìˆ˜ì—…/ë¶„ì„ì— ë°˜ì˜

**3) êµì‚¬ ê¸°ì¤€ ë°˜ì˜**
- `êµì‚¬ í”¼ë“œë°± ê¸°ì¤€/ê´€ì `ì— í‰ê°€ ê¸°ì¤€ ì…ë ¥
- í•™ìƒ í”¼ë“œë°±ì— êµì‚¬ ê¸°ì¤€ + reference.txt ê´€ì ì´ í•¨ê»˜ ë°˜ì˜ë¨

**4) ë°°í¬**
- `ìˆ˜ì—… íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ(JSON)`ë¡œ ë°°í¬
- í•™ìƒì€ í•™ìƒìš© í™”ë©´ì—ì„œ JSON ì—…ë¡œë“œë¡œ ìˆ˜ì—… ë¶ˆëŸ¬ì˜¤ê¸°
"""
        )

    with st.expander("ğŸ§‘â€ğŸ« êµì‚¬ í”¼ë“œë°± ê¸°ì¤€/ê´€ì (í•™ìƒ í”¼ë“œë°±ì— ë°˜ì˜)", expanded=False):
        st.session_state.teacher_feedback_context = st.text_area(
            "êµì‚¬ ê¸°ì¤€ ì…ë ¥",
            value=st.session_state.teacher_feedback_context,
            height=140,
            placeholder="ì˜ˆ) 1) í—ˆë½/ì¶œì²˜í‘œê¸°/ì‚¬ìš©ëª©ì  êµ¬ë¶„  2) ì•½ê´€/í•™êµ ê·œì¹™ í™•ì¸ ì–¸ê¸‰  3) ëŒ€ì²´ì•ˆ ì œì‹œ",
        )

    input_topic = st.text_input("ì£¼ì œ ì…ë ¥", value=st.session_state.topic)

    def teacher_rag_ctx(topic: str) -> str:
        if not rag_index:
            return ""
        q = f"{topic} ì¸ê³µì§€ëŠ¥ ìœ¤ë¦¬ê¸°ì¤€ êµìœ¡ê³¼ì • ìˆ˜ì—… ì„¤ê³„"
        return rag_retrieve(q, rag_index, top_k=RAG_TOP_K)

    colA, colB, colC, colD = st.columns([1, 1, 1, 1])

    with colA:
        if st.button("ë”œë ˆë§ˆ 3ë‹¨ê³„ ìƒì„±"):
            if not input_topic.strip():
                st.warning("ì£¼ì œ í•„ìš”.")
            else:
                with st.spinner("ìƒì„± ì¤‘..."):
                    st.session_state.topic = input_topic.strip()
                    st.session_state.lesson_type = "general"
                    st.session_state.teacher_guide = ""

                    rag_ctx = teacher_rag_ctx(st.session_state.topic)
                    st.session_state.scenario = generate_scenario_3steps(st.session_state.topic, rag_ctx=rag_ctx)

                    # analysis ìƒì„±(ê·¼ê±° í¬í•¨)
                    steps = st.session_state.scenario.get("scenario", [])
                    short_steps = json.dumps(
                        [{"type": s.get("type", ""), "story": _clip(s.get("story", ""), 220)} for s in steps],
                        ensure_ascii=False
                    )
                    a_prompt = f"""
êµì‚¬ìš© ë¶„ì„ ê²°ê³¼ ìƒì„±. ë°˜ë“œì‹œ JSON.
ì£¼ì œ: '{st.session_state.topic}'
[ì™¸ë¶€ ì°¸ê³ ìë£Œ(reference.txt ë°œì·Œ)]
{rag_ctx if rag_ctx else "- ì—†ìŒ"}
[ìˆ˜ì—… ë‹¨ê³„ ìš”ì•½]
{short_steps}

í‚¤:
- ethics_standards: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸(5ê°œ ë‚´ì™¸)
- curriculum_alignment: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸(4~6ê°œ, ì´ˆë“± 5~6 ì‹¤ê³¼/ë„ë• ì¤‘ì‹¬)
- lesson_content: ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸(4~6ê°œ, ë„ì…-í™œë™-í† ë¡ -ì •ë¦¬)
"""
                    st.session_state.analysis = normalize_analysis(ask_gpt_json_object(a_prompt))

                    st.session_state.current_step = 0
                    clear_generated_images_from_session()
                    st.success("ìƒì„± ì™„ë£Œ.")

    with colB:
        if st.button("í˜¼í•© ìˆ˜ì—… ìƒì„±(í™œë™+ì„ íƒ)"):
            if not input_topic.strip():
                st.warning("ì£¼ì œ í•„ìš”.")
            else:
                with st.spinner("í˜¼í•© ìˆ˜ì—… êµ¬ì„± ì¤‘..."):
                    rag_ctx = teacher_rag_ctx(input_topic.strip())
                    t, analysis, scenario_obj, guide = generate_mixed_lesson(input_topic.strip(), rag_ctx=rag_ctx)
                    st.session_state.topic = t
                    st.session_state.analysis = analysis
                    st.session_state.scenario = scenario_obj
                    st.session_state.lesson_type = "general"
                    st.session_state.teacher_guide = guide
                    st.session_state.current_step = 0
                    clear_generated_images_from_session()
                    st.success("ìƒì„± ì™„ë£Œ.")

    with colC:
        if st.button("ì˜ˆì‹œ ìˆ˜ì—… ìƒì„±(ì €ì‘ê¶Œ)"):
            with st.spinner("ì €ì‘ê¶Œ ìˆ˜ì—… êµ¬ì„± ì¤‘..."):
                rag_ctx = ""
                if rag_index:
                    rag_ctx = rag_retrieve("ì €ì‘ê¶Œ ìƒì„±í˜• AI ì´ë¯¸ì§€ ì¶œì²˜í‘œê¸° í—ˆë½ ì‚¬ìš©ëª©ì  ì•½ê´€", rag_index, top_k=RAG_TOP_K)
                t, analysis, scenario_obj, guide = generate_copyright_lesson(rag_ctx=rag_ctx)
                st.session_state.topic = t
                st.session_state.analysis = analysis
                st.session_state.scenario = scenario_obj
                st.session_state.lesson_type = "copyright"
                st.session_state.teacher_guide = guide
                st.session_state.current_step = 0
                clear_generated_images_from_session()
                st.success("ì˜ˆì‹œ ìˆ˜ì—… ìƒì„± ì™„ë£Œ.")

    with colD:
        if st.session_state.scenario.get("scenario"):
            pack = {
                "topic": st.session_state.topic,
                "lesson_type": st.session_state.lesson_type,
                "analysis": st.session_state.analysis,
                "teacher_guide": st.session_state.teacher_guide,
                "teacher_feedback_context": st.session_state.teacher_feedback_context,
                "rag": {"enabled": True, "source": "reference.txt", "top_k": RAG_TOP_K},
                "scenario": st.session_state.scenario.get("scenario", []),
            }
            st.download_button(
                "ìˆ˜ì—… íŒ¨í‚¤ì§€ ë‹¤ìš´ë¡œë“œ(JSON)",
                data=json.dumps(pack, ensure_ascii=False, indent=2),
                file_name="ethics_class_package.json",
                mime="application/json",
            )

    if st.session_state.teacher_guide:
        st.divider()
        with st.expander("ğŸ“Œ êµì‚¬ìš© ìˆ˜ì—… ì•ˆë‚´(ìë™ ìƒì„±)", expanded=True):
            st.text(st.session_state.teacher_guide)

    if st.session_state.analysis:
        st.divider()
        render_analysis_box(st.session_state.analysis)

    steps = st.session_state.scenario.get("scenario", [])
    if steps:
        st.divider()
        st.subheader("ğŸ“œ ìˆ˜ì—… ë‹¨ê³„ ë¯¸ë¦¬ë³´ê¸°")
        for i, step in enumerate(steps):
            with st.container(border=True):
                st.markdown(f"### ğŸ”¹ ë‹¨ê³„ {i+1} ({step.get('type','')})")
                st.markdown(f"**ğŸ“– ìƒí™©/í™œë™:** {step.get('story','')}")
                if step.get("type") == "image_task":
                    if step.get("prompt_goal"):
                        st.write("ğŸ¯ í”„ë¡¬í”„íŠ¸ ëª©í‘œ:", step.get("prompt_goal"))
                    if step.get("prompt_hint"):
                        st.write("ğŸ’¡ íŒíŠ¸:", step.get("prompt_hint"))
                    if step.get("question"):
                        st.write("ğŸ—£ï¸ ì§ˆë¬¸:", step.get("question"))
                elif step.get("type") == "discussion":
                    st.write("ğŸ—£ï¸ ì§ˆë¬¸:", step.get("question", ""))
                else:
                    c1, c2 = st.columns(2)
                    with c1:
                        st.success(f"**ğŸ…°ï¸ ì„ íƒ:** {step.get('choice_a', '')}")
                    with c2:
                        st.warning(f"**ğŸ…±ï¸ ì„ íƒ:** {step.get('choice_b', '')}")

        st.divider()
        st.subheader("ğŸ“ˆ í•™ìŠµ ë¡œê·¸ ë¦¬í¬íŠ¸(í˜„ì¬ ì„¸ì…˜)")
        if not st.session_state.logs:
            st.caption("ì•„ì§ í•™ìƒ ì œì¶œ ë¡œê·¸ ì—†ìŒ.")
        else:
            tag_counts, step_type_counts = compute_report(st.session_state.logs)
            c1, c2 = st.columns(2)
            with c1:
                st.markdown("#### íƒœê·¸ ë¹ˆë„")
                st.bar_chart(tag_counts) if tag_counts else st.caption("íƒœê·¸ ì—†ìŒ.")
            with c2:
                st.markdown("#### í™œë™ ìœ í˜• ë¶„í¬")
                st.bar_chart(step_type_counts) if step_type_counts else st.caption("ë°ì´í„° ì—†ìŒ.")

# =========================================================
# 14) Student mode
# =========================================================
else:
    with st.expander("ğŸ“¦ ìˆ˜ì—… ë¶ˆëŸ¬ì˜¤ê¸°(êµì‚¬ê°€ ë§Œë“  JSON ì—…ë¡œë“œ)", expanded=False):
        up = st.file_uploader("ethics_class_package.json", type=["json"])
        if up is not None:
            try:
                pack = json.load(up)
                st.session_state.topic = pack.get("topic", "")
                st.session_state.lesson_type = pack.get("lesson_type", "general")
                st.session_state.analysis = normalize_analysis(pack.get("analysis", {}))
                st.session_state.teacher_guide = pack.get("teacher_guide", "")
                st.session_state.teacher_feedback_context = pack.get("teacher_feedback_context", "")
                st.session_state.scenario = {"scenario": normalize_steps(pack.get("scenario", []))}
                st.session_state.current_step = 0
                st.session_state.chat_history = []
                clear_generated_images_from_session()
                st.success("ìˆ˜ì—… ë¡œë“œ ì™„ë£Œ")
                st.rerun()
            except Exception:
                st.error("JSON ë¡œë“œ ì‹¤íŒ¨")

    # --------------------------
    # Tutorial
    # --------------------------
    if not st.session_state.tutorial_done:
        st.header("ğŸ’ ì—°ìŠµ")
        st.progress(st.session_state.tutorial_step / 3)

        if st.session_state.tutorial_step == 1:
            st.subheader("1. ì„ íƒ ì—°ìŠµ")
            c1, c2 = st.columns(2)
            with c1:
                if st.button("A ì„ íƒ", key="tut_choose_a"):
                    st.session_state.tutorial_choice = "A"
                    st.session_state.tutorial_step = 2
                    st.rerun()
            with c2:
                if st.button("B ì„ íƒ", key="tut_choose_b"):
                    st.session_state.tutorial_choice = "B"
                    st.session_state.tutorial_step = 2
                    st.rerun()

        elif st.session_state.tutorial_step == 2:
            st.subheader("2. ì…ë ¥ ì—°ìŠµ")
            st.write(f"ë°©ê¸ˆ ì„ íƒ: {st.session_state.tutorial_choice or 'ë¯¸ì„ íƒ'}")
            st.session_state.tutorial_reason = st.text_area(
                "ì´ìœ (ì—°ìŠµ)",
                value=st.session_state.tutorial_reason,
                placeholder="ì˜ˆ: Aë¥¼ ì„ íƒí•œ ì´ìœ ëŠ” ...",
                key="tut_reason",
            )
            c1, c2 = st.columns([1, 1])
            with c1:
                if st.button("ì „ì†¡", key="tut_send"):
                    if st.session_state.tutorial_reason.strip():
                        st.session_state.tutorial_step = 3
                        st.rerun()
                    else:
                        st.warning("ì´ìœ  ì…ë ¥ í•„ìš”.")
            with c2:
                if st.button("ì´ì „", key="tut_back_1"):
                    st.session_state.tutorial_step = 1
                    st.rerun()

        elif st.session_state.tutorial_step == 3:
            st.subheader("3. í”„ë¡¬í”„íŠ¸ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸")
            st.caption("ê¸€ì ì—†ì´ ê·¸ë¦¼ë§Œ ì¶œë ¥")
            st.session_state.tutorial_img_prompt = st.text_input(
                "ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸(ì—°ìŠµ)",
                value=st.session_state.tutorial_img_prompt,
                placeholder="ì˜ˆ: friendly robot and child studying with books",
                key="tut_img_prompt",
            )
            c1, c2, c3 = st.columns([1, 1, 1])
            with c1:
                if st.button("ì´ë¯¸ì§€ ìƒì„±", key="tut_gen_img"):
                    if st.session_state.tutorial_img_prompt.strip():
                        with st.spinner("ìƒì„±..."):
                            st.session_state.tutorial_img_bytes = generate_image_bytes_cached(
                                st.session_state.tutorial_img_prompt.strip(),
                                IMAGE_MODEL,
                            )
                        if not st.session_state.tutorial_img_bytes:
                            st.error("ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨.")
                    else:
                        st.warning("í”„ë¡¬í”„íŠ¸ ì…ë ¥ í•„ìš”.")
            with c2:
                if st.button("ì˜ˆì‹œ ë„£ê¸°", key="tut_example"):
                    st.session_state.tutorial_img_prompt = "cute robot teacher and students in classroom"
                    st.rerun()
            with c3:
                if st.button("ì´ì „", key="tut_back_2"):
                    st.session_state.tutorial_step = 2
                    st.rerun()

            if st.session_state.tutorial_img_bytes:
                st.image(st.session_state.tutorial_img_bytes, width=360)
                if st.button("ìˆ˜ì—… ì…ì¥", key="tut_enter"):
                    st.session_state.tutorial_done = True
                    st.rerun()

    # --------------------------
    # Real class
    # --------------------------
    else:
        steps = st.session_state.scenario.get("scenario", [])
        if not steps:
            st.warning("ë°ì´í„° ì—†ìŒ. êµì‚¬ìš©ì—ì„œ ìƒì„± í›„ JSON ì—…ë¡œë“œ í•„ìš”.")
            if st.button("ìƒˆë¡œê³ ì¹¨", key="student_refresh"):
                st.rerun()
        else:
            idx = st.session_state.current_step
            total = len(steps)

            top1, top2 = st.columns([3, 1])
            with top1:
                st.caption(f"ì£¼ì œ: {st.session_state.topic or 'ë¯¸ì§€ì •'}")
            with top2:
                if st.button("ì²˜ìŒìœ¼ë¡œ(í•™ìƒ)", key="student_to_tutorial"):
                    reset_student_progress(keep_logs=True)
                    st.rerun()

            if idx >= total:
                st.success("ìˆ˜ì—… ì¢…ë£Œ.")
                if st.session_state.logs:
                    st.download_button(
                        "í•™ìŠµ ë¡œê·¸ ë‹¤ìš´ë¡œë“œ(JSON)",
                        data=json.dumps(st.session_state.logs, ensure_ascii=False, indent=2),
                        file_name="ethics_class_log.json",
                        mime="application/json",
                        key="student_logs_download_end",
                    )
                if st.button("ì²˜ìŒìœ¼ë¡œ(ë‹¤ì‹œ)", key="student_restart_all"):
                    reset_student_progress(keep_logs=True)
                    st.rerun()
            else:
                step = steps[idx]
                st.progress((idx + 1) / total)
                st.subheader(f"ë‹¨ê³„ {idx + 1} ({step.get('type', '')})")

                # âœ… í•­ìƒ ì‹œë‚˜ë¦¬ì˜¤ ì´ë¯¸ì§€ í‘œì‹œ
                img_key = f"img_bytes_{idx}"
                if img_key not in st.session_state:
                    with st.spinner("ì´ë¯¸ì§€ ìƒì„±..."):
                        st.session_state[img_key] = generate_image_bytes_cached(
                            step.get("story", "AI ethics"),
                            IMAGE_MODEL,
                        )
                if st.session_state.get(img_key):
                    st.image(st.session_state[img_key])

                st.info(step.get("story", "ë‚´ìš© ì—†ìŒ"))

                def step_rag_ctx():
                    if not rag_index:
                        return ""
                    q = f"{st.session_state.topic} {step.get('story','')} ìœ¤ë¦¬ ê¸°ì¤€ í•µì‹¬"
                    return rag_retrieve(q, rag_index, top_k=RAG_TOP_K)

                # A) IMAGE TASK
                if step.get("type") == "image_task":
                    st.divider()
                    st.subheader("ğŸ¨ í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ ë§Œë“¤ê¸°")
                    if step.get("prompt_goal"):
                        st.caption(f"ëª©í‘œ: {step.get('prompt_goal')}")
                    if step.get("prompt_hint"):
                        st.caption(f"íŒíŠ¸: {step.get('prompt_hint')}")

                    user_prompt_key = f"user_img_prompt_{idx}"
                    user_img_key = f"user_img_bytes_{idx}"

                    user_prompt = st.text_input(
                        "ë‚´ í”„ë¡¬í”„íŠ¸",
                        value=st.session_state.get(user_prompt_key, ""),
                        placeholder="ì˜ˆ: a happy child and a robot painting together",
                        key=user_prompt_key,
                    )

                    c1, c2 = st.columns([1, 1])
                    with c1:
                        if st.button("ë‚´ ì´ë¯¸ì§€ ìƒì„±", key=f"user_img_gen_{idx}"):
                            if user_prompt.strip():
                                with st.spinner("ë‚´ ì´ë¯¸ì§€ ìƒì„±..."):
                                    st.session_state[user_img_key] = generate_image_bytes_cached(
                                        user_prompt.strip(),
                                        IMAGE_MODEL,
                                    )
                                    st.session_state.last_student_image_prompt = user_prompt.strip()
                                    st.session_state.last_student_image_done = True
                            else:
                                st.warning("í”„ë¡¬í”„íŠ¸ ì…ë ¥ í•„ìš”.")
                    with c2:
                        if st.button("ë‚´ ì´ë¯¸ì§€ ì§€ìš°ê¸°", key=f"user_img_clear_{idx}"):
                            if user_img_key in st.session_state:
                                del st.session_state[user_img_key]
                            st.rerun()

                    if st.session_state.get(user_img_key):
                        st.image(st.session_state[user_img_key], caption="ë‚´ê°€ ë§Œë“  ì´ë¯¸ì§€")

                    q = step.get("question", "ì´ í™œë™ì—ì„œ ì¤‘ìš”í•œ ì  1ê°œ")
                    st.markdown(f"**ğŸ—£ï¸ ì§ˆë¬¸:** {q}")

                    with st.form(f"form_image_task_{idx}"):
                        opinion = st.text_area("ë‚´ ìƒê°(ì§§ê²Œ)", key=f"img_opinion_{idx}")
                        submitted = st.form_submit_button("ì œì¶œ")

                    if submitted:
                        if not st.session_state.get(user_img_key):
                            st.warning("ë¨¼ì € ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ì•¼ í•¨.")
                        elif not opinion.strip():
                            st.warning("ìƒê° ì…ë ¥ í•„ìš”.")
                        else:
                            extra_context = f"í•™ìƒ í”„ë¡¬í”„íŠ¸: {user_prompt.strip()}" if user_prompt.strip() else ""
                            mode_hint = "copyright" if st.session_state.lesson_type == "copyright" else "generic"
                            rag_ctx = step_rag_ctx()

                            with st.spinner("í”¼ë“œë°±..."):
                                fb = feedback_with_tags(
                                    step.get("story", ""),
                                    opinion.strip(),
                                    extra_context=extra_context,
                                    mode=mode_hint,
                                    rag_ctx=rag_ctx,
                                )

                            with st.container(border=True):
                                if fb.get("tags"):
                                    st.write("íƒœê·¸:", ", ".join(fb["tags"]))
                                if fb.get("summary"):
                                    st.write("ìš”ì•½:", fb["summary"])
                                st.write("í”¼ë“œë°±:", fb["feedback"])

                            st.session_state.chat_history.append({"role": "user", "content": f"[í™œë™] {opinion.strip()}"})
                            st.session_state.chat_history.append({"role": "assistant", "content": fb["feedback"]})

                            st.session_state.logs.append({
                                "timestamp": now_str(),
                                "student_name": st.session_state.student_name,
                                "topic": st.session_state.topic,
                                "lesson_type": st.session_state.lesson_type,
                                "step": idx + 1,
                                "step_type": "image_task",
                                "story": step.get("story", ""),
                                "prompt": user_prompt.strip(),
                                "opinion": opinion.strip(),
                                "tags": fb.get("tags", []),
                                "summary": fb.get("summary", ""),
                                "feedback": fb.get("feedback", ""),
                            })

                    if st.session_state.chat_history:
                        st.divider()
                        for msg in st.session_state.chat_history:
                            role = "assistant" if msg["role"] == "assistant" else "user"
                            st.chat_message(role).write(msg["content"])

                    if st.button("ë‹¤ìŒ ë‹¨ê³„ >", key=f"next_image_{idx}"):
                        st.session_state.current_step += 1
                        st.session_state.chat_history = []
                        st.rerun()

                # B) DISCUSSION
                elif step.get("type") == "discussion":
                    st.divider()
                    q = step.get("question", "í† ë¡  ì§ˆë¬¸")
                    st.markdown(f"**ğŸ—£ï¸ í† ë¡  ì§ˆë¬¸:** {q}")

                    with st.form(f"form_discussion_{idx}"):
                        opinion = st.text_area("ë‚´ ì˜ê²¬", key=f"disc_opinion_{idx}")
                        submitted = st.form_submit_button("ì œì¶œ")

                    if submitted:
                        if not opinion.strip():
                            st.warning("ì˜ê²¬ ì…ë ¥ í•„ìš”.")
                        else:
                            extra_context = ""
                            if st.session_state.last_student_image_done and st.session_state.last_student_image_prompt:
                                extra_context = f"ì´ì „ í™œë™ í”„ë¡¬í”„íŠ¸: {st.session_state.last_student_image_prompt}"

                            mode_hint = "copyright" if st.session_state.lesson_type == "copyright" else "generic"
                            rag_ctx = step_rag_ctx()

                            with st.spinner("í”¼ë“œë°±..."):
                                fb = feedback_with_tags(
                                    step.get("story", ""),
                                    opinion.strip(),
                                    extra_context=extra_context,
                                    mode=mode_hint,
                                    rag_ctx=rag_ctx,
                                )

                            with st.container(border=True):
                                if fb.get("tags"):
                                    st.write("íƒœê·¸:", ", ".join(fb["tags"]))
                                if fb.get("summary"):
                                    st.write("ìš”ì•½:", fb["summary"])
                                st.write("í”¼ë“œë°±:", fb["feedback"])

                            st.session_state.chat_history.append({"role": "user", "content": f"[í† ë¡ ] {opinion.strip()}"})
                            st.session_state.chat_history.append({"role": "assistant", "content": fb["feedback"]})

                            st.session_state.logs.append({
                                "timestamp": now_str(),
                                "student_name": st.session_state.student_name,
                                "topic": st.session_state.topic,
                                "lesson_type": st.session_state.lesson_type,
                                "step": idx + 1,
                                "step_type": "discussion",
                                "story": step.get("story", ""),
                                "question": q,
                                "opinion": opinion.strip(),
                                "tags": fb.get("tags", []),
                                "summary": fb.get("summary", ""),
                                "feedback": fb.get("feedback", ""),
                            })

                    if st.session_state.chat_history:
                        st.divider()
                        for msg in st.session_state.chat_history:
                            role = "assistant" if msg["role"] == "assistant" else "user"
                            st.chat_message(role).write(msg["content"])

                    if st.button("ë‹¤ìŒ ë‹¨ê³„ >", key=f"next_disc_{idx}"):
                        st.session_state.current_step += 1
                        st.session_state.chat_history = []
                        st.rerun()

                # C) DILEMMA
                else:
                    with st.form(f"form_dilemma_{idx}"):
                        sel = st.radio(
                            "ì„ íƒ",
                            [step.get("choice_a", "A"), step.get("choice_b", "B")],
                            key=f"radio_{idx}",
                        )
                        reason = st.text_area("ì´ìœ ", key=f"reason_{idx}")
                        submitted = st.form_submit_button("ì œì¶œ")

                    if submitted:
                        if not reason.strip():
                            st.warning("ì´ìœ  ì…ë ¥ í•„ìš”.")
                        else:
                            extra_context = ""
                            if st.session_state.last_student_image_done and st.session_state.last_student_image_prompt:
                                extra_context = f"í•™ìƒì´ ë§Œë“  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸(ì°¸ê³ ): {st.session_state.last_student_image_prompt}"

                            mode_hint = "copyright" if st.session_state.lesson_type == "copyright" else "generic"
                            answer_text = f"ì„ íƒ: {sel}\nì´ìœ : {reason.strip()}"
                            rag_ctx = step_rag_ctx()

                            with st.spinner("ë¶„ì„..."):
                                fb = feedback_with_tags(
                                    step.get("story", ""),
                                    answer_text,
                                    extra_context=extra_context,
                                    mode=mode_hint,
                                    rag_ctx=rag_ctx,
                                )

                            with st.container(border=True):
                                st.markdown("#### ğŸ§¾ ì œì¶œ ìš”ì•½")
                                if fb.get("tags"):
                                    st.write("íƒœê·¸:", ", ".join(fb["tags"]))
                                if fb.get("summary"):
                                    st.write("ìš”ì•½:", fb["summary"])
                                st.write("í”¼ë“œë°±:", fb["feedback"])

                            st.session_state.chat_history.append({"role": "user", "content": f"[{sel}] {reason.strip()}"})
                            st.session_state.chat_history.append({"role": "assistant", "content": fb["feedback"]})

                            st.session_state.logs.append({
                                "timestamp": now_str(),
                                "student_name": st.session_state.student_name,
                                "topic": st.session_state.topic,
                                "lesson_type": st.session_state.lesson_type,
                                "step": idx + 1,
                                "step_type": "dilemma",
                                "story": step.get("story", ""),
                                "choice": sel,
                                "reason": reason.strip(),
                                "tags": fb.get("tags", []),
                                "summary": fb.get("summary", ""),
                                "feedback": fb.get("feedback", ""),
                            })

                    if st.session_state.chat_history:
                        st.divider()
                        for msg in st.session_state.chat_history:
                            role = "assistant" if msg["role"] == "assistant" else "user"
                            st.chat_message(role).write(msg["content"])

                    if st.button("ë‹¤ìŒ ë‹¨ê³„ >", key=f"next_dilemma_{idx}"):
                        st.session_state.current_step += 1
                        st.session_state.chat_history = []
                        st.rerun()
