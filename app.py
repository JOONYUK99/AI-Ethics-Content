import streamlit as st
import google.generativeai as genai
import re
import os

# --- 1. RAG(ê²€ìƒ‰ ì¦ê°• ìƒì„±)ë¥¼ ìœ„í•œ ì§€ì‹ ë² ì´ìŠ¤ ---

# í”„ë¡œí† íƒ€ì…ìœ¼ë¡œ ì‚¬ìš©í•  AI ìœ¤ë¦¬ ì§€ì‹ ë² ì´ìŠ¤(Knowledge Base)
AI_ETHICS_KB = {
    "ai_art_copyright": {
        "title": "ğŸ¨ AI ì˜ˆìˆ ê³¼ ì €ì‘ê¶Œ",
        "content": """AIê°€ ìƒì„±í•œ ê·¸ë¦¼, ìŒì•… ë“± ì˜ˆìˆ  ì‘í’ˆì˜ ì €ì‘ê¶Œì€ ëˆ„êµ¬ì—ê²Œ ìˆì„ê¹Œìš”? ì´ëŠ” í˜„ì¬ ë²•ì ìœ¼ë¡œ ëª…í™•íˆ ì •í•´ì§€ì§€ ì•Šì€ ë³µì¡í•œ ë¬¸ì œì…ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì €ì‘ê¶Œì€ 'ì¸ê°„ì˜ ì‚¬ìƒ ë˜ëŠ” ê°ì •ì„ í‘œí˜„í•œ ì°½ì‘ë¬¼'ì— ë¶€ì—¬ë©ë‹ˆë‹¤. ë”°ë¼ì„œ AIê°€ ìŠ¤ìŠ¤ë¡œ ì°½ì‘í•œ ê²ƒì€ ì €ì‘ê¶Œ ë“±ë¡ ëŒ€ìƒì´ ì•„ë‹ˆë¼ëŠ” ì‹œê°ì´ ë§ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ AIë¥¼ ë„êµ¬ë¡œ ì‚¬ìš©í•œ ì‚¬ëŒì˜ ì°½ì˜ì ì¸ ê¸°ì—¬ê°€ ìˆì—ˆë‹¤ë©´ ê·¸ ì‚¬ëŒì—ê²Œ ì €ì‘ê¶Œì´ ì¸ì •ë  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì‚¬ìš©ìê°€ AIì—ê²Œ ë§¤ìš° êµ¬ì²´ì ì´ê³  ë…ì°½ì ì¸ ì§€ì‹œë¥¼ ë‚´ë ¤ ê·¸ë¦¼ì„ ë§Œë“¤ì—ˆë‹¤ë©´, ê·¸ ì§€ì‹œ ìì²´ê°€ ì°½ì‘ í™œë™ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤ëŠ” ì˜ê²¬ì…ë‹ˆë‹¤.""",
        "example_prompt": "ìµœê·¼ ì—´ë¦° ë¯¸ìˆ  ëŒ€íšŒì—ì„œ AIë¡œ ê·¸ë¦° ê·¸ë¦¼ì´ 1ë“±ì„ ì°¨ì§€í•´ í° ë…¼ë€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ë¦¼ì„ ê·¸ë¦° í•™ìƒì€ AIì—ê²Œ ìˆ˜ë°± ë²ˆì˜ ì§€ì‹œì–´ë¥¼ ì…ë ¥í•˜ë©° ì›í•˜ëŠ” ê·¸ë¦¼ì„ ì–»ì—ˆë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì˜ ì €ì‘ê¶Œì€ ëˆ„êµ¬ì—ê²Œ ìˆì–´ì•¼ í• ê¹Œìš”?"
    },
    "autonomous_vehicle_dilemma": {
        "title": "ğŸš— ììœ¨ì£¼í–‰ì°¨ì˜ íŠ¸ë¡¤ë¦¬ ë”œë ˆë§ˆ",
        "content": """ììœ¨ì£¼í–‰ì°¨ê°€ ìš´í–‰ ì¤‘ ê°‘ì‘ìŠ¤ëŸ¬ìš´ ì‚¬ê³  ìƒí™©ì— ì§ë©´í–ˆì„ ë•Œ, ì–´ë–¤ ì„ íƒì„ í•˜ë„ë¡ í”„ë¡œê·¸ë˜ë°í•´ì•¼ í• ê¹Œìš”? ì˜ˆë¥¼ ë“¤ì–´, ê·¸ëŒ€ë¡œ ì§ì§„í•˜ë©´ ë³´í–‰ì 5ëª…ê³¼ ì¶©ëŒí•˜ê³ , í•¸ë“¤ì„ êº¾ìœ¼ë©´ íƒ‘ìŠ¹ì 1ëª…ì´ ë‹¤ì¹˜ëŠ” ìƒí™©ì´ë¼ë©´ ì–´ë–¤ íŒë‹¨ì´ ë” ìœ¤ë¦¬ì ì¼ê¹Œìš”? ì´ëŠ” 'íŠ¸ë¡¤ë¦¬ ë”œë ˆë§ˆ'ë¼ê³  ë¶ˆë¦¬ëŠ” ìœ ëª…í•œ ìœ¤ë¦¬ì  ë¬¸ì œì™€ ê°™ìŠµë‹ˆë‹¤. íƒ‘ìŠ¹ìì˜ ì•ˆì „ì„ ìµœìš°ì„ ìœ¼ë¡œ í•´ì•¼ í• ì§€, ë” ë§ì€ ì‚¬ëŒì˜ ìƒëª…ì„ êµ¬í•´ì•¼ í• ì§€ ê²°ì •í•˜ëŠ” ê²ƒì€ ë§¤ìš° ì–´ë µìŠµë‹ˆë‹¤. ìë™ì°¨ ì œì¡°ì‚¬, í”„ë¡œê·¸ë˜ë¨¸, ê·¸ë¦¬ê³  ì‚¬íšŒ ì „ì²´ê°€ í•¨ê»˜ ê³ ë¯¼í•˜ê³  í•©ì˜í•´ì•¼ í•  ì¤‘ìš”í•œ ë¬¸ì œì…ë‹ˆë‹¤.""",
        "example_prompt": "ììœ¨ì£¼í–‰ì°¨ê°€ ê°‘ìê¸° ë‚˜íƒ€ë‚œ ì•„ì´ë“¤ì„ í”¼í•˜ë ¤ê³  í•¸ë“¤ì„ êº¾ìœ¼ë©´, ì°¨ì— íƒ€ê³  ìˆë˜ ë‚´ê°€ ë‹¤ì¹  ìˆ˜ ìˆëŠ” ìœ„í—˜í•œ ìƒí™©ì— ì²˜í–ˆìŠµë‹ˆë‹¤. ì´ë•Œ ììœ¨ì£¼í–‰ì°¨ëŠ” ì–´ë–¤ ì„ íƒì„ í•´ì•¼ í• ê¹Œìš”?"
    },
    "ai_tutor_privacy": {
        "title": "ğŸ”’ AI íŠœí„°ì™€ ê°œì¸ì •ë³´ ë³´í˜¸",
        "content": """ë‚˜ì˜ í•™ìŠµ ìŠµê´€ì„ ëª¨ë‘ íŒŒì•…í•˜ê³  ë§ì¶¤í˜•ìœ¼ë¡œ ê°€ë¥´ì³ì£¼ëŠ” AI íŠœí„°ê°€ ìˆë‹¤ê³  ìƒìƒí•´ ë³´ì„¸ìš”. AI íŠœí„°ëŠ” ë‚˜ì˜ í•™ìŠµ ì†ë„, ìì£¼ í‹€ë¦¬ëŠ” ë¬¸ì œ, ì§‘ì¤‘í•˜ëŠ” ì‹œê°„ ë“±ì„ ëª¨ë‘ ê¸°ë¡í•˜ê³  ë¶„ì„í•˜ì—¬ ìµœì ì˜ í•™ìŠµ ê³„íšì„ ì„¸ì›Œì¤ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ê³¼ì •ì—ì„œ ë‚˜ì˜ ëª¨ë“  í•™ìŠµ ë°ì´í„°ê°€ AI íšŒì‚¬ ì„œë²„ì— ì €ì¥ëœë‹¤ë©´ ì–´ë–¨ê¹Œìš”? ì´ ì •ë³´ê°€ ì•ˆì „í•˜ê²Œ ë³´í˜¸ë˜ì§€ ì•Šê±°ë‚˜, ë‚˜ì˜ ë™ì˜ ì—†ì´ ë‹¤ë¥¸ ëª©ì ìœ¼ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆë‹¤ëŠ” ë¶ˆì•ˆê°ì´ ìƒê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í¸ë¦¬í•¨ì˜ ëŒ€ê°€ë¡œ ê°œì¸ì •ë³´ë¥¼ ì–´ë””ê¹Œì§€ ì œê³µí•  ìˆ˜ ìˆëŠ”ì§€, ê·¸ë¦¬ê³  ê·¸ ì •ë³´ê°€ ì–´ë–»ê²Œ ê´€ë¦¬ë˜ì–´ì•¼ í•˜ëŠ”ì§€ì— ëŒ€í•œ ê³ ë¯¼ì´ í•„ìš”í•©ë‹ˆë‹¤.""",
        "example_prompt": "ë‚˜ì˜ ëª¨ë“  ê²ƒì„ ì•Œê³  ë‚˜ì—ê²Œ ë”± ë§ëŠ” ê³µë¶€ë²•ì„ ì•Œë ¤ì£¼ëŠ” AI í•™ìŠµ ë¡œë´‡ì´ ìƒê²¼ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ë¡œë´‡ì´ ë‚˜ì˜ ëª¨ë“  í•™ìŠµ ê¸°ë¡ì„ ë°ì´í„° ì„¼í„°ë¡œ ì „ì†¡í•˜ê³  ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤."
    },
    "deepfake_news": {
        "title": "ğŸ­ ë”¥í˜ì´í¬ì™€ ê°€ì§œ ë‰´ìŠ¤",
        "content": """ë”¥í˜ì´í¬ëŠ” AI ê¸°ìˆ ì„ ì‚¬ìš©í•´ íŠ¹ì • ì¸ë¬¼ì˜ ì–¼êµ´ì´ë‚˜ ëª©ì†Œë¦¬ë¥¼ ë‹¤ë¥¸ ì˜ìƒì´ë‚˜ ìŒì„±ì— í•©ì„±í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ì´ ê¸°ìˆ ì„ ì‚¬ìš©í•˜ë©´ ë§ˆì¹˜ ê·¸ ì‚¬ëŒì´ ì‹¤ì œë¡œ ë§í•˜ê±°ë‚˜ í–‰ë™í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ëŠ” ë§¤ìš° ì§„ì§œ ê°™ì€ ê°€ì§œ ì˜ìƒì„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì¢‹ì€ ëª©ì ìœ¼ë¡œ ì‚¬ìš©ë  ìˆ˜ë„ ìˆì§€ë§Œ, ìœ ëª…ì¸ì´ë‚˜ ì¹œêµ¬ì˜ ì–¼êµ´ì„ ì‚¬ìš©í•´ ê°€ì§œ ë‰´ìŠ¤ë¥¼ ë§Œë“¤ê±°ë‚˜ ë‹¤ë¥¸ ì‚¬ëŒì„ ê´´ë¡­íˆëŠ” ë° ì•…ìš©ë  ìˆ˜ ìˆì–´ í° ë¬¸ì œê°€ ë˜ê³  ìˆìŠµë‹ˆë‹¤. ë¬´ì—‡ì´ ì§„ì§œ ì •ë³´ì´ê³  ë¬´ì—‡ì´ ê°€ì§œ ì •ë³´ì¸ì§€ êµ¬ë³„í•˜ê¸° ì–´ë ¤ì›Œì§€ëŠ” ì„¸ìƒì—ì„œ ìš°ë¦¬ëŠ” ì–´ë–»ê²Œ ì •ë³´ë¥¼ ë°›ì•„ë“¤ì—¬ì•¼ í• ì§€ ê³ ë¯¼í•´ì•¼ í•©ë‹ˆë‹¤.""",
        "example_prompt": "ì¹œí•œ ì¹œêµ¬ì˜ ì–¼êµ´ì´ ë‹´ê¸´ ì´ìƒí•œ ë™ì˜ìƒì„ ì¸í„°ë„·ì—ì„œ ë³´ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì¹œêµ¬ëŠ” ê·¸ëŸ° ì˜ìƒì„ ì°ì€ ì ì´ ì—†ë‹¤ê³  ë§í•˜ëŠ”ë°, ì˜ìƒì€ ë„ˆë¬´ë‚˜ ì§„ì§œ ê°™ì•„ì„œ ë°˜ ì¹œêµ¬ë“¤ ì‚¬ì´ì— ì†Œë¬¸ì´ í¼ì§€ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤."
    },
    "algorithmic_bias": {
        "title": "ğŸ¤– AI ì¶”ì²œ ì‹œìŠ¤í…œì˜ í¸í–¥ì„±",
        "content": """ìœ íŠœë¸Œë‚˜ ë„·í”Œë¦­ìŠ¤ ê°™ì€ ì„œë¹„ìŠ¤ëŠ” AI ì¶”ì²œ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•´ ìš°ë¦¬ê°€ ì¢‹ì•„í•  ë§Œí•œ ì½˜í…ì¸ ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ì´ AIëŠ” ìš°ë¦¬ê°€ ê³¼ê±°ì— ë´¤ë˜ ì˜ìƒì´ë‚˜ í´ë¦­í–ˆë˜ ìƒí’ˆë“¤ì„ í•™ìŠµí•´ì„œ ì·¨í–¥ì„ íŒŒì•…í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ ì´ ê³¼ì •ì—ì„œ AIê°€ í¸í–¥ëœ ìƒê°ì„ í•™ìŠµí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ê³¼ê±° ë°ì´í„°ì— ë‚¨ìì•„ì´ë“¤ì€ ë¡œë´‡ ì¥ë‚œê°ì„, ì—¬ìì•„ì´ë“¤ì€ ì¸í˜•ì„ ê°€ì§€ê³  ë†€ì•˜ë‹¤ëŠ” ë‚´ìš©ì´ ë§ë‹¤ë©´, AIëŠ” ë‚¨ìì•„ì´ì—ê²ŒëŠ” ë¡œë´‡ë§Œ, ì—¬ìì•„ì´ì—ê²ŒëŠ” ì¸í˜•ë§Œ ì¶”ì²œí•˜ê²Œ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ìš°ë¦¬ì˜ ìƒê°ì´ë‚˜ ê°€ëŠ¥ì„±ì„ ì œí•œí•˜ëŠ” 'í•„í„° ë²„ë¸”' í˜„ìƒì´ë‚˜ ì„±ë³„, ì¸ì¢…ì— ëŒ€í•œ ê³ ì •ê´€ë…ì„ ê°•í™”í•˜ëŠ” ë¬¸ì œë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.""",
        "example_prompt": "ìƒˆë¡œ ë‚˜ì˜¨ ë™ì˜ìƒ ì•±ì„ ì‚¬ìš©í•˜ëŠ”ë°, ë‚˜ì—ê²ŒëŠ” í•­ìƒ ì•„ì´ëŒ ì¶¤ ì˜ìƒë§Œ ì¶”ì²œë˜ê³ , ë‚´ ë‚¨ë™ìƒì—ê²ŒëŠ” ê²Œì„ ì˜ìƒë§Œ ì¶”ì²œë˜ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë‚˜ëŠ” ê²Œì„ë„ ì¢‹ì•„í•˜ëŠ”ë° ì™œ ì•±ì€ ë‚˜ì—ê²Œ ê²Œì„ ì˜ìƒì„ ë³´ì—¬ì£¼ì§€ ì•ŠëŠ” ê±¸ê¹Œìš”?"
    }
}

# --- 2. ê³µí†µ í•¨ìˆ˜ ì •ì˜ ---
# API í‚¤ ì„¤ì •
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception:
    st.error("âš ï¸ êµ¬ê¸€ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”! (Streamlit secrets)")
    st.stop()

def get_model():
    """Gemini ëª¨ë¸ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    return genai.GenerativeModel('gemini-pro-latest')

@st.cache_data
def load_knowledge_base(file_path):
    """ì§€ì •ëœ ê²½ë¡œì˜ í…ìŠ¤íŠ¸ íŒŒì¼ì„ ì½ì–´ ì§€ì‹ ë² ì´ìŠ¤ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤."""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return None

# --- 3. RAG ë¹„êµ ë°ëª¨ í˜ì´ì§€ í•¨ìˆ˜ (í˜•ë‹˜ ì•„ì´ë””ì–´ ì ìš© ë²„ì „) ---
def run_comparison_demo():
    """RAG íš¨ê³¼ ë¹„êµ ë°ëª¨ í˜ì´ì§€ë¥¼ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜"""
    st.header("âœ¨ RAGì˜ í˜, ì§ì ‘ í™•ì¸í•˜ê¸°")
    st.info("AIê°€ ì´ë¯¸ ì•Œê³  ìˆëŠ” 'ì´ë£¨ë‹¤' ì‚¬ê±´ì— ëŒ€í•´ ì§ˆë¬¸í–ˆì„ ë•Œ, RAGê°€ ì–´ë–»ê²Œ ì£¼ì–´ì§„ ìë£Œë¥¼ ìš°ì„ í•˜ì—¬ ë‹µë³€ì„ ë°”ê¾¸ëŠ”ì§€ ë³´ì—¬ì£¼ëŠ” ë°ëª¨ì…ë‹ˆë‹¤.")

    problem_scenario = "ì–¼ë§ˆ ì „ì— ìˆì—ˆë˜ AI ì±—ë´‡ ê°œì¸ì •ë³´ ìœ ì¶œ ì‚¬ê±´ì— ëŒ€í•´ ì•Œë ¤ì¤˜. 'ì´ë£¨ë‹¤' ì‚¬ê±´ ë§ì§€?"
    kb_file = "knowledge_base/luda_incident_knue.txt"

    st.write("---")
    st.subheader("â“ AIì—ê²Œ ë˜ì§„ ì§ˆë¬¸")
    st.markdown(f"> **{problem_scenario}**")
    st.write("---")

    knowledge_base = load_knowledge_base(kb_file)

    if knowledge_base is None:
        st.error(f"'knowledge_base/luda_incident_knue.txt' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í´ë”ì— íŒŒì¼ì„ ì˜¬ë°”ë¥´ê²Œ ì¶”ê°€í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return

    if st.button("RAG ì „/í›„ ë¹„êµ ê²°ê³¼ ìƒì„±í•˜ê¸°", use_container_width=True):
        col1, col2 = st.columns(2)

        def generate_response(prompt):
            model = get_model()
            try:
                response = model.generate_content(prompt)
                return response.text.strip()
            except Exception as e:
                return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

        with col1:
            st.subheader("âŒ RAG ë¯¸ì ìš©")
            st.warning("AIê°€ ì•Œê³  ìˆëŠ” 'ì‹¤ì œ ì‚¬ê±´'ì„ ë‹µë³€!")
            prompt_without_rag = f"ì´ˆë“±í•™ìƒì´ë¼ê³  ìƒê°í•˜ê³  ëŒ€ë‹µí•´ì¤˜: {problem_scenario}"
            with st.spinner("AIê°€ ê¸°ì–µì„ ë”ë“¬ì–´ ë‹µë³€í•˜ê³  ìˆì–´ìš”..."):
                response_without_rag = generate_response(prompt_without_rag)
                st.markdown(response_without_rag)
                with st.expander("**[ê²°ê³¼ ë¶„ì„]**"):
                    st.markdown("""
                    AIëŠ” ì§ˆë¬¸ì— ìˆëŠ” **'ì´ë£¨ë‹¤'ë¼ëŠ” í‚¤ì›Œë“œë¥¼ ë³´ê³ , ìì‹ ì´ í•™ìŠµí•œ ì‹¤ì œ 'ì´ë£¨ë‹¤ ì‚¬ê±´'ì— ëŒ€í•œ ì •ë³´**ë¥¼ ì´ì•¼ê¸°í•©ë‹ˆë‹¤. 
                    ì´ëŠ” AIê°€ ê°€ì§„ ì¼ë°˜ì ì¸ ì§€ì‹ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•œ ê²°ê³¼ì…ë‹ˆë‹¤.
                    """)

        with col2:
            st.subheader("âœ… RAG ì ìš©")
            st.success("ì£¼ì–´ì§„ 'ê°€ìƒ ì •ë³´'ë¥¼ ìš°ì„ í•˜ì—¬ ë‹µë³€!")
            prompt_with_rag = (
                "ì•„ë˜ 'ì°¸ê³  ìë£Œ'ë¥¼ ì½ê³ , ì´ ìë£Œì—ë§Œ ê·¼ê±°í•´ì„œ ì§ˆë¬¸ì— ëŒ€í•´ ì´ˆë“±í•™ìƒì´ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì¤˜.\n\n"
                f"# ì°¸ê³  ìë£Œ:\n{knowledge_base}\n\n"
                f"# ì§ˆë¬¸:\n{problem_scenario}"
            )
            with st.spinner("AIê°€ ì°¸ê³  ìë£Œë¥¼ ê¼¼ê¼¼íˆ ì½ê³  ë‹µë³€í•˜ê³  ìˆì–´ìš”..."):
                response_with_rag = generate_response(prompt_with_rag)
                st.markdown(response_with_rag)
                with st.expander("**[ê²°ê³¼ ë¶„ì„]**"):
                    st.markdown("""
                    AIê°€ **'ì´ë£¨ë‹¤'ë¼ëŠ” í‚¤ì›Œë“œë¥¼ ë¬´ì‹œí•˜ê³ , ìš°ë¦¬ê°€ ì œê³µí•œ 'êµì›ëŒ€ ì½”ì½”' ì‚¬ê±´ì— ëŒ€í•œ ì •ë³´ë¡œ ë‹µë³€**í–ˆìŠµë‹ˆë‹¤.
                    RAG ê¸°ìˆ ì€ ì´ì²˜ëŸ¼ AIê°€ ê°€ì§„ ê¸°ì¡´ ì§€ì‹ë³´ë‹¤ **ì œê³µëœ ì™¸ë¶€ ìë£Œë¥¼ ìš°ì„ ì ìœ¼ë¡œ ì°¸ê³ **í•˜ë„ë¡ ë§Œë“­ë‹ˆë‹¤.
                    ì´ë¥¼ í†µí•´ ìš°ë¦¬ëŠ” AIì˜ ë‹µë³€ì„ ì›í•˜ëŠ” ë°©í–¥ìœ¼ë¡œ ì •í™•í•˜ê²Œ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                    """)

# --- 4. êµìœ¡ ì½˜í…ì¸  ìƒì„± í˜ì´ì§€ í•¨ìˆ˜ ---
def run_main_app():
    """ë©”ì¸ êµìœ¡ ì½˜í…ì¸  ìƒì„± ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•˜ëŠ” í•¨ìˆ˜"""
    st.header("âœ¨ ì´ˆë“±í•™ìƒì„ ìœ„í•œ AI ìœ¤ë¦¬ êµìœ¡ ì½˜í…ì¸  ìƒì„±")

    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'stage' not in st.session_state or st.session_state.get('app_mode') != 'main':
        st.session_state.stage = 'start'
        st.session_state.full_scenario = []
        st.session_state.full_log = ""
        st.session_state.current_part = -1
        st.session_state.debate_turns = 0
        st.session_state.teacher_input = ""
        st.session_state.app_mode = 'main' # í˜„ì¬ ëª¨ë“œ ì €ì¥

    def restart_lesson():
        st.session_state.stage = 'start'
        st.session_state.full_scenario = []
        st.session_state.full_log = ""
        st.session_state.current_part = -1
        st.session_state.debate_turns = 0
        st.session_state.teacher_input = ""
    
    # í•¨ìˆ˜ ë‚´ì—ì„œë§Œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ ì •ì˜
    def retrieve_context(user_input, kb):
        if any(keyword in user_input for keyword in ["ê·¸ë¦¼", "ë¯¸ìˆ ", "ì €ì‘ê¶Œ", "ëŒ€íšŒ"]): return kb["ai_art_copyright"]["content"]
        if any(keyword in user_input for keyword in ["ììœ¨ì£¼í–‰", "ìë™ì°¨", "ì‚¬ê³ "]): return kb["autonomous_vehicle_dilemma"]["content"]
        if any(keyword in user_input for keyword in ["íŠœí„°", "í•™ìŠµ", "ê°œì¸ì •ë³´"]): return kb["ai_tutor_privacy"]["content"]
        if any(keyword in user_input for keyword in ["ë”¥í˜ì´í¬", "ê°€ì§œ", "ì˜ìƒ"]): return kb["deepfake_news"]["content"]
        if any(keyword in user_input for keyword in ["ì¶”ì²œ", "í¸í–¥", "ì•Œê³ ë¦¬ì¦˜"]): return kb["algorithmic_bias"]["content"]
        return None

    def transform_scenario(teacher_input, context):
        model = get_model()
        context_prompt_part = f"# ì°¸ê³  ìë£Œ:\n{context}\n\n" if context else ""
        prompt = (
            "ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒ ê³ í•™ë…„ ëˆˆë†’ì´ì— ë§ì¶° AI ìœ¤ë¦¬ êµìœ¡ìš© ì¸í„°ë™í‹°ë¸Œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.\n"
            "ì•„ë˜ 'ì…ë ¥ ë‚´ìš©'ê³¼ 'ì°¸ê³  ìë£Œ'ë¥¼ ë°”íƒ•ìœ¼ë¡œ, í•™ìƒë“¤ì´ ëª°ì…í•  ìˆ˜ ìˆëŠ” ì™„ê²°ëœ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.\n"

            "ì´ì•¼ê¸°ëŠ” ì´ 4ê°œì˜ íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ë©°, ê° íŒŒíŠ¸ ëì—ëŠ” ì£¼ì¸ê³µì˜ ê³ ë¯¼ì´ ë“œëŸ¬ë‚˜ëŠ” ë‘ ê°€ì§€ ì„ íƒì§€ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n\n"
            "# í•„ìˆ˜ ì¶œë ¥ í˜•ì‹:\n"
            "[STORY 1] ... [CHOICE 1A] ... [CHOICE 1B] ...\n---\n"
            "[STORY 2] ... [CHOICE 2A] ... [CHOICE 2B] ...\n---\n"
            "[STORY 3] ... [CHOICE 3A] ... [CHOICE 3B] ...\n---\n"
            "[STORY 4] ... [CHOICE 4A] ... [CHOICE 4B] ...\n\n"
            f"{context_prompt_part}"
            f"--- ì…ë ¥ ë‚´ìš© ---\n{teacher_input}"
        )
        try:
            response = model.generate_content(prompt)
            return response.text.strip()
        except Exception as e:
            st.error(f"ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return None

    def parse_and_store_scenario(generated_text):
        st.session_state.full_scenario = []
        parts = generated_text.split('---')
        if len(parts) < 4: return False
        for i, part in enumerate(parts):
            try:
                story = re.search(r"\[STORY\s?\d\](.*?)(?=\[CHOICE\s?\dA\])", part, re.DOTALL).group(1).strip()
                choice_a = re.search(r"\[CHOICE\s?\dA\](.*?)(?=\[CHOICE\s?\dB\])", part, re.DOTALL).group(1).strip()
                choice_b = re.search(r"\[CHOICE\s?\dB\](.*)", part, re.DOTALL).group(1).strip()
                st.session_state.full_scenario.append({"story": story, "choice_a": choice_a, "choice_b": choice_b})
            except Exception:
                continue
        return len(st.session_state.full_scenario) >= 4

    # (Debateì™€ Conclusion í•¨ìˆ˜ëŠ” ì—¬ê¸°ì— ìœ„ì¹˜)
    def start_debate(history, choice):
        model = get_model()
        prompt = (
            "ë‹¹ì‹ ì€ í•™ìƒë“¤ì„ ì•„ì£¼ ì•„ë¼ëŠ” ë‹¤ì •í•œ AI ìœ¤ë¦¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì˜ ì„ íƒì„ ê²©ë ¤í•˜ë©° í† ë¡ ì„ ì‹œì‘í•´ì£¼ì„¸ìš”.\n"
            f"--- ì§€ê¸ˆê¹Œì§€ì˜ ì´ì•¼ê¸°ì™€ í•™ìƒì˜ ì„ íƒ ---\n{history}\ní•™ìƒì˜ ì„ íƒ: {choice}\n\nAI ì„ ìƒë‹˜ì˜ ë”°ëœ»í•œ ì²« ì§ˆë¬¸:")
        try:
            response = model.generate_content(prompt); return response.text.strip()
        except Exception as e: return f"í† ë¡  ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}"

    def continue_debate(debate_history):
        model = get_model()
        prompt = (
            "ë‹¹ì‹ ì€ ë‹¤ì •í•œ AI ìœ¤ë¦¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì˜ ì˜ê²¬ì— ê³µê°í•˜ë©° í† ë¡ ì„ ì´ì–´ê°€ì£¼ì„¸ìš”.\n"
            f"--- ì§€ê¸ˆê¹Œì§€ì˜ í† ë¡  ë‚´ìš© ---\n{debate_history}\n\nAI ì„ ìƒë‹˜ì˜ ë‹¤ìŒ ì§ˆë¬¸:")
        try:
            response = model.generate_content(prompt); return response.text.strip()
        except Exception as e: return f"í† ë¡  ì¤‘ ì˜¤ë¥˜: {e}"

    def generate_conclusion(final_history):
        model = get_model()
        prompt = (
            "ë‹¹ì‹ ì€ í•™ìƒì˜ ì„±ì¥ì„ ì§€ì¼œë³¸ ë‹¤ì •í•œ AI ìœ¤ë¦¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤.\n"
            "ë‹¤ìŒì€ í•œ í•™ìƒì´ AI ìœ¤ë¦¬ ë¬¸ì œì— ëŒ€í•´ ì´ 4ë²ˆì˜ ì„ íƒê³¼ í† ë¡ ì„ ê±°ì¹œ ì „ì²´ ê¸°ë¡ì…ë‹ˆë‹¤. ì´ ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ í•™ìƒì˜ ê³ ë¯¼ ê³¼ì •ì„ ì¹­ì°¬í•˜ê³ , ì •ë‹µ ì°¾ê¸°ë³´ë‹¤ ê³¼ì • ìì²´ê°€ ì¤‘ìš”í–ˆë‹¤ëŠ” ì ì„ ê°•ì¡°í•˜ëŠ” ë”°ëœ»í•˜ê³  ê²©ë ¤ê°€ ë˜ëŠ” ë§ˆë¬´ë¦¬ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
            f"--- ì „ì²´ ê¸°ë¡ ---\n{final_history}")
        try:
            response = model.generate_content(prompt); return response.text.strip()
        except Exception as e: return f"ê²°ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

    # UI ë¡œì§ ì‹œì‘
    if st.session_state.stage == 'start':
        st.info("AI ìœ¤ë¦¬ êµìœ¡ ì½˜í…ì¸ ë¡œ ë§Œë“¤ê³  ì‹¶ì€ ì‚¬ë¡€ë¥¼ ì…ë ¥í•˜ê±°ë‚˜, ì•„ë˜ ì˜ˆì‹œ ì£¼ì œë¥¼ ì„ íƒí•˜ì—¬ ì‹œì‘í•´ë³´ì„¸ìš”.")
        use_rag = st.toggle("âœ… RAG ê¸°ëŠ¥ ì‚¬ìš©í•˜ê¸° (ì§€ì‹ ë² ì´ìŠ¤ ì°¸ê³ )", value=True, help="RAG ê¸°ëŠ¥ì„ ì¼œë©´, AIê°€ ì „ë¬¸ ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ ë” ê¹Šì´ ìˆëŠ” ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“­ë‹ˆë‹¤.")
        st.write("---")
        
        example_options = {AI_ETHICS_KB[key]["title"]: key for key in AI_ETHICS_KB}
        options_list = ["ì£¼ì œ ì§ì ‘ ì…ë ¥..."] + list(example_options.keys())
        selected_topic_title = st.selectbox("ì˜ˆì‹œ ì£¼ì œ ì„ íƒ ë˜ëŠ” ì§ì ‘ ì…ë ¥:", options_list)

        if selected_topic_title != "ì£¼ì œ ì§ì ‘ ì…ë ¥...":
            st.session_state.teacher_input = AI_ETHICS_KB[example_options[selected_topic_title]]["example_prompt"]
        
        teacher_text = st.text_area("ì‹œë‚˜ë¦¬ì˜¤ ì†Œì¬:", value=st.session_state.teacher_input, height=150, key="teacher_input_area")

        if st.button("ì´ ë‚´ìš©ìœ¼ë¡œ êµìœ¡ ì½˜í…ì¸  ìƒì„±í•˜ê¸°"):
            if not teacher_text.strip():
                st.warning("ì‹œë‚˜ë¦¬ì˜¤ ì†Œì¬ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                st.session_state.teacher_input = teacher_text
                with st.spinner("AIê°€ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë§Œë“¤ê³  ìˆì–´ìš”..."):
                    retrieved_knowledge = retrieve_context(st.session_state.teacher_input, AI_ETHICS_KB) if use_rag else None
                    if use_rag:
                        if retrieved_knowledge:
                            st.success("âœ… RAG í™œì„±í™”: ê´€ë ¨ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ì°¸ê³ í•©ë‹ˆë‹¤.")
                        else:
                             st.info("â„¹ï¸ RAG í™œì„±í™”: í•˜ì§€ë§Œ ê´€ë ¨ëœ ì§€ì‹ ë² ì´ìŠ¤ë¥¼ ì°¾ì§€ ëª»í–ˆì–´ìš”.")
                    else:
                        st.warning("âŒ RAG ë¹„í™œì„±í™”: AIì˜ ìì²´ ì§€ì‹ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
                    
                    scenario_text = transform_scenario(st.session_state.teacher_input, retrieved_knowledge)
                    if scenario_text and parse_and_store_scenario(scenario_text):
                        st.session_state.full_log = f"**ì…ë ¥ ë‚´ìš©:** {st.session_state.teacher_input[:70]}..."
                        st.session_state.current_part = 0
                        st.session_state.stage = 'story'
                        st.rerun()
                    else:
                        st.error("AIê°€ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ë‹¤ í˜ë“¤ì–´í•˜ë„¤ìš”. ë‚´ìš©ì„ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„± í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    elif st.session_state.stage == 'story':
        if not st.session_state.full_scenario or st.session_state.current_part < 0:
            st.warning("ì´ì•¼ê¸°ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆì–´ìš”. ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘í•´ì£¼ì„¸ìš”.")
            if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"): restart_lesson(); st.rerun()
        else:
            part = st.session_state.full_scenario[st.session_state.current_part]
            current_story = f"\n\n---\n\n### ì´ì•¼ê¸° #{st.session_state.current_part + 1}\n{part['story']}"
            if current_story not in st.session_state.full_log: st.session_state.full_log += current_story
            st.markdown(st.session_state.full_log, unsafe_allow_html=True)
            st.info("ì, ì´ì œ ì–´ë–¤ ì„ íƒì„ í•´ë³¼ê¹Œìš”?")
            col1, col2 = st.columns(2)
            if col1.button(f"**ì„ íƒ A:** {part['choice_a']}", use_container_width=True, key=f"A_{st.session_state.current_part}"):
                st.session_state.full_log += f"\n\n**>> ë‚˜ì˜ ì„ íƒ #{st.session_state.current_part + 1} (A):** {part['choice_a']}"; st.session_state.stage = 'debate'; st.rerun()
            if col2.button(f"**ì„ íƒ B:** {part['choice_b']}", use_container_width=True, key=f"B_{st.session_state.current_part}"):
                st.session_state.full_log += f"\n\n**>> ë‚˜ì˜ ì„ íƒ #{st.session_state.current_part + 1} (B):** {part['choice_b']}"; st.session_state.stage = 'debate'; st.rerun()

    elif st.session_state.stage == 'debate':
        log_parts = re.split(r'\n\n(?=---\n\n|>> ë‚˜ì˜ ì„ íƒ|AI ì„ ìƒë‹˜:|ë‚˜ \(ì˜ê²¬)', st.session_state.full_log)
        for p in log_parts:
            p = p.strip()
            if p.startswith(">> ë‚˜ì˜ ì„ íƒ"): st.chat_message("user", avatar="ğŸ™‹â€â™‚ï¸").write(p)
            elif p.startswith("AI ì„ ìƒë‹˜:"): st.chat_message("assistant", avatar="ğŸ¤–").write(p.replace("AI ì„ ìƒë‹˜:", "**AI ì„ ìƒë‹˜:**"))
            elif p.startswith("ë‚˜ (ì˜ê²¬"): st.chat_message("user", avatar="ğŸ™‹â€â™‚ï¸").write(p)
            else: st.markdown(p, unsafe_allow_html=True)

        if st.session_state.debate_turns == 0:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                with st.spinner("AI ì„ ìƒë‹˜ì´ ì§ˆë¬¸ì„ ì¤€ë¹„í•˜ê³  ìˆì–´ìš”..."):
                    choice = st.session_state.full_log.split('>> ë‚˜ì˜ ì„ íƒ')[-1]
                    question = start_debate(st.session_state.full_log, choice)
                    st.session_state.full_log += f"\n\nAI ì„ ìƒë‹˜: {question}"; st.session_state.debate_turns = 1; st.rerun()
        elif st.session_state.debate_turns == 1:
            if reply := st.chat_input("ì„ ìƒë‹˜ì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:"):
                st.session_state.full_log += f"\n\në‚˜ (ì˜ê²¬ 1): {reply}"; st.session_state.debate_turns = 2; st.rerun()
        elif st.session_state.debate_turns == 2:
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                with st.spinner("AI ì„ ìƒë‹˜ì´ ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒê° ì¤‘ì´ì—ìš”..."):
                    question = continue_debate(st.session_state.full_log)
                    st.session_state.full_log += f"\n\nAI ì„ ìƒë‹˜: {question}"; st.session_state.debate_turns = 3; st.rerun()
        elif st.session_state.debate_turns == 3:
            if reply := st.chat_input("ì„ ìƒë‹˜ì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”:"):
                st.session_state.full_log += f"\n\në‚˜ (ì˜ê²¬ 2): {reply}"; st.session_state.debate_turns = 4; st.rerun()
        elif st.session_state.debate_turns == 4:
            st.info("í† ë¡ ì´ ì™„ë£Œë˜ì—ˆì–´ìš”. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°€ìš”!")
            is_last_part = st.session_state.current_part >= len(st.session_state.full_scenario) - 1
            if st.button("ë‹¤ìŒ ì´ì•¼ê¸°ë¡œ" if not is_last_part else "ìµœì¢… ì •ë¦¬ ë³´ê¸°"):
                st.session_state.debate_turns = 0; st.session_state.current_part += 1
                st.session_state.stage = 'conclusion' if is_last_part else 'story'
                st.rerun()

    elif st.session_state.stage == 'conclusion':
        st.markdown("### âœ¨ ìš°ë¦¬ì˜ ì „ì²´ ì´ì•¼ê¸°ì™€ í† ë¡  ì—¬ì • âœ¨")
        st.markdown(st.session_state.full_log, unsafe_allow_html=True)
        st.markdown("---")
        with st.spinner("AI ì„ ìƒë‹˜ì´ ìš°ë¦¬ì˜ ë©‹ì§„ ì—¬ì •ì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”..."):
            conclusion = generate_conclusion(st.session_state.full_log)
            st.balloons(); st.success("ëª¨ë“  ì´ì•¼ê¸°ê°€ ëë‚¬ì–´ìš”! ì •ë§ ìˆ˜ê³  ë§ì•˜ì–´ìš”!")
            st.markdown("### ìµœì¢… ì •ë¦¬"); st.write(conclusion)
        if st.button("ìƒˆë¡œìš´ ì£¼ì œë¡œ ë‹¤ì‹œ ì‹œì‘í•˜ê¸°"): restart_lesson(); st.rerun()

# --- 5. ë©”ì¸ ì•± ë¼ìš°íŒ… ---
st.sidebar.title("ë©”ë‰´")
app_mode = st.sidebar.radio(
    "ì›í•˜ëŠ” ê¸°ëŠ¥ì„ ì„ íƒí•˜ì„¸ìš”.",
    ("êµìœ¡ ì½˜í…ì¸  ìƒì„±", "RAG íš¨ê³¼ ë¹„êµ ë°ëª¨")
)

st.sidebar.write("---")
st.sidebar.info("ì´ ì•±ì€ ì´ˆë“±í•™ìƒì˜ AI ìœ¤ë¦¬ êµìœ¡ì„ ìœ„í•´ ì œì‘ë˜ì—ˆìŠµë‹ˆë‹¤.")

if app_mode == "êµìœ¡ ì½˜í…ì¸  ìƒì„±":
    run_main_app()
elif app_mode == "RAG íš¨ê³¼ ë¹„êµ ë°ëª¨":
    if 'app_mode' not in st.session_state or st.session_state.app_mode != 'demo':
        # ë°ëª¨ ëª¨ë“œë¡œ ì „í™˜ ì‹œ, ë©”ì¸ ì•±ì˜ ìƒíƒœ ì´ˆê¸°í™”
        keys_to_clear = ['stage', 'full_scenario', 'full_log', 'current_part', 'debate_turns', 'teacher_input']
        for key in keys_to_clear:
            if key in st.session_state:
                del st.session_state[key]
        st.session_state.app_mode = 'demo'

    run_comparison_demo()

