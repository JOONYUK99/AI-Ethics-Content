import streamlit as st
import google.generativeai as genai
import re
import urllib.parse

# --- 1. AI í•µì‹¬ ê¸°ëŠ¥ í•¨ìˆ˜ ì •ì˜ ---
def get_model(model_name='gemini-pro'):
    return genai.GenerativeModel(model_name)

def generate_story_part(topic, history_summary=""):
    model = get_model()
    if not history_summary:
        prompt = f"'{topic}'ë¼ëŠ” ì£¼ì œë¡œ, ì´ˆë“±í•™ìƒ ê³ í•™ë…„ì´ í¥ë¯¸ë¥¼ ëŠë‚„ ë§Œí•œ AI ìœ¤ë¦¬ ë”œë ˆë§ˆ ì´ì•¼ê¸°ì˜ 'ì²« ë¶€ë¶„'ì„ ë§Œë“¤ì–´ì¤˜. ì´ì•¼ê¸°ëŠ” 3~4ê°œì˜ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±í•˜ê³ , ì£¼ì¸ê³µì´ ì¤‘ìš”í•œ ê²°ì •ì„ ë‚´ë ¤ì•¼ í•˜ëŠ” ìˆœê°„ì—ì„œ ëë‚˜ì•¼ í•´."
    else:
        prompt = f"ë‹¤ìŒì€ ì§€ê¸ˆê¹Œì§€ ì§„í–‰ëœ ì´ì•¼ê¸°ì˜ ìš”ì•½ì´ì•¼: '{history_summary}'. ì´ ì´ì•¼ê¸°ì— ì´ì–´ì„œ, í•™ìƒì˜ ì„ íƒìœ¼ë¡œ ì¸í•´ ë²Œì–´ì§€ëŠ” 'ë‹¤ìŒ ì‚¬ê±´'ì„ 3~4ê°œì˜ ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜. ê·¸ë¦¬ê³  ë§ˆì°¬ê°€ì§€ë¡œ ì´ì•¼ê¸°ê°€ ë˜ ë‹¤ë¥¸ ì¤‘ìš”í•œ ê²°ì •ì„ ë‚´ë ¤ì•¼ í•˜ëŠ” ìˆœê°„ì—ì„œ ëë‚˜ë„ë¡ í•´ì¤˜."
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e: return f"ì´ì•¼ê¸° ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

def generate_image_keywords(story_part):
    model = get_model()
    prompt = f"ë‹¤ìŒ í•œêµ­ì–´ ë¬¸ì¥ì˜ í•µì‹¬ ë‚´ìš©ì„ ëŒ€í‘œí•˜ëŠ” ì˜ì–´ ë‹¨ì–´ 2ê°œë¥¼ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì§§ê²Œ ìš”ì•½í•´ì¤˜. ì˜ˆ: 'ë¯¸ë˜ ë„ì‹œì˜ ë¡œë´‡ ì¹œêµ¬ê°€ ì‚¬ëŒì„ ë„ì™€ì¤€ë‹¤' -> 'future city, robot friend'\n\në¬¸ì¥: {story_part}"
    try:
        response = model.generate_content(prompt)
        keywords = [keyword.strip() for keyword in response.text.strip().split(',')]
        return ",".join(keywords)
    except Exception:
        return "AI,robot,children"

def generate_choices_for_story(story_part):
    model = get_model()
    prompt = f"ì•„ë˜ ì´ì•¼ê¸°ì˜ ë§ˆì§€ë§‰ ìƒí™©ì—ì„œ ì£¼ì¸ê³µì´ í•  ìˆ˜ ìˆëŠ”, ìœ¤ë¦¬ì ìœ¼ë¡œ ìƒë°˜ëœ ë‘ ê°€ì§€ ì„ íƒì§€ë¥¼ ì´ˆë“±í•™ìƒ ëˆˆë†’ì´ì— ë§ì¶°ì„œ ê°„ê²°í•˜ê²Œ ë§Œë“¤ì–´ì¤˜.\n[ì¶œë ¥ í˜•ì‹]\nA: [A ì„ íƒì§€ ë‚´ìš©]\nB: [B ì„ íƒì§€ ë‚´ìš©]\n\n--- ì´ì•¼ê¸° ---\n{story_part}"
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e: return f"ì„ íƒì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

def start_debate(current_story_log, choice):
    model = get_model()
    prompt = f"ë‹¹ì‹ ì€ í•™ìƒë“¤ì„ ì•„ì£¼ ì•„ë¼ëŠ” ë‹¤ì •í•œ AI ìœ¤ë¦¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì´ ë°©ê¸ˆ ë‚´ë¦° ì„ íƒ('{choice}')ì„ ì¹­ì°¬í•˜ê³ , ì™œ ê·¸ë ‡ê²Œ ìƒê°í–ˆëŠ”ì§€ ë¶€ë“œëŸ½ê²Œ ì²« ì§ˆë¬¸ì„ ë˜ì ¸ì£¼ì„¸ìš”.\n\n--- ì´ì•¼ê¸°ì™€ í•™ìƒì˜ ì„ íƒ ---\n{current_story_log}\n\nAI ì„ ìƒë‹˜ì˜ ë”°ëœ»í•œ ì²« ì§ˆë¬¸:"
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e: return f"í† ë¡  ì‹œì‘ ì¤‘ ì˜¤ë¥˜: {e}"

def continue_debate(current_debate_history):
    model = get_model()
    prompt = f"ë‹¹ì‹ ì€ ë‹¤ì •í•œ AI ìœ¤ë¦¬ ì„ ìƒë‹˜ì…ë‹ˆë‹¤. í•™ìƒì˜ ì´ì „ ë‹µë³€ì— ê³µê°í•˜ë©° í† ë¡ ì„ ì´ì–´ê°€ì£¼ì„¸ìš”. 'í˜¹ì‹œ ì´ëŸ° ì ì€ ì–´ë–¨ê¹Œìš”?' ì™€ ê°™ì´ ë¶€ë“œëŸ¬ìš´ ë§íˆ¬ë¡œ ë°˜ëŒ€ ê´€ì ì´ë‚˜ ìƒˆë¡œìš´ ìƒê°í•´ë³¼ ê±°ë¦¬ë¥¼ ì§ˆë¬¸ìœ¼ë¡œ ì œì‹œí•´ì£¼ì„¸ìš”.\n\n--- ì§€ê¸ˆê¹Œì§€ì˜ í† ë¡  ë‚´ìš© ---\n{current_debate_history}\n\nAI ì„ ìƒë‹˜ì˜ ë‹¤ìŒ ì§ˆë¬¸:"
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e: return f"í† ë¡  ì¤‘ ì˜¤ë¥˜: {e}"

def generate_conclusion(final_history):
    model = get_model()
    prompt = (
        "ë‹¤ìŒì€ í•œ í•™ìƒì´ AI ìœ¤ë¦¬ ë¬¸ì œì— ëŒ€í•´ ì´ 4ë²ˆì˜ ì„ íƒê³¼ í† ë¡ ì„ ê±°ì¹œ ì „ì²´ ê¸°ë¡ì…ë‹ˆë‹¤.\n\n"
        "# ë‹¹ì‹ ì˜ ì—­í• :\n"
        "1. í•™ìƒì˜ ê³ ë¯¼ ê³¼ì •ì„ ìš”ì•½í•˜ê³ , ë¹„íŒì  ì‚¬ê³  ëŠ¥ë ¥ì„ ë”°ëœ»í•˜ê²Œ ì¹­ì°¬í•´ì£¼ì„¸ìš”.\n"
        "2. ì´ ìœ¤ë¦¬ì  ë”œë ˆë§ˆë¥¼ ë§ˆì£¼í–ˆì„ ë•Œ, ì´ˆë“±í•™ìƒì´ í˜„ì‹¤ì—ì„œ ìƒê°í•´ ë³´ê±°ë‚˜ ì‹¤ì²œí•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ 'ëŒ€ì²˜ ë°©ë²•'ì´ë‚˜ 'ë§ˆìŒê°€ì§'ì„ í•œë‘ ê°€ì§€ ì œì•ˆí•´ì£¼ì„¸ìš”.\n"
        "3. ì •ë‹µì€ ì—†ë‹¤ëŠ” ì ì„ ê°•ì¡°í•˜ë©°, í•™ìƒì˜ ì„±ì¥ì„ ê²©ë ¤í•˜ëŠ” ë©”ì‹œì§€ë¡œ ë§ˆë¬´ë¦¬í•´ì£¼ì„¸ìš”.\n\n"
        "--- ì „ì²´ ê¸°ë¡ ---\n"
        f"{final_history}"
    )
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e: return f"ê²°ë¡  ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}"

# --- 2. Streamlit ì•± UI ë° ë¡œì§ ---
st.set_page_config(page_title="AI ìœ¤ë¦¬ êµìœ¡ ì±—ë´‡", page_icon="âœ¨", layout="centered")
st.title("âœ¨ ì´ˆë“±í•™ìƒì„ ìœ„í•œ AI ìœ¤ë¦¬ êµìœ¡")

try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception:
    st.error("API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
    st.stop()

if 'stage' not in st.session_state:
    st.session_state.stage = 'start'
    st.session_state.full_log = ""
    st.session_state.current_story_part_log = ""
    st.session_state.choice_count = 0
    st.session_state.debate_turns = 0
    st.session_state.MAX_CHOICES = 4

def restart_lesson():
    st.session_state.stage = 'start'
    st.session_state.full_log = ""
    st.session_state.current_story_part_log = ""
    st.session_state.choice_count = 0
    st.session_state.debate_turns = 0

if st.session_state.stage == 'start':
    st.info("ì•ˆë…•í•˜ì„¸ìš”, ì¹œêµ¬ë“¤! AI ìœ¤ë¦¬ ë¬¸ì œì— ëŒ€í•´ í•¨ê»˜ ê³ ë¯¼í•´ë³´ëŠ” ìˆ˜ì—…ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•´ìš”.")
    topics = ["ììœ¨ì£¼í–‰ ìë™ì°¨ì˜ ìœ¤ë¦¬ì  ë”œë ˆë§ˆ", "ì¸ê³µì§€ëŠ¥ íŒì‚¬ì˜ ê³µì •ì„± ë¬¸ì œ", "AI ì°½ì‘ë¬¼ì˜ ì €ì‘ê¶Œ", "ê°œì¸ì •ë³´ë¥¼ í•™ìŠµí•œ AI ì±—ë´‡"]
    selected_topic = st.selectbox("ì˜¤ëŠ˜ íƒêµ¬í•´ë³¼ ì£¼ì œë¥¼ ì„ íƒí•´ë³¼ê¹Œìš”?", topics)
    if st.button("ìˆ˜ì—… ì‹œì‘í•˜ê¸°"):
        st.session_state.topic = selected_topic
        st.session_state.full_log = f"**ì£¼ì œ:** {st.session_state.topic}"
        st.session_state.stage = 'story'
        st.rerun()

elif st.session_state.stage == 'story':
    history_summary = st.session_state.full_log[-500:] if st.session_state.choice_count > 0 else ""
    st.markdown(f"### âœ¨ ìƒˆë¡œìš´ ì´ì•¼ê¸° #{st.session_state.choice_count + 1} âœ¨")
    with st.spinner(f"AIê°€ ì´ì•¼ê¸° #{st.session_state.choice_count + 1}ì„(ë¥¼) ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        story_part = generate_story_part(st.session_state.topic, history_summary)
        keywords = generate_image_keywords(story_part)
        encoded_keywords = urllib.parse.quote(keywords)
        st.image(f"https://placehold.co/600x300/E8E8E8/313131?text={encoded_keywords}", caption=f"AIê°€ ìƒê°í•œ ì´ë¯¸ì§€ í‚¤ì›Œë“œ: {keywords}")
        choices_text = generate_choices_for_story(story_part)
    
    st.write(story_part)
    st.session_state.current_story_part_log = f"### ì´ì•¼ê¸° #{st.session_state.choice_count + 1}\n{story_part}"
    
    try:
        match_a = re.search(r"A:\s*(.*)", choices_text, re.DOTALL)
        match_b = re.search(r"B:\s*(.*)", choices_text, re.DOTALL)
        if not (match_a and match_b): raise ValueError("ì„ íƒì§€ í˜•ì‹ ì˜¤ë¥˜")
        choice_a_text = match_a.group(1).strip()
        choice_b_text = match_b.group(1).strip()
        st.info("ì, ì´ì œ ì–´ë–¤ ì„ íƒì„ í•´ë³¼ê¹Œìš”?")
        col1, col2 = st.columns(2)
        if col1.button(f"A: {choice_a_text}", use_container_width=True, key=f"A_{st.session_state.choice_count}"):
            st.session_state.current_story_part_log += f"\n\n**>> ë‚˜ì˜ ì„ íƒ:** {choice_a_text}"; st.session_state.stage = 'debate'; st.rerun()
        if col2.button(f"B: {choice_b_text}", use_container_width=True, key=f"B_{st.session_state.choice_count}"):
            st.session_state.current_story_part_log += f"\n\n**>> ë‚˜ì˜ ì„ íƒ:** {choice_b_text}"; st.session_state.stage = 'debate'; st.rerun()
    except Exception as e:
        st.error(f"ì„ íƒì§€ë¥¼ ë§Œë“œëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”. AIê°€ ì´ìƒí•œ ë‹µë³€ì„ ì£¼ì—ˆì„ ìˆ˜ë„ ìˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
        if st.button("ì´ì•¼ê¸° ë‹¤ì‹œ ë§Œë“¤ê¸°"): st.rerun()

elif st.session_state.stage == 'debate':
    st.markdown(f"### ì´ì•¼ê¸° #{st.session_state.choice_count + 1} í† ë¡ ")
    log_parts = st.session_state.current_story_part_log.split('\n\n')
    for p in log_parts:
        if p.startswith("**>> ë‚˜ì˜ ì„ íƒ"): st.chat_message("user").write(p.replace("**>> ë‚˜ì˜ ì„ íƒ:**",""))
        elif p.startswith("**AI ì„ ìƒë‹˜:**"): st.chat_message("assistant").write(p.replace("**AI ì„ ìƒë‹˜:**",""))
        elif p.startswith("**ë‚˜ (ì˜ê²¬"): st.chat_message("user").write(p)
        else: st.write(p)
    
    if st.session_state.debate_turns == 0:
        with st.chat_message("assistant"):
            with st.spinner("AI ì„ ìƒë‹˜ì´ ì²« ì§ˆë¬¸ì„ ì¤€ë¹„í•˜ê³  ìˆì–´ìš”..."):
                question = start_debate(st.session_state.current_story_part_log, st.session_state.current_story_part_log.split('>> ë‚˜ì˜ ì„ íƒ:')[-1].strip())
                st.session_state.current_story_part_log += f"\n\n**AI ì„ ìƒë‹˜:** {question}"
                st.session_state.debate_turns = 1; st.rerun()
    elif st.session_state.debate_turns == 1:
        if reply := st.chat_input("ì²« ë²ˆì§¸ ì˜ê²¬ì„ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”:"):
            st.session_state.current_story_part_log += f"\n\n**ë‚˜ (ì˜ê²¬ 1):** {reply}"; st.session_state.debate_turns = 2; st.rerun()
    elif st.session_state.debate_turns == 2:
        with st.chat_message("assistant"):
            with st.spinner("AI ì„ ìƒë‹˜ì´ ë‹¤ìŒ ì§ˆë¬¸ì„ ìƒê° ì¤‘ì´ì—ìš”..."):
                question = continue_debate(st.session_state.current_story_part_log)
                st.session_state.current_story_part_log += f"\n\n**AI ì„ ìƒë‹˜:** {question}"; st.session_state.debate_turns = 3; st.rerun()
    elif st.session_state.debate_turns == 3:
        if reply := st.chat_input("ë‘ ë²ˆì§¸ ì˜ê²¬ì„ ì´ì•¼ê¸°í•´ì£¼ì„¸ìš”:"):
            st.session_state.current_story_part_log += f"\n\n**ë‚˜ (ì˜ê²¬ 2):** {reply}"; st.session_state.debate_turns = 4; st.rerun()
    elif st.session_state.debate_turns == 4:
        st.info("í† ë¡ ì´ ì™„ë£Œë˜ì—ˆì–´ìš”. ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°€ìš”!")
        st.session_state.full_log += f"\n\n---\n{st.session_state.current_story_part_log}"
        st.session_state.choice_count += 1
        if st.button("ë‹¤ìŒ ì´ì•¼ê¸°ë¡œ" if st.session_state.choice_count < st.session_state.MAX_CHOICES else "ìµœì¢… ì •ë¦¬ ë³´ê¸°"):
            st.session_state.debate_turns = 0; st.session_state.current_story_part_log = ""
            if st.session_state.choice_count >= st.session_state.MAX_CHOICES:
                st.session_state.stage = 'conclusion'
            else:
                st.session_state.stage = 'story'
            st.rerun()

elif st.session_state.stage == 'conclusion':
    st.markdown("### ğŸ“š ìš°ë¦¬ì˜ ì „ì²´ ì´ì•¼ê¸°ì™€ ê³ ë¯¼ ğŸ“š")
    st.markdown(st.session_state.full_log, unsafe_allow_html=True)
    st.markdown("---")
    with st.spinner("AI ì„ ìƒë‹˜ì´ ìš°ë¦¬ì˜ ë©‹ì§„ ì—¬ì •ì„ ì •ë¦¬í•˜ê³  ìˆì–´ìš”..."):
        conclusion = generate_conclusion(st.session_state.full_log)
        st.balloons(); st.success("ëª¨ë“  ì´ì•¼ê¸°ê°€ ëë‚¬ì–´ìš”! ì •ë§ ìˆ˜ê³  ë§ì•˜ì–´ìš”!")
        st.markdown("---"); st.markdown("### âœ¨ AI ì„ ìƒë‹˜ì˜ ìµœì¢… ì •ë¦¬ ë° ëŒ€ì²˜ë²• âœ¨"); st.write(conclusion)
    if st.button("ìƒˆë¡œìš´ ì£¼ì œë¡œ ë‹¤ì‹œ ì‹œì‘í•˜ê¸°"):
        restart_lesson(); st.rerun()
"""

#### ğŸ“ **`requirements.txt`** (ì´ ë‚´ìš©ë§Œ ë“¤ì–´ìˆëŠ” ìƒˆ í…ìŠ¤íŠ¸ íŒŒì¼)
```txt
streamlit
google-generativeai