import streamlit as st
from openai import OpenAI
import re

# --- 1. í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(page_title="ì­ˆë‹ˆë´‡ê³¼ í•¨ê»˜ í† ë¡ í•˜ê¸°", page_icon="ğŸ¤–")

# --- 2. OpenAI í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ---
try:
    # secrets.toml íŒŒì¼ì— OPENAI_API_KEYê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])
except Exception:
    st.error("âš ï¸ OpenAI API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”! (.streamlit/secrets.toml íŒŒì¼ í™•ì¸)")
    st.stop()

# --- 3. ì˜ˆì‹œ ì£¼ì œ ë°ì´í„° ---
EXAMPLE_TOPICS = {
    "AI ì˜ˆìˆ ê³¼ ì €ì‘ê¶Œ": "ìµœê·¼ ì—´ë¦° ë¯¸ìˆ  ëŒ€íšŒì—ì„œ AIë¡œ ê·¸ë¦° ê·¸ë¦¼ì´ 1ë“±ì„ ì°¨ì§€í•´ í° ë…¼ë€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ë¦¼ì„ ê·¸ë¦° í•™ìƒì€ AIì—ê²Œ ìˆ˜ë°± ë²ˆì˜ ì§€ì‹œì–´ë¥¼ ì…ë ¥í•˜ë©° ì›í•˜ëŠ” ê·¸ë¦¼ì„ ì–»ì—ˆë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì˜ ì €ì‘ê¶Œì€ ëˆ„êµ¬ì—ê²Œ ìˆì–´ì•¼ í• ê¹Œìš”?",
    "ììœ¨ì£¼í–‰ì°¨ì˜ ë”œë ˆë§ˆ": "ììœ¨ì£¼í–‰ì°¨ê°€ ê°‘ìê¸° ë‚˜íƒ€ë‚œ ì•„ì´ë“¤ì„ í”¼í•˜ë ¤ê³  í•¸ë“¤ì„ êº¾ìœ¼ë©´, ì°¨ì— íƒ€ê³  ìˆë˜ ë‚´ê°€ ë‹¤ì¹  ìˆ˜ ìˆëŠ” ìœ„í—˜í•œ ìƒí™©ì— ì²˜í–ˆìŠµë‹ˆë‹¤. ì´ë•Œ ììœ¨ì£¼í–‰ì°¨ëŠ” ì–´ë–¤ ì„ íƒì„ í•´ì•¼ í• ê¹Œìš”?",
    "AI íŠœí„°ì™€ ê°œì¸ì •ë³´": "ë‚˜ì˜ ëª¨ë“  ê²ƒì„ ì•Œê³  ë‚˜ì—ê²Œ ë”± ë§ëŠ” ê³µë¶€ë²•ì„ ì•Œë ¤ì£¼ëŠ” AI í•™ìŠµ ë¡œë´‡ì´ ìƒê²¼ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ë¡œë´‡ì´ ë‚˜ì˜ ëª¨ë“  í•™ìŠµ ê¸°ë¡ì„ ë°ì´í„° ì„¼í„°ë¡œ ì „ì†¡í•˜ê³  ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.",
    "ë”¥í˜ì´í¬ì™€ ê°€ì§œ ë‰´ìŠ¤": "ì¹œí•œ ì¹œêµ¬ì˜ ì–¼êµ´ì´ ë‹´ê¸´ ì´ìƒí•œ ë™ì˜ìƒì„ ì¸í„°ë„·ì—ì„œ ë³´ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì¹œêµ¬ëŠ” ê·¸ëŸ° ì˜ìƒì„ ì°ì€ ì ì´ ì—†ë‹¤ê³  ë§í•˜ëŠ”ë°, ì˜ìƒì€ ë„ˆë¬´ë‚˜ ì§„ì§œ ê°™ì•„ì„œ ë°˜ ì¹œêµ¬ë“¤ ì‚¬ì´ì— ì†Œë¬¸ì´ í¼ì§€ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤.",
    "AI ì¶”ì²œì˜ í¸í–¥ì„±": "ìƒˆë¡œ ë‚˜ì˜¨ ë™ì˜ìƒ ì•±ì„ ì‚¬ìš©í•˜ëŠ”ë°, ë‚˜ì—ê²ŒëŠ” í•­ìƒ ì•„ì´ëŒ ì¶¤ ì˜ìƒë§Œ ì¶”ì²œë˜ê³ , ë‚´ ë‚¨ë™ìƒì—ê²ŒëŠ” ê²Œì„ ì˜ìƒë§Œ ì¶”ì²œë˜ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë‚˜ëŠ” ê²Œì„ë„ ì¢‹ì•„í•˜ëŠ”ë° ì™œ ì•±ì€ ë‚˜ì—ê²Œ ê²Œì„ ì˜ìƒì„ ë³´ì—¬ì£¼ì§€ ì•ŠëŠ” ê±¸ê¹Œìš”?"
}

# --- 4. AI ë¡œì§ í•¨ìˆ˜ë“¤ (GPT-4o ì ìš©) ---

def ask_gpt(prompt):
    """OpenAI GPT-4o ëª¨ë¸ì—ê²Œ ì§ˆë¬¸í•˜ê³  ë‹µì„ ë°›ëŠ” ê³µí†µ í•¨ìˆ˜"""
    try:
        response = client.chat.completions.create(
            model="gpt-4o",  # ìµœì‹  GPT-4o ëª¨ë¸ ì‚¬ìš©
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒì„ ìœ„í•œ ë‹¤ì •í•œ AI ìœ¤ë¦¬ ì„ ìƒë‹˜ 'ì­ˆë‹ˆë´‡'ì…ë‹ˆë‹¤. ë‹µë³€ì€ í•­ìƒ ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ í•´ì£¼ì„¸ìš”."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7  # ì°½ì˜ì„±ê³¼ ì¼ê´€ì„±ì˜ ê· í˜•
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"GPT ì‘ë‹µ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”: {e}")
        return None

def transform_scenario(teacher_input):
    """ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±"""
    prompt = (
        "ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒ ê³ í•™ë…„ ëˆˆë†’ì´ì— ë§ì¶° AI ìœ¤ë¦¬ êµìœ¡ìš© ì¸í„°ë™í‹°ë¸Œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.\n"
        "ì•„ë˜ 'ì…ë ¥ ë‚´ìš©'ì„ ë°”íƒ•ìœ¼ë¡œ, í•™ìƒë“¤ì´ ëª°ì…í•  ìˆ˜ ìˆëŠ” ì™„ê²°ëœ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.\n"
        "ì´ì•¼ê¸°ëŠ” ì´ 4ê°œì˜ íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ë©°, ê° íŒŒíŠ¸ ëì—ëŠ” ì£¼ì¸ê³µì˜ ê³ ë¯¼ì´ ë“œëŸ¬ë‚˜ëŠ” ë‘ ê°€ì§€ ì„ íƒì§€ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n\n"
        
        "# í•„ìˆ˜ ì¶œë ¥ í˜•ì‹:\n"
        "[STORY 1] ... [CHOICE 1A] ... [CHOICE 1B] ...\n---\n"
        "[STORY 2] ... [CHOICE 2A] ... [CHOICE 2B] ...\n---\n"
        "[STORY 3] ... [CHOICE 3A] ... [CHOICE 3B] ...\n---\n"
        "[STORY 4] ... [CHOICE 4A] ... [CHOICE 4B] ...\n\n"
        
        f"--- ì…ë ¥ ë‚´ìš© ---\n{teacher_input}"
    )
    return ask_gpt(prompt)

def analyze_student_response(debate_history):
    """í•™ìƒ ë‹µë³€ ë¶„ì„ (ê°ë… AI)"""
    prompt = (
        "ì•„ë˜ í† ë¡  ë‚´ìš© ì¤‘ í•™ìƒì˜ ë§ˆì§€ë§‰ ë‹µë³€ì„ ë³´ê³  ë‹¤ìŒ 4ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.\n"
        "ë‹µë³€ì€ ì˜¤ì§ í‚¤ì›Œë“œë§Œ ì¶œë ¥í•˜ì„¸ìš”.\n\n"
        "# í‰ê°€ ì˜µì…˜:\n"
        "- ê¹Šê²Œ íŒŒê³ ë“¤ê¸°\n"
        "- í† ë¡  ì´ì–´ê°€ê¸°\n"
        "- ì‰½ê²Œ ì§ˆë¬¸í•˜ê¸°\n"
        "- í† ë¡  ë§ˆë¬´ë¦¬í•˜ê¸°\n\n"
        f"--- í† ë¡  ë‚´ìš© ---\n{debate_history}"
    )
    response = ask_gpt(prompt)
    if response:
        if "ê¹Šê²Œ" in response: return "deepen"
        if "ì‰½ê²Œ" in response: return "simplify"
        if "ë§ˆë¬´ë¦¬" in response: return "end_early"
    return "continue"

def generate_simpler_question(debate_history):
    """ì‰¬ìš´ ì§ˆë¬¸ ìƒì„±"""
    prompt = (
        "í•™ìƒì´ ë‹µë³€ì„ ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ê²©ë ¤í•˜ë©° 'ì˜ˆ/ì•„ë‹ˆì˜¤'ë‚˜ 'ì„ íƒì§€' í˜•íƒœì˜ ì‰¬ìš´ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.\n"
        f"--- í† ë¡  ë‚´ìš© ---\n{debate_history}\n\n"
        "ì­ˆë‹ˆë´‡ì˜ ì‰¬ìš´ ì§ˆë¬¸:"
    )
    return ask_gpt(prompt)

def continue_debate(debate_history, level="normal"):
    """ì¼ë°˜/ì‹¬í™” ì§ˆë¬¸ ìƒì„±"""
    instruction = "ë°˜ë¡ ì„ ì œê¸°í•˜ê±°ë‚˜ ê´€ì ì„ ë°”ê¾¸ëŠ” ì‹¬í™” ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”." if level == "deepen" else "ìƒê°ì˜ í­ì„ ë„“íˆëŠ” ë‹¤ìŒ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
    prompt = (
        f"{instruction}\n"
        "í•™ìƒì˜ ì˜ê²¬ì„ ê¹Šì´ ê³µê°í•˜ê³  ì¡´ì¤‘í•´ì£¼ì„¸ìš”. ë§íˆ¬ëŠ” ì¹œê·¼í•˜ê²Œ í•´ìš”ì²´(~í•´ìš”)ë¥¼ ì¨ì£¼ì„¸ìš”.\n"
        f"--- í† ë¡  ë‚´ìš© ---\n{debate_history}\n\n"
        "ì­ˆë‹ˆë´‡ì˜ ë‹¤ìŒ ì§ˆë¬¸:"
    )
    return ask_gpt(prompt)

def parse_and_store_scenario(generated_text):
    """ìƒì„±ëœ í…ìŠ¤íŠ¸ íŒŒì‹±"""
    if not generated_text: return False
    st.session_state.full_scenario = []
    parts = generated_text.split('---')
    if len(parts) < 4: return False
    for part in parts:
        try:
            story = re.search(r"\[STORY\s?\d\](.*?)(?=\[CHOICE\s?\dA\])", part, re.DOTALL).group(1).strip()
            choice_a = re.search(r"\[CHOICE\s?\dA\](.*?)(?=\[CHOICE\s?\dB\])", part, re.DOTALL).group(1).strip()
            choice_b = re.search(r"\[CHOICE\s?\dB\](.*)", part, re.DOTALL).group(1).strip()
            st.session_state.full_scenario.append({"story": story, "choice_a": choice_a, "choice_b": choice_b})
        except Exception:
            continue
    return len(st.session_state.full_scenario) >= 4

def start_debate(history, choice):
    """í† ë¡  ì‹œì‘ ì§ˆë¬¸"""
    prompt = (
        "í•™ìƒì˜ ì„ íƒì„ ì§€ì§€í•˜ë©° ìì—°ìŠ¤ëŸ½ê²Œ í† ë¡ ì„ ì‹œì‘í•˜ëŠ” ì²« ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.\n"
        f"--- ì´ì•¼ê¸°ì™€ ì„ íƒ ---\n{history}\ní•™ìƒì˜ ì„ íƒ: {choice}\n\nì­ˆë‹ˆë´‡:"
    )
    return ask_gpt(prompt)

def generate_conclusion(final_history):
    """ìµœì¢… í”¼ë“œë°±"""
    prompt = (
        "í•™ìƒì˜ ì „ì²´ í† ë¡  ê¸°ë¡ì„ ë³´ê³ , ì •ë‹µë³´ë‹¤ëŠ” ê³ ë¯¼í•˜ëŠ” ê³¼ì •ì´ ì¤‘ìš”í–ˆìŒì„ ì¹­ì°¬í•˜ëŠ” ë”°ëœ»í•œ ë§ˆë¬´ë¦¬ ë©˜íŠ¸ë¥¼ í•´ì£¼ì„¸ìš”.\n"
        f"--- ì „ì²´ ê¸°ë¡ ---\n{final_history}"
    )
    return ask_gpt(prompt)

# --- 5. ë©”ì¸ ì•± ë¡œì§ (UI) ---

def run_main_app():
    st.header("ğŸ¤– ì­ˆë‹ˆë´‡ê³¼ í•¨ê»˜ í† ë¡ í•˜ê¸° (GPT-4o ver.)")
    st.caption("OpenAI GPT-4o ëª¨ë¸ì´ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ì¤ë‹ˆë‹¤.")

    # ì„¸ì…˜ ì´ˆê¸°í™”
    if 'stage' not in st.session_state:
        st.session_state.stage = 'start'
        st.session_state.full_scenario = []
        st.session_state.full_log = ""
        st.session_state.current_part = -1
        st.session_state.debate_turns = 0
        st.session_state.debate_finished = False

    MAX_DEBATE_REPLIES = 3

    def restart():
        for key in ['stage', 'full_scenario', 'full_log', 'current_part', 'debate_turns', 'debate_finished']:
            if key in st.session_state: del st.session_state[key]
        st.rerun()

    # [1ë‹¨ê³„] ì‹œì‘ í™”ë©´
    if st.session_state.stage == 'start':
        st.info("í† ë¡ í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ê³ ë¥´ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ë©´, ì­ˆë‹ˆë´‡ì´ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ì¤„ ê±°ì•¼!")
        
        options_list = ["ì§ì ‘ ì…ë ¥..."] + list(EXAMPLE_TOPICS.keys())
        selected_topic = st.selectbox("ì£¼ì œ ì„ íƒ:", options_list)

        default_text = ""
        if selected_topic != "ì§ì ‘ ì…ë ¥...":
            default_text = EXAMPLE_TOPICS[selected_topic]
        
        teacher_input = st.text_area("ì‹œë‚˜ë¦¬ì˜¤ ì†Œì¬ ì…ë ¥:", value=default_text, height=150)

        if st.button("í† ë¡  ì‹œì‘í•˜ê¸° âœ¨"):
            if not teacher_input.strip():
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ì­ˆë‹ˆë´‡(GPT)ì´ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ê³  ìˆì–´ìš”..."):
                    scenario_text = transform_scenario(teacher_input)
                    
                    if scenario_text and parse_and_store_scenario(scenario_text):
                        st.session_state.full_log = f"**ì£¼ì œ:** {teacher_input[:50]}..."
                        st.session_state.current_part = 0
                        st.session_state.stage = 'story'
                        st.rerun()
                    else:
                        st.error("ì´ì•¼ê¸°ë¥¼ ë§Œë“œëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    # [2ë‹¨ê³„] ì´ì•¼ê¸° ì§„í–‰ ë° ì„ íƒ
    elif st.session_state.stage == 'story':
        part = st.session_state.full_scenario[st.session_state.current_part]
        current_story = f"\n\n---\n\n### ğŸ“– ì´ì•¼ê¸° #{st.session_state.current_part + 1}\n{part['story']}"
        
        if current_story.strip() not in st.session_state.full_log:
            st.session_state.full_log += current_story
            
        st.markdown(current_story)
        st.info("ì–´ë–¤ ì„ íƒì„ í• ë˜?")
        
        c1, c2 = st.columns(2)
        if c1.button(f"ğŸ…°ï¸ {part['choice_a']}", use_container_width=True):
            st.session_state.full_log += f"\n\n**>> ë‚˜ì˜ ì„ íƒ(A):** {part['choice_a']}"
            st.session_state.stage = 'debate'
            st.rerun()
        if c2.button(f"ğŸ…±ï¸ {part['choice_b']}", use_container_width=True):
            st.session_state.full_log += f"\n\n**>> ë‚˜ì˜ ì„ íƒ(B):** {part['choice_b']}"
            st.session_state.stage = 'debate'
            st.rerun()

    # [3ë‹¨ê³„] í† ë¡  ì§„í–‰
    elif st.session_state.stage == 'debate':
        for msg in st.session_state.full_log.split('\n\n'):
            msg = msg.strip()
            if not msg: continue
            if msg.startswith(">> ë‚˜ì˜ ì„ íƒ"): st.chat_message("user", avatar="ğŸ™‹").write(msg)
            elif msg.startswith("ì­ˆë‹ˆë´‡:"): st.chat_message("assistant", avatar="ğŸ¤–").write(msg.replace("ì­ˆë‹ˆë´‡:", "**ì­ˆë‹ˆë´‡:**"))
            elif msg.startswith("ë‚˜ (ì˜ê²¬"): st.chat_message("user", avatar="ğŸ™‹").write(msg)
            elif "### ğŸ“– ì´ì•¼ê¸°" in msg: st.markdown(msg)

        if st.session_state.debate_finished:
            st.success("ì´ë²ˆ í† ë¡ ì´ ëë‚¬ì–´!")
            is_last = st.session_state.current_part >= len(st.session_state.full_scenario) - 1
            if st.button("ë‹¤ìŒ ì´ì•¼ê¸°ë¡œ ê°€ê¸° â¡ï¸" if not is_last else "ìµœì¢… ê²°ê³¼ ë³´ê¸° ğŸ†"):
                st.session_state.debate_turns = 0
                st.session_state.debate_finished = False
                st.session_state.current_part += 1
                st.session_state.stage = 'conclusion' if is_last else 'story'
                st.rerun()
        
        else:
            if st.session_state.debate_turns == 0:
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    with st.spinner("ì­ˆë‹ˆë´‡ì´ ìƒê° ì¤‘..."):
                        last_choice = st.session_state.full_log.split('>> ë‚˜ì˜ ì„ íƒ')[-1]
                        q = start_debate(st.session_state.full_log, last_choice)
                        st.write(f"**ì­ˆë‹ˆë´‡:** {q}")
                        st.session_state.full_log += f"\n\nì­ˆë‹ˆë´‡: {q}"
                        st.session_state.debate_turns = 1

            elif st.session_state.debate_turns % 2 != 0:
                if user_input := st.chat_input(f"ë‚´ ìƒê° ë§í•˜ê¸° ({ (st.session_state.debate_turns+1)//2 }/{MAX_DEBATE_REPLIES})"):
                    st.session_state.full_log += f"\n\në‚˜ (ì˜ê²¬): {user_input}"
                    st.session_state.debate_turns += 1
                    st.rerun()

            else:
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    with st.spinner("ì­ˆë‹ˆë´‡ì´ ë‹µë³€ì„ ì½ê³  ìˆì–´ìš”..."):
                        decision = analyze_student_response(st.session_state.full_log)
                        
                        if decision == "end_early" or (st.session_state.debate_turns / 2) >= MAX_DEBATE_REPLIES:
                            msg = "ì¢‹ì€ ì˜ê²¬ì´ì•¼! ë„¤ ìƒê°ì„ ë“¤ë ¤ì¤˜ì„œ ê³ ë§ˆì›Œ. ìš°ë¦¬ ì´ì œ ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°€ ë³¼ê¹Œ?"
                            st.write(f"**ì­ˆë‹ˆë´‡:** {msg}")
                            st.session_state.full_log += f"\n\nì­ˆë‹ˆë´‡: {msg}"
                            st.session_state.debate_finished = True
                            st.rerun()
                        else:
                            if decision == "simplify": q = generate_simpler_question(st.session_state.full_log)
                            elif decision == "deepen": q = continue_debate(st.session_state.full_log, "deepen")
                            else: q = continue_debate(st.session_state.full_log, "normal")
                            
                            st.write(f"**ì­ˆë‹ˆë´‡:** {q}")
                            st.session_state.full_log += f"\n\nì­ˆë‹ˆë´‡: {q}"
                            st.session_state.debate_turns += 1
                            st.rerun()

    # [4ë‹¨ê³„] ìµœì¢… ê²°ê³¼
    elif st.session_state.stage == 'conclusion':
        st.balloons()
        st.header("ğŸ‰ í† ë¡  ì™„ë£Œ!")
        st.subheader("ìš°ë¦¬ê°€ ë‚˜ëˆˆ ì´ì•¼ê¸°ë“¤")
        st.text_area("í™œë™ ê¸°ë¡", st.session_state.full_log, height=300)
        
        st.subheader("ğŸ’Œ ì­ˆë‹ˆë´‡ì˜ í¸ì§€")
        with st.spinner("í¸ì§€ ì“°ëŠ” ì¤‘..."):
            final_comment = generate_conclusion(st.session_state.full_log)
            st.write(final_comment)
            
        if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
            restart()

if __name__ == "__main__":
    run_main_app()
