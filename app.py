import streamlit as st
import google.generativeai as genai
import re

# --- 1. í˜ì´ì§€ ì„¤ì • ë° ì œëª© ---
st.set_page_config(page_title="ì­ˆë‹ˆë´‡ê³¼ í•¨ê»˜ í† ë¡ í•˜ê¸°", page_icon="ğŸ¤–")

# --- 2. ì˜ˆì‹œ ì£¼ì œ ë°ì´í„° ---
EXAMPLE_TOPICS = {
    "AI ì˜ˆìˆ ê³¼ ì €ì‘ê¶Œ": "ìµœê·¼ ì—´ë¦° ë¯¸ìˆ  ëŒ€íšŒì—ì„œ AIë¡œ ê·¸ë¦° ê·¸ë¦¼ì´ 1ë“±ì„ ì°¨ì§€í•´ í° ë…¼ë€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤. ê·¸ë¦¼ì„ ê·¸ë¦° í•™ìƒì€ AIì—ê²Œ ìˆ˜ë°± ë²ˆì˜ ì§€ì‹œì–´ë¥¼ ì…ë ¥í•˜ë©° ì›í•˜ëŠ” ê·¸ë¦¼ì„ ì–»ì—ˆë‹¤ê³  ì£¼ì¥í•©ë‹ˆë‹¤. ì´ ê·¸ë¦¼ì˜ ì €ì‘ê¶Œì€ ëˆ„êµ¬ì—ê²Œ ìˆì–´ì•¼ í• ê¹Œìš”?",
    "ììœ¨ì£¼í–‰ì°¨ì˜ ë”œë ˆë§ˆ": "ììœ¨ì£¼í–‰ì°¨ê°€ ê°‘ìê¸° ë‚˜íƒ€ë‚œ ì•„ì´ë“¤ì„ í”¼í•˜ë ¤ê³  í•¸ë“¤ì„ êº¾ìœ¼ë©´, ì°¨ì— íƒ€ê³  ìˆë˜ ë‚´ê°€ ë‹¤ì¹  ìˆ˜ ìˆëŠ” ìœ„í—˜í•œ ìƒí™©ì— ì²˜í–ˆìŠµë‹ˆë‹¤. ì´ë•Œ ììœ¨ì£¼í–‰ì°¨ëŠ” ì–´ë–¤ ì„ íƒì„ í•´ì•¼ í• ê¹Œìš”?",
    "AI íŠœí„°ì™€ ê°œì¸ì •ë³´": "ë‚˜ì˜ ëª¨ë“  ê²ƒì„ ì•Œê³  ë‚˜ì—ê²Œ ë”± ë§ëŠ” ê³µë¶€ë²•ì„ ì•Œë ¤ì£¼ëŠ” AI í•™ìŠµ ë¡œë´‡ì´ ìƒê²¼ìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ë¡œë´‡ì´ ë‚˜ì˜ ëª¨ë“  í•™ìŠµ ê¸°ë¡ì„ ë°ì´í„° ì„¼í„°ë¡œ ì „ì†¡í•˜ê³  ìˆë‹¤ëŠ” ì‚¬ì‹¤ì„ ì•Œê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤.",
    "ë”¥í˜ì´í¬ì™€ ê°€ì§œ ë‰´ìŠ¤": "ì¹œí•œ ì¹œêµ¬ì˜ ì–¼êµ´ì´ ë‹´ê¸´ ì´ìƒí•œ ë™ì˜ìƒì„ ì¸í„°ë„·ì—ì„œ ë³´ê²Œ ë˜ì—ˆìŠµë‹ˆë‹¤. ì¹œêµ¬ëŠ” ê·¸ëŸ° ì˜ìƒì„ ì°ì€ ì ì´ ì—†ë‹¤ê³  ë§í•˜ëŠ”ë°, ì˜ìƒì€ ë„ˆë¬´ë‚˜ ì§„ì§œ ê°™ì•„ì„œ ë°˜ ì¹œêµ¬ë“¤ ì‚¬ì´ì— ì†Œë¬¸ì´ í¼ì§€ê¸° ì‹œì‘í–ˆìŠµë‹ˆë‹¤.",
    "AI ì¶”ì²œì˜ í¸í–¥ì„±": "ìƒˆë¡œ ë‚˜ì˜¨ ë™ì˜ìƒ ì•±ì„ ì‚¬ìš©í•˜ëŠ”ë°, ë‚˜ì—ê²ŒëŠ” í•­ìƒ ì•„ì´ëŒ ì¶¤ ì˜ìƒë§Œ ì¶”ì²œë˜ê³ , ë‚´ ë‚¨ë™ìƒì—ê²ŒëŠ” ê²Œì„ ì˜ìƒë§Œ ì¶”ì²œë˜ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ë‚˜ëŠ” ê²Œì„ë„ ì¢‹ì•„í•˜ëŠ”ë° ì™œ ì•±ì€ ë‚˜ì—ê²Œ ê²Œì„ ì˜ìƒì„ ë³´ì—¬ì£¼ì§€ ì•ŠëŠ” ê±¸ê¹Œìš”?"
}

# --- 3. ê¸°ë³¸ ì„¤ì • ë° í•¨ìˆ˜ ---
# API í‚¤ ì„¤ì •
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except Exception:
    st.error("âš ï¸ êµ¬ê¸€ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”! (.streamlit/secrets.toml íŒŒì¼ í™•ì¸)")
    st.stop()

def get_model():
    """
    Gemini ìµœì‹  ëª¨ë¸(Flash)ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜
    * ì†ë„ê°€ ë¹ ë¥´ê³  ë¬´ë£Œ í‹°ì–´ì—ì„œ ì•ˆì •ì ì…ë‹ˆë‹¤.
    """
    return genai.GenerativeModel('gemini-1.5-flash')

# --- 4. AI ë¡œì§ í•¨ìˆ˜ë“¤ ---

def transform_scenario(teacher_input):
    """ì„ ìƒë‹˜ì˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ 4ë‹¨ê³„ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±"""
    model = get_model()
    prompt = (
        "ë‹¹ì‹ ì€ ì´ˆë“±í•™ìƒ ê³ í•™ë…„ ëˆˆë†’ì´ì— ë§ì¶° AI ìœ¤ë¦¬ êµìœ¡ìš© ì¸í„°ë™í‹°ë¸Œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ ì‘ê°€ 'ì­ˆë‹ˆë´‡'ì…ë‹ˆë‹¤.\n"
        "ì•„ë˜ 'ì…ë ¥ ë‚´ìš©'ì„ ë°”íƒ•ìœ¼ë¡œ, í•™ìƒë“¤ì´ ëª°ì…í•  ìˆ˜ ìˆëŠ” ì™„ê²°ëœ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.\n"
        "ì´ì•¼ê¸°ëŠ” ì´ 4ê°œì˜ íŒŒíŠ¸ë¡œ êµ¬ì„±ë˜ë©°, ê° íŒŒíŠ¸ ëì—ëŠ” ì£¼ì¸ê³µì˜ ê³ ë¯¼ì´ ë“œëŸ¬ë‚˜ëŠ” ë‘ ê°€ì§€ ì„ íƒì§€ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.\n\n"
        
        "# í•„ìˆ˜ ì¶œë ¥ í˜•ì‹:\n"
        "[STORY 1] ... [CHOICE 1A] ... [CHOICE 1B] ...\n---\n"
        "[STORY 2] ... [CHOICE 2A] ... [CHOICE 2B] ...\n---\n"
        "[STORY 3] ... [CHOICE 3A] ... [CHOICE 3B] ...\n---\n"
        "[STORY 4] ... [CHOICE 4A] ... [CHOICE 4B] ...\n\n"
        
        f"--- ì…ë ¥ ë‚´ìš© ---\n{teacher_input}"
    )
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception as e:
        st.error(f"ì‹œë‚˜ë¦¬ì˜¤ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def analyze_student_response(debate_history):
    """í•™ìƒ ë‹µë³€ ë¶„ì„ (ê°ë… AI)"""
    model = get_model()
    prompt = (
        "ë‹¹ì‹ ì€ í•™ìƒì˜ í† ë¡  ëŠ¥ë ¥ì„ ë¶„ì„í•˜ëŠ” êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n"
        "ì•„ë˜ í† ë¡  ë‚´ìš© ì¤‘ í•™ìƒì˜ ë§ˆì§€ë§‰ ë‹µë³€ì„ ë³´ê³  ë‹¤ìŒ 4ê°€ì§€ ì¤‘ í•˜ë‚˜ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.\n\n"
        "# í‰ê°€ ì˜µì…˜:\n"
        "- ê¹Šê²Œ íŒŒê³ ë“¤ê¸°: í•™ìƒì´ ì´í•´ë¥¼ ì˜í•¨. ì‹¬í™” ì§ˆë¬¸ í•„ìš”.\n"
        "- í† ë¡  ì´ì–´ê°€ê¸°: ë¬´ë‚œí•œ ì§„í–‰.\n"
        "- ì‰½ê²Œ ì§ˆë¬¸í•˜ê¸°: í•™ìƒì´ ì–´ë ¤ì›Œí•¨. ì‰¬ìš´ ì§ˆë¬¸ í•„ìš”.\n"
        "- í† ë¡  ë§ˆë¬´ë¦¬í•˜ê¸°: ì£¼ì œ ì´íƒˆ ë˜ëŠ” ë¶€ë‹´ê°. ë§ˆë¬´ë¦¬ í•„ìš”.\n\n"
        f"--- í† ë¡  ë‚´ìš© ---\n{debate_history}\n\n"
        "# í‰ê°€ ê²°ê³¼ (ì˜µì…˜ ì¤‘ í•˜ë‚˜ë§Œ ì„ íƒ):"
    )
    try:
        response = model.generate_content(prompt)
        text = response.text.strip()
        if "ê¹Šê²Œ íŒŒê³ ë“¤ê¸°" in text: return "deepen"
        elif "ì‰½ê²Œ ì§ˆë¬¸í•˜ê¸°" in text: return "simplify"
        elif "í† ë¡  ë§ˆë¬´ë¦¬í•˜ê¸°" in text: return "end_early"
        else: return "continue"
    except Exception:
        return "continue"

def generate_simpler_question(debate_history):
    """ì‰¬ìš´ ì§ˆë¬¸ ìƒì„±"""
    model = get_model()
    prompt = (
        "ë‹¹ì‹ ì€ ë‹¤ì •í•œ AI ì¹œêµ¬ 'ì­ˆë‹ˆë´‡'ì…ë‹ˆë‹¤.\n"
        "í•™ìƒì´ ë‹µë³€ì„ ì–´ë ¤ì›Œí•©ë‹ˆë‹¤. ê²©ë ¤í•˜ë©° 'ì˜ˆ/ì•„ë‹ˆì˜¤'ë‚˜ 'ì„ íƒì§€' í˜•íƒœì˜ ì‰¬ìš´ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.\n\n"
        f"--- í† ë¡  ë‚´ìš© ---\n{debate_history}\n\n"
        "ì­ˆë‹ˆë´‡ì˜ ì‰¬ìš´ ì§ˆë¬¸:"
    )
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception:
        return "ì¡°ê¸ˆ ì–´ë ¤ìš´ê°€ìš”? ê´œì°®ì•„ìš”! ê·¸ëŸ¼ ê°„ë‹¨í•˜ê²Œ ë‹¤ì‹œ ìƒê°í•´ë³¼ê¹Œìš”?"

def continue_debate(debate_history, level="normal"):
    """ì¼ë°˜/ì‹¬í™” ì§ˆë¬¸ ìƒì„±"""
    model = get_model()
    instruction = "ë°˜ë¡ ì„ ì œê¸°í•˜ê±°ë‚˜ ê´€ì ì„ ë°”ê¾¸ëŠ” ì‹¬í™” ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”." if level == "deepen" else "ìƒê°ì˜ í­ì„ ë„“íˆëŠ” ë‹¤ìŒ ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”."
    prompt = (
        f"ë‹¹ì‹ ì€ ë‹¤ì •í•œ AI ì¹œêµ¬ 'ì­ˆë‹ˆë´‡'ì…ë‹ˆë‹¤. {instruction}\n"
        "í•™ìƒì˜ ì˜ê²¬ì„ ê¹Šì´ ê³µê°í•˜ê³  ì¡´ì¤‘í•´ì£¼ì„¸ìš”. ë§íˆ¬ëŠ” ì¹œê·¼í•˜ê²Œ í•´ìš”ì²´(~í•´ìš”)ë¥¼ ì¨ì£¼ì„¸ìš”.\n\n"
        f"--- í† ë¡  ë‚´ìš© ---\n{debate_history}\n\n"
        "ì­ˆë‹ˆë´‡ì˜ ë‹¤ìŒ ì§ˆë¬¸:"
    )
    try:
        response = model.generate_content(prompt)
        return response.text.strip()
    except Exception:
        return "ì¢‹ì€ ìƒê°ì´ë„¤ìš”! ë˜ ë‹¤ë¥¸ ìƒê°ì€ ì—†ë‚˜ìš”?"

def parse_and_store_scenario(generated_text):
    """ìƒì„±ëœ í…ìŠ¤íŠ¸ íŒŒì‹±"""
    st.session_state.full_scenario = []
    parts = generated_text.split('---')
    if len(parts) < 4: return False
    for part in parts:
        try:
            story = re.search(r"\[STORY\s?\d\](.*?)(?=\[CHOICE\s?\dA\])", part, re.DOTALL).group(1).strip()
            choice_a = re.search(r"\[CHOICE\s?\dA\](.*?)(?=\[CHOICE\s?\dB\])", part, re.DOTALL).group(1).strip()
            choice_b = re.search(r"\[CHOICE\s?\dB\](.*)", part, re.DOTALL).group(1).strip()
            st.session_state.full_scenario.append({"story": story, "choice_a": choice_a, "choice_b": choice_b})
        except Exception:
            continue
    return len(st.session_state.full_scenario) >= 4

def start_debate(history, choice):
    """í† ë¡  ì‹œì‘ ì§ˆë¬¸"""
    model = get_model()
    prompt = (
        "ë‹¹ì‹ ì€ ë‹¤ì •í•œ AI ì¹œêµ¬ 'ì­ˆë‹ˆë´‡'ì…ë‹ˆë‹¤. í•™ìƒì˜ ì„ íƒì„ ì§€ì§€í•˜ë©° ìì—°ìŠ¤ëŸ½ê²Œ í† ë¡ ì„ ì‹œì‘í•˜ëŠ” ì²« ì§ˆë¬¸ì„ í•´ì£¼ì„¸ìš”.\n"
        f"--- ì´ì•¼ê¸°ì™€ ì„ íƒ ---\n{history}\ní•™ìƒì˜ ì„ íƒ: {choice}\n\nì­ˆë‹ˆë´‡:"
    )
    try:
        response = model.generate_content(prompt); return response.text.strip()
    except Exception: return "ì„ íƒí–ˆêµ°ìš”! ì™œ ê·¸ëŸ° ì„ íƒì„ í–ˆëŠ”ì§€ ê¶ê¸ˆí•´ìš”."

def generate_conclusion(final_history):
    """ìµœì¢… í”¼ë“œë°±"""
    model = get_model()
    prompt = (
        "ë‹¹ì‹ ì€ ë‹¤ì •í•œ AI ì¹œêµ¬ 'ì­ˆë‹ˆë´‡'ì…ë‹ˆë‹¤. í•™ìƒì˜ ì „ì²´ í† ë¡  ê¸°ë¡ì„ ë³´ê³ , ì •ë‹µë³´ë‹¤ëŠ” ê³ ë¯¼í•˜ëŠ” ê³¼ì •ì´ ì¤‘ìš”í–ˆìŒì„ ì¹­ì°¬í•˜ëŠ” ë”°ëœ»í•œ ë§ˆë¬´ë¦¬ ë©˜íŠ¸ë¥¼ í•´ì£¼ì„¸ìš”.\n"
        f"--- ì „ì²´ ê¸°ë¡ ---\n{final_history}"
    )
    try:
        response = model.generate_content(prompt); return response.text.strip()
    except Exception: return "ì •ë§ ìˆ˜ê³ í–ˆì–´ìš”! í›Œë¥­í•œ í† ë¡ ì´ì—ˆìŠµë‹ˆë‹¤."

# --- 5. ë©”ì¸ ì•± ë¡œì§ ---

def run_main_app():
    st.header("ğŸ¤– ì­ˆë‹ˆë´‡ê³¼ í•¨ê»˜ í† ë¡ í•˜ê¸°")
    st.caption("AI ìœ¤ë¦¬ ë¬¸ì œ, ì­ˆë‹ˆë´‡ê³¼ í•¨ê»˜ ì´ì•¼ê¸°í•˜ë©° ë‹µì„ ì°¾ì•„ë´ìš”!")

    # ì„¸ì…˜ ì´ˆê¸°í™”
    if 'stage' not in st.session_state:
        st.session_state.stage = 'start'
        st.session_state.full_scenario = []
        st.session_state.full_log = ""
        st.session_state.current_part = -1
        st.session_state.debate_turns = 0
        st.session_state.debate_finished = False

    MAX_DEBATE_REPLIES = 3  # í† ë¡  í„´ ìˆ˜ ì œí•œ

    def restart():
        for key in ['stage', 'full_scenario', 'full_log', 'current_part', 'debate_turns', 'debate_finished']:
            if key in st.session_state: del st.session_state[key]
        st.rerun()

    # [1ë‹¨ê³„] ì‹œì‘ í™”ë©´
    if st.session_state.stage == 'start':
        st.info("í† ë¡ í•˜ê³  ì‹¶ì€ ì£¼ì œë¥¼ ê³ ë¥´ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ë©´, ì­ˆë‹ˆë´‡ì´ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ì–´ì¤„ ê±°ì•¼!")
        
        options_list = ["ì§ì ‘ ì…ë ¥..."] + list(EXAMPLE_TOPICS.keys())
        selected_topic = st.selectbox("ì£¼ì œ ì„ íƒ:", options_list)

        default_text = ""
        if selected_topic != "ì§ì ‘ ì…ë ¥...":
            default_text = EXAMPLE_TOPICS[selected_topic]
        
        teacher_input = st.text_area("ì‹œë‚˜ë¦¬ì˜¤ ì†Œì¬ ì…ë ¥:", value=default_text, height=150)

        if st.button("í† ë¡  ì‹œì‘í•˜ê¸° âœ¨"):
            if not teacher_input.strip():
                st.warning("ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner("ì­ˆë‹ˆë´‡ì´ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ê³  ìˆì–´ìš”..."):
                    scenario_text = transform_scenario(teacher_input)
                    
                    if scenario_text and parse_and_store_scenario(scenario_text):
                        st.session_state.full_log = f"**ì£¼ì œ:** {teacher_input[:50]}..."
                        st.session_state.current_part = 0
                        st.session_state.stage = 'story'
                        st.rerun()
                    else:
                        st.error("ì´ì•¼ê¸°ë¥¼ ë§Œë“œëŠ” ë° ì‹¤íŒ¨í–ˆì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    # [2ë‹¨ê³„] ì´ì•¼ê¸° ì§„í–‰ ë° ì„ íƒ
    elif st.session_state.stage == 'story':
        part = st.session_state.full_scenario[st.session_state.current_part]
        current_story = f"\n\n---\n\n### ğŸ“– ì´ì•¼ê¸° #{st.session_state.current_part + 1}\n{part['story']}"
        
        if current_story.strip() not in st.session_state.full_log:
            st.session_state.full_log += current_story
            
        st.markdown(current_story)
        st.info("ì–´ë–¤ ì„ íƒì„ í• ë˜?")
        
        c1, c2 = st.columns(2)
        if c1.button(f"ğŸ…°ï¸ {part['choice_a']}", use_container_width=True):
            st.session_state.full_log += f"\n\n**>> ë‚˜ì˜ ì„ íƒ(A):** {part['choice_a']}"
            st.session_state.stage = 'debate'
            st.rerun()
        if c2.button(f"ğŸ…±ï¸ {part['choice_b']}", use_container_width=True):
            st.session_state.full_log += f"\n\n**>> ë‚˜ì˜ ì„ íƒ(B):** {part['choice_b']}"
            st.session_state.stage = 'debate'
            st.rerun()

    # [3ë‹¨ê³„] í† ë¡  ì§„í–‰
    elif st.session_state.stage == 'debate':
        # ì±„íŒ… UI í‘œì‹œ
        for msg in st.session_state.full_log.split('\n\n'):
            msg = msg.strip()
            if not msg: continue
            if msg.startswith(">> ë‚˜ì˜ ì„ íƒ"): st.chat_message("user", avatar="ğŸ™‹").write(msg)
            elif msg.startswith("ì­ˆë‹ˆë´‡:"): st.chat_message("assistant", avatar="ğŸ¤–").write(msg.replace("ì­ˆë‹ˆë´‡:", "**ì­ˆë‹ˆë´‡:**"))
            elif msg.startswith("ë‚˜ (ì˜ê²¬"): st.chat_message("user", avatar="ğŸ™‹").write(msg)
            elif "### ğŸ“– ì´ì•¼ê¸°" in msg: st.markdown(msg)

        # í† ë¡  ì¢…ë£Œ ì²˜ë¦¬
        if st.session_state.debate_finished:
            st.success("ì´ë²ˆ í† ë¡ ì´ ëë‚¬ì–´!")
            is_last = st.session_state.current_part >= len(st.session_state.full_scenario) - 1
            if st.button("ë‹¤ìŒ ì´ì•¼ê¸°ë¡œ ê°€ê¸° â¡ï¸" if not is_last else "ìµœì¢… ê²°ê³¼ ë³´ê¸° ğŸ†"):
                st.session_state.debate_turns = 0
                st.session_state.debate_finished = False
                st.session_state.current_part += 1
                st.session_state.stage = 'conclusion' if is_last else 'story'
                st.rerun()
        
        else:
            # 1. ì­ˆë‹ˆë´‡ ì²« ì§ˆë¬¸
            if st.session_state.debate_turns == 0:
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    with st.spinner("ì­ˆë‹ˆë´‡ì´ ìƒê° ì¤‘..."):
                        last_choice = st.session_state.full_log.split('>> ë‚˜ì˜ ì„ íƒ')[-1]
                        q = start_debate(st.session_state.full_log, last_choice)
                        st.write(f"**ì­ˆë‹ˆë´‡:** {q}")
                        st.session_state.full_log += f"\n\nì­ˆë‹ˆë´‡: {q}"
                        st.session_state.debate_turns = 1

            # 2. í•™ìƒ ë‹µë³€ ì…ë ¥
            elif st.session_state.debate_turns % 2 != 0:
                if user_input := st.chat_input(f"ë‚´ ìƒê° ë§í•˜ê¸° ({ (st.session_state.debate_turns+1)//2 }/{MAX_DEBATE_REPLIES})"):
                    st.session_state.full_log += f"\n\në‚˜ (ì˜ê²¬): {user_input}"
                    st.session_state.debate_turns += 1
                    st.rerun()

            # 3. ì­ˆë‹ˆë´‡ ë°˜ì‘ ë° ë‹¤ìŒ ì§ˆë¬¸
            else:
                with st.chat_message("assistant", avatar="ğŸ¤–"):
                    with st.spinner("ì­ˆë‹ˆë´‡ì´ ë‹µë³€ì„ ì½ê³  ìˆì–´ìš”..."):
                        decision = analyze_student_response(st.session_state.full_log)
                        
                        if decision == "end_early" or (st.session_state.debate_turns / 2) >= MAX_DEBATE_REPLIES:
                            msg = "ì¢‹ì€ ì˜ê²¬ì´ì•¼! ë„¤ ìƒê°ì„ ë“¤ë ¤ì¤˜ì„œ ê³ ë§ˆì›Œ. ìš°ë¦¬ ì´ì œ ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°€ ë³¼ê¹Œ?"
                            st.write(f"**ì­ˆë‹ˆë´‡:** {msg}")
                            st.session_state.full_log += f"\n\nì­ˆë‹ˆë´‡: {msg}"
                            st.session_state.debate_finished = True
                            st.rerun()
                        else:
                            if decision == "simplify": q = generate_simpler_question(st.session_state.full_log)
                            elif decision == "deepen": q = continue_debate(st.session_state.full_log, "deepen")
                            else: q = continue_debate(st.session_state.full_log, "normal")
                            
                            st.write(f"**ì­ˆë‹ˆë´‡:** {q}")
                            st.session_state.full_log += f"\n\nì­ˆë‹ˆë´‡: {q}"
                            st.session_state.debate_turns += 1
                            st.rerun()

    # [4ë‹¨ê³„] ìµœì¢… ê²°ê³¼
    elif st.session_state.stage == 'conclusion':
        st.balloons()
        st.header("ğŸ‰ í† ë¡  ì™„ë£Œ!")
        st.subheader("ìš°ë¦¬ê°€ ë‚˜ëˆˆ ì´ì•¼ê¸°ë“¤")
        st.text_area("í™œë™ ê¸°ë¡", st.session_state.full_log, height=300)
        
        st.subheader("ğŸ’Œ ì­ˆë‹ˆë´‡ì˜ í¸ì§€")
        with st.spinner("í¸ì§€ ì“°ëŠ” ì¤‘..."):
            final_comment = generate_conclusion(st.session_state.full_log)
            st.write(final_comment)
            
        if st.button("ì²˜ìŒìœ¼ë¡œ ëŒì•„ê°€ê¸°"):
            restart()

# ì•± ì‹¤í–‰
if __name__ == "__main__":
    run_main_app()
